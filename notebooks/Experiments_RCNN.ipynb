{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "SEED = 41\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH        = '../data/raw/'\n",
    "PROCESSED_DATA_PATH  = '../data/processed/' \n",
    "\n",
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample():\n",
    "    return pd.read_csv(os.path.join(PROCESSED_DATA_PATH, 'train_sample.csv'))\n",
    "\n",
    "def load_full():\n",
    "    train       = pd.read_csv(os.path.join(RAW_DATA_PATH, 'train.csv'))\n",
    "    test        = pd.read_csv(os.path.join(RAW_DATA_PATH, 'test.csv'))\n",
    "    test_labels = pd.read_csv(os.path.join(RAW_DATA_PATH, 'test_labels.csv'))\n",
    "    \n",
    "    return train, test, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 s, sys: 236 ms, total: 1.75 s\n",
      "Wall time: 2.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, _, _ = load_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 132 ms, sys: 40 ms, total: 172 ms\n",
      "Wall time: 487 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# train = load_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLS = ['toxic', \n",
    "               'severe_toxic', \n",
    "               'obscene', \n",
    "               'threat', \n",
    "               'insult', \n",
    "               'identity_hate'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tokenizer\n",
    "tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.25 s, sys: 328 ms, total: 5.58 s\n",
      "Wall time: 5.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_tokenized_comments = list(map(tokenizer.tokenize, train.comment_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.99 s, sys: 3.92 s, total: 9.91 s\n",
      "Wall time: 9.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.loc[:, 'tokenized_comments'] = list(map(' '.join, map(tokenizer.tokenize, train.comment_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create word freq mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter()\n",
    "\n",
    "for tok_comments in train_tokenized_comments:\n",
    "    token_counts.update(tok_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 32838\n"
     ]
    }
   ],
   "source": [
    "# we can put a threshold on the token frequency to reduce the vocabulary\n",
    "tokens    = {}\n",
    "min_count = 10\n",
    "\n",
    "for token, freq in token_counts.items():\n",
    "    if freq >= min_count:\n",
    "        tokens[token] = freq\n",
    "        \n",
    "print('Size of the vocabulary: {}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wv_embedding_matrix(words):\n",
    "    word2vec_dict = word2vec.KeyedVectors.load_word2vec_format(os.path.join(PROCESSED_DATA_PATH, 'word2vec.bin.gz'), binary=True)\n",
    "    embed_size    = 300\n",
    "\n",
    "    embedding_index = dict()\n",
    "    for word in word2vec_dict.wv.vocab:\n",
    "        embedding_index[word] = word2vec_dict.word_vec(word)\n",
    "\n",
    "    print('Loaded %d word vectors'%(len(embedding_index)))\n",
    "\n",
    "    all_embs          = np.stack(list(embedding_index.values()))\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "    UNK, PAD       = 'UNK', 'PAD'\n",
    "    UNK_IX, PAD_IX = len(words), len(words) + 1\n",
    "\n",
    "    nb_words = len(words) + 2\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "    embed_cnt = 0\n",
    "    for i, word in enumerate(list(words.keys()) + [UNK, PAD]):\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            embed_cnt +=1\n",
    "\n",
    "    print('total embedded ', embed_cnt, ' common words')\n",
    "    del embedding_index\n",
    "    gc.collect()\n",
    "\n",
    "    return embedding_matrix, UNK, PAD, UNK_IX, PAD_IX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token to ID mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token to index (manual)\n",
    "# UNK, PAD       = 'UNK', 'PAD'\n",
    "# UNK_IX, PAD_IX =  0, 1\n",
    "\n",
    "# token_to_id = {UNK: UNK_IX,\n",
    "#                PAD: PAD_IX\n",
    "#               }\n",
    "\n",
    "# for token in tokens.keys():\n",
    "#     token_to_id[token] = len(token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000000 word vectors\n",
      "total embedded  29714  common words\n",
      "CPU times: user 2min 39s, sys: 9.04 s, total: 2min 48s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# token to index ( word2vec embeddings )\n",
    "embedding_matrix, UNK, PAD, UNK_IX, PAD_IX = load_wv_embedding_matrix(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id      = {word: index for index, word in enumerate(tokens.keys())}\n",
    "token_to_id[UNK] = UNK_IX\n",
    "token_to_id[PAD] = PAD_IX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad Sequences and convert map tokens to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, token_to_id, word_dropout, UNK_IX, PAD_IX, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "\n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "\n",
    "    if word_dropout != 0:\n",
    "        matrix = apply_word_dropout(matrix, 1 - word_dropout, replace_with=UNK_IX, pad_ix=PAD_IX)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with, pad_ix):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1-keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  127656\n",
      "Validation size =  31915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "data_train.index     = range(len(data_train))\n",
    "data_val.index       = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(matrix, labels, batch_size, predict_mode='train'):\n",
    "    indices = np.arange(len(matrix))\n",
    "    if predict_mode == 'train':\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, len(matrix), batch_size):\n",
    "        end = min(start + batch_size, len(matrix))\n",
    "        \n",
    "        batch_indices = indices[start: end]\n",
    "        X = matrix[batch_indices]\n",
    "        \n",
    "        if predict_mode != 'train': yield X\n",
    "        else: yield X, labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN(nn.Module):\n",
    "    def __init__(self, weights, vocab_size, embed_size, hidden_size, num_classes):\n",
    "        super(RCNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size  = vocab_size\n",
    "        self.embed_size  = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.embedding.weight = nn.Parameter(weights)\n",
    "        \n",
    "        self.Wl  = nn.Parameter(data=torch.Tensor(self.hidden_size, self.hidden_size), requires_grad=True)\n",
    "        self.Wsl = nn.Parameter(data=torch.Tensor(self.hidden_size, self.embed_size), requires_grad=True) \n",
    "        \n",
    "        self.Wr  = nn.Parameter(data=torch.Tensor(self.hidden_size, self.hidden_size), requires_grad=True)\n",
    "        self.Wsr = nn.Parameter(data=torch.Tensor(self.hidden_size, self.embed_size), requires_grad=True) \n",
    "        \n",
    "        \n",
    "        self.cl  = nn.Parameter(data=torch.Tensor(1, self.hidden_size), requires_grad=True)\n",
    "        self.cr  = nn.Parameter(data=torch.Tensor(1, self.hidden_size), requires_grad=True)\n",
    "        \n",
    "        self.relu = nn.ReLU() \n",
    "        self.fc   = nn.Linear(self.hidden_size * 2 + self.embed_size, self.num_classes)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.Wl, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wsl, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wr, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wsr, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.cl, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.cr, a=np.sqrt(5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # create left and right context vectors to be equal to be\n",
    "        # equal to (batch_size, hidden_size)\n",
    "        \n",
    "        cl        = self.cl.repeat(x.size(0), 1)\n",
    "        cr        = self.cr.repeat(x.size(0), 1)\n",
    "        \n",
    "        \n",
    "        embed     = self.embedding(x)\n",
    "        cxt       = cl.t()\n",
    "        \n",
    "        left_context  = []\n",
    "        right_context = []\n",
    "        \n",
    "        # O(n)\n",
    "        for i in range(1, x.size(1)):\n",
    "            cxt         = self.relu(torch.mm(self.Wl, cxt) + torch.mm(self.Wsl, embed[:, i-1, :].t()))\n",
    "            left_context.append(cxt)\n",
    "        \n",
    "        cxt = cr.t()\n",
    "        \n",
    "        # O(n)\n",
    "        for i in range(x.size(1)-2, -1, -1):\n",
    "            cxt         = self.relu(torch.mm(self.Wr, cxt) + torch.mm(self.Wsr, embed[:, i-1, :].t()))\n",
    "            right_context.append(cxt)\n",
    "        \n",
    "        \n",
    "        left_context  = torch.cat([cl.t()] + left_context, dim=1)\n",
    "        left_context  = left_context.view(x.size(0), x.size(1), -1)\n",
    "        \n",
    "        right_context = torch.cat(right_context + [cr.t()], dim=1).t()\n",
    "        right_context = right_context.view(x.size(0), x.size(1), -1)\n",
    "        \n",
    "        # word representation\n",
    "        word_repr = torch.cat((left_context, embed, right_context), dim=2)\n",
    "        \n",
    "#         print('WORD REPR ', word_repr.shape)\n",
    "        \n",
    "#         out = self.fc1(word_repr)\n",
    "#         out = self.relu(out)\n",
    "        \n",
    "        # text representation\n",
    "        out = word_repr.max(dim=1)[0]\n",
    "        \n",
    "        # final layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, criterion, data, batch_size, optimizer=None):\n",
    "    epoch_loss, total_size = 0, 0\n",
    "    per_label_preds = [[], [], [], [], [], []]\n",
    "    per_label_true  = [[], [], [], [], [], []]\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    model.train(is_train)\n",
    "    \n",
    "    data, labels = data\n",
    "    batchs_count = math.ceil(data.shape[0] / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        for i, (X_batch, y_batch) in enumerate(iterate_batches(data, labels, batch_size)):\n",
    "            X_batch, y_batch = torch.cuda.LongTensor(X_batch), torch.cuda.FloatTensor(y_batch)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            loss   = criterion(logits, y_batch)\n",
    "            \n",
    "            if is_train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # convert true target\n",
    "            batch_target = y_batch.cpu().detach().numpy()\n",
    "            logits_cpu   = logits.cpu().detach().numpy()\n",
    "            \n",
    "            # per_label_preds\n",
    "            for j in range(6):\n",
    "                label_preds     = logits_cpu[:, j]\n",
    "                per_label_preds[j].extend(label_preds)\n",
    "                per_label_true[j].extend(batch_target[:, j])\n",
    "                            \n",
    "            # calculate log loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            print('\\r[{} / {}]: Loss = {:.4f}'.format(\n",
    "                  i, batchs_count, loss.item(), end=''))\n",
    "    \n",
    "    label_auc = []\n",
    "    \n",
    "    for i in range(6):\n",
    "        label_auc.append(roc_auc_score(per_label_true[i], per_label_preds[i]))\n",
    "    \n",
    "    return epoch_loss / batchs_count, np.mean(label_auc)\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, \n",
    "        batch_size=32, val_data=None, val_batch_size=None):\n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_auc = do_epoch(\n",
    "            model, criterion, train_data, batch_size, optimizer\n",
    "        )\n",
    "        \n",
    "        output_info = '\\rEpoch {} / {}, Epoch Time = {:.2f}s: Train Loss = {:.4f}, Train AUC = {:.4f}'\n",
    "        if not val_data is None:\n",
    "            val_loss, val_auc   = do_epoch(model, criterion, val_data, val_batch_size, None)\n",
    "            \n",
    "            epoch_time   = time.time() - start_time\n",
    "            output_info += ', Val Loss = {:.4f}, Val AUC = {:.4f}'\n",
    "            print(output_info.format(epoch+1, epochs_count, epoch_time, \n",
    "                                     train_loss,\n",
    "                                     train_auc,\n",
    "                                     val_loss,\n",
    "                                     val_auc\n",
    "                                    ))\n",
    "        else:\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(output_info.format(epoch+1, epochs_count, epoch_time, train_loss, train_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = as_matrix(data_train['tokenized_comments'], \n",
    "                   token_to_id, \n",
    "                   word_dropout=0, \n",
    "                   UNK_IX=UNK_IX, \n",
    "                   PAD_IX=PAD_IX,\n",
    "                   max_len=MAX_LEN\n",
    "                  )\n",
    "\n",
    "labels = data_train.loc[:, TARGET_COLS].values\n",
    "X, y   = next(iterate_batches(matrix, labels, batch_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cuda.LongTensor(X)\n",
    "y = torch.cuda.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size  = len(token_to_id)\n",
    "embed_size  = 300\n",
    "hidden_size = 2\n",
    "num_classes = 6\n",
    "\n",
    "model =  RCNN(torch.FloatTensor(embedding_matrix),\n",
    "              vocab_size, \n",
    "              embed_size,\n",
    "              hidden_size,\n",
    "              num_classes,\n",
    "              batch_size=2\n",
    "              ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1889,  0.0636,  0.0409,  0.1613, -0.0313, -0.0770],\n",
      "        [ 0.1457,  0.0622,  0.0820,  0.1540, -0.0168, -0.1331]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "logits = model(X)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on full batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 / 250]: Loss = 0.6359\n",
      "[1 / 250]: Loss = 0.5850\n",
      "[2 / 250]: Loss = 0.5344\n",
      "[3 / 250]: Loss = 0.4948\n",
      "[4 / 250]: Loss = 0.4465\n",
      "[5 / 250]: Loss = 0.4094\n",
      "[6 / 250]: Loss = 0.3817\n",
      "[7 / 250]: Loss = 0.3427\n",
      "[8 / 250]: Loss = 0.3005\n",
      "[9 / 250]: Loss = 0.2863\n",
      "[10 / 250]: Loss = 0.2658\n",
      "[11 / 250]: Loss = 0.2426\n",
      "[12 / 250]: Loss = 0.2279\n",
      "[13 / 250]: Loss = 0.2014\n",
      "[14 / 250]: Loss = 0.1907\n",
      "[15 / 250]: Loss = 0.1702\n",
      "[16 / 250]: Loss = 0.1697\n",
      "[17 / 250]: Loss = 0.1988\n",
      "[18 / 250]: Loss = 0.1495\n",
      "[19 / 250]: Loss = 0.1577\n",
      "[20 / 250]: Loss = 0.1743\n",
      "[21 / 250]: Loss = 0.1117\n",
      "[22 / 250]: Loss = 0.1423\n",
      "[23 / 250]: Loss = 0.1430\n",
      "[24 / 250]: Loss = 0.1455\n",
      "[25 / 250]: Loss = 0.1314\n",
      "[26 / 250]: Loss = 0.1390\n",
      "[27 / 250]: Loss = 0.1486\n",
      "[28 / 250]: Loss = 0.1444\n",
      "[29 / 250]: Loss = 0.1695\n",
      "[30 / 250]: Loss = 0.1426\n",
      "[31 / 250]: Loss = 0.1579\n",
      "[32 / 250]: Loss = 0.1402\n",
      "[33 / 250]: Loss = 0.1616\n",
      "[34 / 250]: Loss = 0.1551\n",
      "[35 / 250]: Loss = 0.1378\n",
      "[36 / 250]: Loss = 0.1475\n",
      "[37 / 250]: Loss = 0.1342\n",
      "[38 / 250]: Loss = 0.1269\n",
      "[39 / 250]: Loss = 0.1183\n",
      "[40 / 250]: Loss = 0.1363\n",
      "[41 / 250]: Loss = 0.1206\n",
      "[42 / 250]: Loss = 0.1602\n",
      "[43 / 250]: Loss = 0.1473\n",
      "[44 / 250]: Loss = 0.1294\n",
      "[45 / 250]: Loss = 0.1169\n",
      "[46 / 250]: Loss = 0.1406\n",
      "[47 / 250]: Loss = 0.1338\n",
      "[48 / 250]: Loss = 0.1415\n",
      "[49 / 250]: Loss = 0.1282\n",
      "[50 / 250]: Loss = 0.1408\n",
      "[51 / 250]: Loss = 0.1474\n",
      "[52 / 250]: Loss = 0.1330\n",
      "[53 / 250]: Loss = 0.1522\n",
      "[54 / 250]: Loss = 0.1197\n",
      "[55 / 250]: Loss = 0.1530\n",
      "[56 / 250]: Loss = 0.1435\n",
      "[57 / 250]: Loss = 0.1277\n",
      "[58 / 250]: Loss = 0.1484\n",
      "[59 / 250]: Loss = 0.1191\n",
      "[60 / 250]: Loss = 0.1310\n",
      "[61 / 250]: Loss = 0.1370\n",
      "[62 / 250]: Loss = 0.1238\n",
      "[63 / 250]: Loss = 0.1178\n",
      "[64 / 250]: Loss = 0.1516\n",
      "[65 / 250]: Loss = 0.1118\n",
      "[66 / 250]: Loss = 0.1244\n",
      "[67 / 250]: Loss = 0.1299\n",
      "[68 / 250]: Loss = 0.1329\n",
      "[69 / 250]: Loss = 0.1258\n",
      "[70 / 250]: Loss = 0.1596\n",
      "[71 / 250]: Loss = 0.1290\n",
      "[72 / 250]: Loss = 0.1218\n",
      "[73 / 250]: Loss = 0.1531\n",
      "[74 / 250]: Loss = 0.1381\n",
      "[75 / 250]: Loss = 0.1292\n",
      "[76 / 250]: Loss = 0.1218\n",
      "[77 / 250]: Loss = 0.1277\n",
      "[78 / 250]: Loss = 0.1117\n",
      "[79 / 250]: Loss = 0.1190\n",
      "[80 / 250]: Loss = 0.1500\n",
      "[81 / 250]: Loss = 0.1283\n",
      "[82 / 250]: Loss = 0.1511\n",
      "[83 / 250]: Loss = 0.1737\n",
      "[84 / 250]: Loss = 0.1246\n",
      "[85 / 250]: Loss = 0.1302\n",
      "[86 / 250]: Loss = 0.1567\n",
      "[87 / 250]: Loss = 0.1147\n",
      "[88 / 250]: Loss = 0.1553\n",
      "[89 / 250]: Loss = 0.1688\n",
      "[90 / 250]: Loss = 0.1273\n",
      "[91 / 250]: Loss = 0.1428\n",
      "[92 / 250]: Loss = 0.1289\n",
      "[93 / 250]: Loss = 0.1396\n",
      "[94 / 250]: Loss = 0.1204\n",
      "[95 / 250]: Loss = 0.1532\n",
      "[96 / 250]: Loss = 0.1042\n",
      "[97 / 250]: Loss = 0.1423\n",
      "[98 / 250]: Loss = 0.1241\n",
      "[99 / 250]: Loss = 0.1393\n",
      "[100 / 250]: Loss = 0.1369\n",
      "[101 / 250]: Loss = 0.1447\n",
      "[102 / 250]: Loss = 0.1378\n",
      "[103 / 250]: Loss = 0.1483\n",
      "[104 / 250]: Loss = 0.1511\n",
      "[105 / 250]: Loss = 0.1259\n",
      "[106 / 250]: Loss = 0.1155\n",
      "[107 / 250]: Loss = 0.1441\n",
      "[108 / 250]: Loss = 0.1555\n",
      "[109 / 250]: Loss = 0.1663\n",
      "[110 / 250]: Loss = 0.1243\n",
      "[111 / 250]: Loss = 0.1478\n",
      "[112 / 250]: Loss = 0.1228\n",
      "[113 / 250]: Loss = 0.1337\n",
      "[114 / 250]: Loss = 0.1441\n",
      "[115 / 250]: Loss = 0.1439\n",
      "[116 / 250]: Loss = 0.1431\n",
      "[117 / 250]: Loss = 0.1194\n",
      "[118 / 250]: Loss = 0.1495\n",
      "[119 / 250]: Loss = 0.1095\n",
      "[120 / 250]: Loss = 0.1221\n",
      "[121 / 250]: Loss = 0.1416\n",
      "[122 / 250]: Loss = 0.1349\n",
      "[123 / 250]: Loss = 0.1102\n",
      "[124 / 250]: Loss = 0.1336\n",
      "[125 / 250]: Loss = 0.1376\n",
      "[126 / 250]: Loss = 0.1071\n",
      "[127 / 250]: Loss = 0.1402\n",
      "[128 / 250]: Loss = 0.1379\n",
      "[129 / 250]: Loss = 0.1476\n",
      "[130 / 250]: Loss = 0.1074\n",
      "[131 / 250]: Loss = 0.1067\n",
      "[132 / 250]: Loss = 0.1312\n",
      "[133 / 250]: Loss = 0.1267\n",
      "[134 / 250]: Loss = 0.1322\n",
      "[135 / 250]: Loss = 0.1726\n",
      "[136 / 250]: Loss = 0.1277\n",
      "[137 / 250]: Loss = 0.1046\n",
      "[138 / 250]: Loss = 0.1145\n",
      "[139 / 250]: Loss = 0.1389\n",
      "[140 / 250]: Loss = 0.1295\n",
      "[141 / 250]: Loss = 0.1320\n",
      "[142 / 250]: Loss = 0.1344\n",
      "[143 / 250]: Loss = 0.1143\n",
      "[144 / 250]: Loss = 0.1426\n",
      "[145 / 250]: Loss = 0.1660\n",
      "[146 / 250]: Loss = 0.1239\n",
      "[147 / 250]: Loss = 0.1305\n",
      "[148 / 250]: Loss = 0.1366\n",
      "[149 / 250]: Loss = 0.1378\n",
      "[150 / 250]: Loss = 0.1151\n",
      "[151 / 250]: Loss = 0.1220\n",
      "[152 / 250]: Loss = 0.1361\n",
      "[153 / 250]: Loss = 0.1254\n",
      "[154 / 250]: Loss = 0.1089\n",
      "[155 / 250]: Loss = 0.1382\n",
      "[156 / 250]: Loss = 0.1171\n",
      "[157 / 250]: Loss = 0.1461\n",
      "[158 / 250]: Loss = 0.1247\n",
      "[159 / 250]: Loss = 0.1230\n",
      "[160 / 250]: Loss = 0.1303\n",
      "[161 / 250]: Loss = 0.1200\n",
      "[162 / 250]: Loss = 0.1392\n",
      "[163 / 250]: Loss = 0.1372\n",
      "[164 / 250]: Loss = 0.1308\n",
      "[165 / 250]: Loss = 0.1253\n",
      "[166 / 250]: Loss = 0.1133\n",
      "[167 / 250]: Loss = 0.1530\n",
      "[168 / 250]: Loss = 0.1551\n",
      "[169 / 250]: Loss = 0.1272\n",
      "[170 / 250]: Loss = 0.1369\n",
      "[171 / 250]: Loss = 0.1543\n",
      "[172 / 250]: Loss = 0.1370\n",
      "[173 / 250]: Loss = 0.1249\n",
      "[174 / 250]: Loss = 0.1262\n",
      "[175 / 250]: Loss = 0.1503\n",
      "[176 / 250]: Loss = 0.1165\n",
      "[177 / 250]: Loss = 0.1238\n",
      "[178 / 250]: Loss = 0.0940\n",
      "[179 / 250]: Loss = 0.1177\n",
      "[180 / 250]: Loss = 0.1102\n",
      "[181 / 250]: Loss = 0.1348\n",
      "[182 / 250]: Loss = 0.1083\n",
      "[183 / 250]: Loss = 0.1246\n",
      "[184 / 250]: Loss = 0.1498\n",
      "[185 / 250]: Loss = 0.1249\n",
      "[186 / 250]: Loss = 0.1190\n",
      "[187 / 250]: Loss = 0.1603\n",
      "[188 / 250]: Loss = 0.1318\n",
      "[189 / 250]: Loss = 0.1348\n",
      "[190 / 250]: Loss = 0.1396\n",
      "[191 / 250]: Loss = 0.1036\n",
      "[192 / 250]: Loss = 0.1125\n",
      "[193 / 250]: Loss = 0.1031\n",
      "[194 / 250]: Loss = 0.1162\n",
      "[195 / 250]: Loss = 0.1269\n",
      "[196 / 250]: Loss = 0.1085\n",
      "[197 / 250]: Loss = 0.1267\n",
      "[198 / 250]: Loss = 0.1014\n",
      "[199 / 250]: Loss = 0.1579\n",
      "[200 / 250]: Loss = 0.1357\n",
      "[201 / 250]: Loss = 0.1268\n",
      "[202 / 250]: Loss = 0.1226\n",
      "[203 / 250]: Loss = 0.1505\n",
      "[204 / 250]: Loss = 0.1106\n",
      "[205 / 250]: Loss = 0.1324\n",
      "[206 / 250]: Loss = 0.1342\n",
      "[207 / 250]: Loss = 0.1308\n",
      "[208 / 250]: Loss = 0.1080\n",
      "[209 / 250]: Loss = 0.1177\n",
      "[210 / 250]: Loss = 0.1351\n",
      "[211 / 250]: Loss = 0.1690\n",
      "[212 / 250]: Loss = 0.1365\n",
      "[213 / 250]: Loss = 0.1044\n",
      "[214 / 250]: Loss = 0.1380\n",
      "[215 / 250]: Loss = 0.1325\n",
      "[216 / 250]: Loss = 0.1210\n",
      "[217 / 250]: Loss = 0.1294\n",
      "[218 / 250]: Loss = 0.1246\n",
      "[219 / 250]: Loss = 0.1125\n",
      "[220 / 250]: Loss = 0.1041\n",
      "[221 / 250]: Loss = 0.1280\n",
      "[222 / 250]: Loss = 0.1012\n",
      "[223 / 250]: Loss = 0.1347\n",
      "[224 / 250]: Loss = 0.1230\n",
      "[225 / 250]: Loss = 0.1125\n",
      "[226 / 250]: Loss = 0.1268\n",
      "[227 / 250]: Loss = 0.1316\n",
      "[228 / 250]: Loss = 0.1460\n",
      "[229 / 250]: Loss = 0.1183\n",
      "[230 / 250]: Loss = 0.1293\n",
      "[231 / 250]: Loss = 0.1368\n",
      "[232 / 250]: Loss = 0.1178\n",
      "[233 / 250]: Loss = 0.1575\n",
      "[234 / 250]: Loss = 0.1333\n",
      "[235 / 250]: Loss = 0.1032\n",
      "[236 / 250]: Loss = 0.1175\n",
      "[237 / 250]: Loss = 0.1259\n",
      "[238 / 250]: Loss = 0.1146\n",
      "[239 / 250]: Loss = 0.1323\n",
      "[240 / 250]: Loss = 0.1255\n",
      "[241 / 250]: Loss = 0.1310\n",
      "[242 / 250]: Loss = 0.1304\n",
      "[243 / 250]: Loss = 0.1064\n",
      "[244 / 250]: Loss = 0.1372\n",
      "[245 / 250]: Loss = 0.1033\n",
      "[246 / 250]: Loss = 0.1356\n",
      "[247 / 250]: Loss = 0.1418\n",
      "[248 / 250]: Loss = 0.1443\n",
      "[249 / 250]: Loss = 0.1323\n",
      "[0 / 32]: Loss = 0.1161\n",
      "[1 / 32]: Loss = 0.1264\n",
      "[2 / 32]: Loss = 0.1303\n",
      "[3 / 32]: Loss = 0.1140\n",
      "[4 / 32]: Loss = 0.1175\n",
      "[5 / 32]: Loss = 0.1224\n",
      "[6 / 32]: Loss = 0.1239\n",
      "[7 / 32]: Loss = 0.1168\n",
      "[8 / 32]: Loss = 0.1079\n",
      "[9 / 32]: Loss = 0.1244\n",
      "[10 / 32]: Loss = 0.1241\n",
      "[11 / 32]: Loss = 0.1231\n",
      "[12 / 32]: Loss = 0.1280\n",
      "[13 / 32]: Loss = 0.1183\n",
      "[14 / 32]: Loss = 0.1245\n",
      "[15 / 32]: Loss = 0.1243\n",
      "[16 / 32]: Loss = 0.1080\n",
      "[17 / 32]: Loss = 0.1587\n",
      "[18 / 32]: Loss = 0.1140\n",
      "[19 / 32]: Loss = 0.1166\n",
      "[20 / 32]: Loss = 0.1171\n",
      "[21 / 32]: Loss = 0.1204\n",
      "[22 / 32]: Loss = 0.1368\n",
      "[23 / 32]: Loss = 0.1168\n",
      "[24 / 32]: Loss = 0.1156\n",
      "[25 / 32]: Loss = 0.1455\n",
      "[26 / 32]: Loss = 0.1206\n",
      "[27 / 32]: Loss = 0.1246\n",
      "[28 / 32]: Loss = 0.1330\n",
      "[29 / 32]: Loss = 0.1248\n",
      "[30 / 32]: Loss = 0.1255\n",
      "[31 / 32]: Loss = 0.1464\n",
      "Epoch 1 / 10, Epoch Time = 167.85s: Train Loss = 0.1471, Train AUC = 0.6709, Val Loss = 0.1239, Val AUC = 0.7852\n",
      "[0 / 250]: Loss = 0.1224\n",
      "[1 / 250]: Loss = 0.1382\n",
      "[2 / 250]: Loss = 0.1224\n",
      "[3 / 250]: Loss = 0.1021\n",
      "[4 / 250]: Loss = 0.1208\n",
      "[5 / 250]: Loss = 0.1149\n",
      "[6 / 250]: Loss = 0.1274\n",
      "[7 / 250]: Loss = 0.1283\n",
      "[8 / 250]: Loss = 0.1091\n",
      "[9 / 250]: Loss = 0.1127\n",
      "[10 / 250]: Loss = 0.1226\n",
      "[11 / 250]: Loss = 0.1339\n",
      "[12 / 250]: Loss = 0.1095\n",
      "[13 / 250]: Loss = 0.1049\n",
      "[14 / 250]: Loss = 0.1296\n",
      "[15 / 250]: Loss = 0.1104\n",
      "[16 / 250]: Loss = 0.1087\n",
      "[17 / 250]: Loss = 0.1253\n",
      "[18 / 250]: Loss = 0.1304\n",
      "[19 / 250]: Loss = 0.1350\n",
      "[20 / 250]: Loss = 0.1144\n",
      "[21 / 250]: Loss = 0.1353\n",
      "[22 / 250]: Loss = 0.1127\n",
      "[23 / 250]: Loss = 0.1280\n",
      "[24 / 250]: Loss = 0.1137\n",
      "[25 / 250]: Loss = 0.1207\n",
      "[26 / 250]: Loss = 0.1033\n",
      "[27 / 250]: Loss = 0.1162\n",
      "[28 / 250]: Loss = 0.1156\n",
      "[29 / 250]: Loss = 0.1302\n",
      "[30 / 250]: Loss = 0.1318\n",
      "[31 / 250]: Loss = 0.1353\n",
      "[32 / 250]: Loss = 0.1135\n",
      "[33 / 250]: Loss = 0.1040\n",
      "[34 / 250]: Loss = 0.1307\n",
      "[35 / 250]: Loss = 0.1008\n",
      "[36 / 250]: Loss = 0.1241\n",
      "[37 / 250]: Loss = 0.1174\n",
      "[38 / 250]: Loss = 0.1320\n",
      "[39 / 250]: Loss = 0.0943\n",
      "[40 / 250]: Loss = 0.1560\n",
      "[41 / 250]: Loss = 0.1318\n",
      "[42 / 250]: Loss = 0.1221\n",
      "[43 / 250]: Loss = 0.1170\n",
      "[44 / 250]: Loss = 0.1192\n",
      "[45 / 250]: Loss = 0.1119\n",
      "[46 / 250]: Loss = 0.1337\n",
      "[47 / 250]: Loss = 0.1186\n",
      "[48 / 250]: Loss = 0.1102\n",
      "[49 / 250]: Loss = 0.1116\n",
      "[50 / 250]: Loss = 0.1069\n",
      "[51 / 250]: Loss = 0.1052\n",
      "[52 / 250]: Loss = 0.1018\n",
      "[53 / 250]: Loss = 0.1450\n",
      "[54 / 250]: Loss = 0.1152\n",
      "[55 / 250]: Loss = 0.1186\n",
      "[56 / 250]: Loss = 0.1168\n",
      "[57 / 250]: Loss = 0.1192\n",
      "[58 / 250]: Loss = 0.1021\n",
      "[59 / 250]: Loss = 0.0962\n",
      "[60 / 250]: Loss = 0.0963\n",
      "[61 / 250]: Loss = 0.1108\n",
      "[62 / 250]: Loss = 0.1131\n",
      "[63 / 250]: Loss = 0.1184\n",
      "[64 / 250]: Loss = 0.1116\n",
      "[65 / 250]: Loss = 0.0975\n",
      "[66 / 250]: Loss = 0.1344\n",
      "[67 / 250]: Loss = 0.1246\n",
      "[68 / 250]: Loss = 0.1190\n",
      "[69 / 250]: Loss = 0.1279\n",
      "[70 / 250]: Loss = 0.1225\n",
      "[71 / 250]: Loss = 0.1190\n",
      "[72 / 250]: Loss = 0.1312\n",
      "[73 / 250]: Loss = 0.1023\n",
      "[74 / 250]: Loss = 0.1358\n",
      "[75 / 250]: Loss = 0.1026\n",
      "[76 / 250]: Loss = 0.1181\n",
      "[77 / 250]: Loss = 0.1049\n",
      "[78 / 250]: Loss = 0.1164\n",
      "[79 / 250]: Loss = 0.1050\n",
      "[80 / 250]: Loss = 0.1094\n",
      "[81 / 250]: Loss = 0.1140\n",
      "[82 / 250]: Loss = 0.1175\n",
      "[83 / 250]: Loss = 0.1166\n",
      "[84 / 250]: Loss = 0.1241\n",
      "[85 / 250]: Loss = 0.1118\n",
      "[86 / 250]: Loss = 0.1088\n",
      "[87 / 250]: Loss = 0.1035\n",
      "[88 / 250]: Loss = 0.1197\n",
      "[89 / 250]: Loss = 0.1102\n",
      "[90 / 250]: Loss = 0.1085\n",
      "[91 / 250]: Loss = 0.1077\n",
      "[92 / 250]: Loss = 0.1318\n",
      "[93 / 250]: Loss = 0.0979\n",
      "[94 / 250]: Loss = 0.1417\n",
      "[95 / 250]: Loss = 0.1002\n",
      "[96 / 250]: Loss = 0.1024\n",
      "[97 / 250]: Loss = 0.0982\n",
      "[98 / 250]: Loss = 0.1044\n",
      "[99 / 250]: Loss = 0.1009\n",
      "[100 / 250]: Loss = 0.1085\n",
      "[101 / 250]: Loss = 0.1168\n",
      "[102 / 250]: Loss = 0.1219\n",
      "[103 / 250]: Loss = 0.0940\n",
      "[104 / 250]: Loss = 0.1119\n",
      "[105 / 250]: Loss = 0.1113\n",
      "[106 / 250]: Loss = 0.1151\n",
      "[107 / 250]: Loss = 0.1023\n",
      "[108 / 250]: Loss = 0.1244\n",
      "[109 / 250]: Loss = 0.1067\n",
      "[110 / 250]: Loss = 0.1084\n",
      "[111 / 250]: Loss = 0.1187\n",
      "[112 / 250]: Loss = 0.1125\n",
      "[113 / 250]: Loss = 0.1008\n",
      "[114 / 250]: Loss = 0.1097\n",
      "[115 / 250]: Loss = 0.1337\n",
      "[116 / 250]: Loss = 0.1116\n",
      "[117 / 250]: Loss = 0.1219\n",
      "[118 / 250]: Loss = 0.1271\n",
      "[119 / 250]: Loss = 0.0932\n",
      "[120 / 250]: Loss = 0.1199\n",
      "[121 / 250]: Loss = 0.0983\n",
      "[122 / 250]: Loss = 0.1122\n",
      "[123 / 250]: Loss = 0.1226\n",
      "[124 / 250]: Loss = 0.1114\n",
      "[125 / 250]: Loss = 0.1145\n",
      "[126 / 250]: Loss = 0.1163\n",
      "[127 / 250]: Loss = 0.1286\n",
      "[128 / 250]: Loss = 0.0786\n",
      "[129 / 250]: Loss = 0.1190\n",
      "[130 / 250]: Loss = 0.1042\n",
      "[131 / 250]: Loss = 0.0802\n",
      "[132 / 250]: Loss = 0.1195\n",
      "[133 / 250]: Loss = 0.1057\n",
      "[134 / 250]: Loss = 0.1082\n",
      "[135 / 250]: Loss = 0.0962\n",
      "[136 / 250]: Loss = 0.1057\n",
      "[137 / 250]: Loss = 0.1277\n",
      "[138 / 250]: Loss = 0.1004\n",
      "[139 / 250]: Loss = 0.0955\n",
      "[140 / 250]: Loss = 0.1005\n",
      "[141 / 250]: Loss = 0.0947\n",
      "[142 / 250]: Loss = 0.1245\n",
      "[143 / 250]: Loss = 0.1000\n",
      "[144 / 250]: Loss = 0.0950\n",
      "[145 / 250]: Loss = 0.0874\n",
      "[146 / 250]: Loss = 0.1125\n",
      "[147 / 250]: Loss = 0.1014\n",
      "[148 / 250]: Loss = 0.1072\n",
      "[149 / 250]: Loss = 0.1108\n",
      "[150 / 250]: Loss = 0.1196\n",
      "[151 / 250]: Loss = 0.1001\n",
      "[152 / 250]: Loss = 0.1049\n",
      "[153 / 250]: Loss = 0.1142\n",
      "[154 / 250]: Loss = 0.0974\n",
      "[155 / 250]: Loss = 0.1079\n",
      "[156 / 250]: Loss = 0.0935\n",
      "[157 / 250]: Loss = 0.0906\n",
      "[158 / 250]: Loss = 0.0861\n",
      "[159 / 250]: Loss = 0.1097\n",
      "[160 / 250]: Loss = 0.1101\n",
      "[161 / 250]: Loss = 0.1090\n",
      "[162 / 250]: Loss = 0.0984\n",
      "[163 / 250]: Loss = 0.0880\n",
      "[164 / 250]: Loss = 0.0890\n",
      "[165 / 250]: Loss = 0.1130\n",
      "[166 / 250]: Loss = 0.1087\n",
      "[167 / 250]: Loss = 0.0718\n",
      "[168 / 250]: Loss = 0.0978\n",
      "[169 / 250]: Loss = 0.0918\n",
      "[170 / 250]: Loss = 0.1186\n",
      "[171 / 250]: Loss = 0.1209\n",
      "[172 / 250]: Loss = 0.1107\n",
      "[173 / 250]: Loss = 0.1063\n",
      "[174 / 250]: Loss = 0.1046\n",
      "[175 / 250]: Loss = 0.1154\n",
      "[176 / 250]: Loss = 0.0839\n",
      "[177 / 250]: Loss = 0.1130\n",
      "[178 / 250]: Loss = 0.0894\n",
      "[179 / 250]: Loss = 0.1202\n",
      "[180 / 250]: Loss = 0.1180\n",
      "[181 / 250]: Loss = 0.0868\n",
      "[182 / 250]: Loss = 0.0867\n",
      "[183 / 250]: Loss = 0.1101\n",
      "[184 / 250]: Loss = 0.0982\n",
      "[185 / 250]: Loss = 0.0928\n",
      "[186 / 250]: Loss = 0.0927\n",
      "[187 / 250]: Loss = 0.0790\n",
      "[188 / 250]: Loss = 0.0831\n",
      "[189 / 250]: Loss = 0.0910\n",
      "[190 / 250]: Loss = 0.1176\n",
      "[191 / 250]: Loss = 0.0938\n",
      "[192 / 250]: Loss = 0.1069\n",
      "[193 / 250]: Loss = 0.1002\n",
      "[194 / 250]: Loss = 0.1087\n",
      "[195 / 250]: Loss = 0.0950\n",
      "[196 / 250]: Loss = 0.0810\n",
      "[197 / 250]: Loss = 0.0823\n",
      "[198 / 250]: Loss = 0.0909\n",
      "[199 / 250]: Loss = 0.0867\n",
      "[200 / 250]: Loss = 0.0759\n",
      "[201 / 250]: Loss = 0.0933\n",
      "[202 / 250]: Loss = 0.1001\n",
      "[203 / 250]: Loss = 0.1121\n",
      "[204 / 250]: Loss = 0.0711\n",
      "[205 / 250]: Loss = 0.1008\n",
      "[206 / 250]: Loss = 0.1020\n",
      "[207 / 250]: Loss = 0.0998\n",
      "[208 / 250]: Loss = 0.0926\n",
      "[209 / 250]: Loss = 0.0781\n",
      "[210 / 250]: Loss = 0.0762\n",
      "[211 / 250]: Loss = 0.0924\n",
      "[212 / 250]: Loss = 0.0868\n",
      "[213 / 250]: Loss = 0.1100\n",
      "[214 / 250]: Loss = 0.0915\n",
      "[215 / 250]: Loss = 0.1033\n",
      "[216 / 250]: Loss = 0.0837\n",
      "[217 / 250]: Loss = 0.0802\n",
      "[218 / 250]: Loss = 0.0994\n",
      "[219 / 250]: Loss = 0.0847\n",
      "[220 / 250]: Loss = 0.0830\n",
      "[221 / 250]: Loss = 0.0892\n",
      "[222 / 250]: Loss = 0.0942\n",
      "[223 / 250]: Loss = 0.0773\n",
      "[224 / 250]: Loss = 0.1079\n",
      "[225 / 250]: Loss = 0.1071\n",
      "[226 / 250]: Loss = 0.0748\n",
      "[227 / 250]: Loss = 0.0825\n",
      "[228 / 250]: Loss = 0.0978\n",
      "[229 / 250]: Loss = 0.0821\n",
      "[230 / 250]: Loss = 0.0758\n",
      "[231 / 250]: Loss = 0.0968\n",
      "[232 / 250]: Loss = 0.0885\n",
      "[233 / 250]: Loss = 0.0898\n",
      "[234 / 250]: Loss = 0.0825\n",
      "[235 / 250]: Loss = 0.0801\n",
      "[236 / 250]: Loss = 0.0807\n",
      "[237 / 250]: Loss = 0.0871\n",
      "[238 / 250]: Loss = 0.0898\n",
      "[239 / 250]: Loss = 0.0784\n",
      "[240 / 250]: Loss = 0.1085\n",
      "[241 / 250]: Loss = 0.0933\n",
      "[242 / 250]: Loss = 0.1085\n",
      "[243 / 250]: Loss = 0.0692\n",
      "[244 / 250]: Loss = 0.0877\n",
      "[245 / 250]: Loss = 0.0954\n",
      "[246 / 250]: Loss = 0.0901\n",
      "[247 / 250]: Loss = 0.0877\n",
      "[248 / 250]: Loss = 0.0898\n",
      "[249 / 250]: Loss = 0.0770\n",
      "[0 / 32]: Loss = 0.0848\n",
      "[1 / 32]: Loss = 0.0840\n",
      "[2 / 32]: Loss = 0.0918\n",
      "[3 / 32]: Loss = 0.1034\n",
      "[4 / 32]: Loss = 0.0956\n",
      "[5 / 32]: Loss = 0.0932\n",
      "[6 / 32]: Loss = 0.0916\n",
      "[7 / 32]: Loss = 0.0807\n",
      "[8 / 32]: Loss = 0.0921\n",
      "[9 / 32]: Loss = 0.0854\n",
      "[10 / 32]: Loss = 0.0886\n",
      "[11 / 32]: Loss = 0.0857\n",
      "[12 / 32]: Loss = 0.0842\n",
      "[13 / 32]: Loss = 0.0929\n",
      "[14 / 32]: Loss = 0.0900\n",
      "[15 / 32]: Loss = 0.0903\n",
      "[16 / 32]: Loss = 0.0851\n",
      "[17 / 32]: Loss = 0.0900\n",
      "[18 / 32]: Loss = 0.0894\n",
      "[19 / 32]: Loss = 0.0847\n",
      "[20 / 32]: Loss = 0.0836\n",
      "[21 / 32]: Loss = 0.0851\n",
      "[22 / 32]: Loss = 0.0854\n",
      "[23 / 32]: Loss = 0.0893\n",
      "[24 / 32]: Loss = 0.0900\n",
      "[25 / 32]: Loss = 0.0981\n",
      "[26 / 32]: Loss = 0.0890\n",
      "[27 / 32]: Loss = 0.1016\n",
      "[28 / 32]: Loss = 0.0941\n",
      "[29 / 32]: Loss = 0.0927\n",
      "[30 / 32]: Loss = 0.0864\n",
      "[31 / 32]: Loss = 0.0980\n",
      "Epoch 2 / 10, Epoch Time = 167.83s: Train Loss = 0.1064, Train AUC = 0.8442, Val Loss = 0.0899, Val AUC = 0.8856\n",
      "[0 / 250]: Loss = 0.0769\n",
      "[1 / 250]: Loss = 0.1023\n",
      "[2 / 250]: Loss = 0.1092\n",
      "[3 / 250]: Loss = 0.0836\n",
      "[4 / 250]: Loss = 0.0860\n",
      "[5 / 250]: Loss = 0.0699\n",
      "[6 / 250]: Loss = 0.0967\n",
      "[7 / 250]: Loss = 0.0872\n",
      "[8 / 250]: Loss = 0.0898\n",
      "[9 / 250]: Loss = 0.0816\n",
      "[10 / 250]: Loss = 0.0664\n",
      "[11 / 250]: Loss = 0.0677\n",
      "[12 / 250]: Loss = 0.0961\n",
      "[13 / 250]: Loss = 0.0724\n",
      "[14 / 250]: Loss = 0.0878\n",
      "[15 / 250]: Loss = 0.0930\n",
      "[16 / 250]: Loss = 0.0608\n",
      "[17 / 250]: Loss = 0.0804\n",
      "[18 / 250]: Loss = 0.0637\n",
      "[19 / 250]: Loss = 0.0719\n",
      "[20 / 250]: Loss = 0.0882\n",
      "[21 / 250]: Loss = 0.0858\n",
      "[22 / 250]: Loss = 0.0850\n",
      "[23 / 250]: Loss = 0.0742\n",
      "[24 / 250]: Loss = 0.0950\n",
      "[25 / 250]: Loss = 0.0809\n",
      "[26 / 250]: Loss = 0.0806\n",
      "[27 / 250]: Loss = 0.0867\n",
      "[28 / 250]: Loss = 0.0762\n",
      "[29 / 250]: Loss = 0.0952\n",
      "[30 / 250]: Loss = 0.0770\n",
      "[31 / 250]: Loss = 0.0813\n",
      "[32 / 250]: Loss = 0.1094\n",
      "[33 / 250]: Loss = 0.0817\n",
      "[34 / 250]: Loss = 0.0823\n",
      "[35 / 250]: Loss = 0.0829\n",
      "[36 / 250]: Loss = 0.0717\n",
      "[37 / 250]: Loss = 0.0895\n",
      "[38 / 250]: Loss = 0.0745\n",
      "[39 / 250]: Loss = 0.0943\n",
      "[40 / 250]: Loss = 0.0850\n",
      "[41 / 250]: Loss = 0.0997\n",
      "[42 / 250]: Loss = 0.0821\n",
      "[43 / 250]: Loss = 0.0871\n",
      "[44 / 250]: Loss = 0.0888\n",
      "[45 / 250]: Loss = 0.0741\n",
      "[46 / 250]: Loss = 0.0914\n",
      "[47 / 250]: Loss = 0.0754\n",
      "[48 / 250]: Loss = 0.0922\n",
      "[49 / 250]: Loss = 0.0682\n",
      "[50 / 250]: Loss = 0.0803\n",
      "[51 / 250]: Loss = 0.0657\n",
      "[52 / 250]: Loss = 0.0787\n",
      "[53 / 250]: Loss = 0.0856\n",
      "[54 / 250]: Loss = 0.0856\n",
      "[55 / 250]: Loss = 0.0773\n",
      "[56 / 250]: Loss = 0.0547\n",
      "[57 / 250]: Loss = 0.0717\n",
      "[58 / 250]: Loss = 0.0825\n",
      "[59 / 250]: Loss = 0.0799\n",
      "[60 / 250]: Loss = 0.0812\n",
      "[61 / 250]: Loss = 0.0697\n",
      "[62 / 250]: Loss = 0.0878\n",
      "[63 / 250]: Loss = 0.0703\n",
      "[64 / 250]: Loss = 0.0793\n",
      "[65 / 250]: Loss = 0.0873\n",
      "[66 / 250]: Loss = 0.0894\n",
      "[67 / 250]: Loss = 0.0768\n",
      "[68 / 250]: Loss = 0.0847\n",
      "[69 / 250]: Loss = 0.0622\n",
      "[70 / 250]: Loss = 0.0572\n",
      "[71 / 250]: Loss = 0.0808\n",
      "[72 / 250]: Loss = 0.0673\n",
      "[73 / 250]: Loss = 0.0883\n",
      "[74 / 250]: Loss = 0.0881\n",
      "[75 / 250]: Loss = 0.0744\n",
      "[76 / 250]: Loss = 0.0630\n",
      "[77 / 250]: Loss = 0.0528\n",
      "[78 / 250]: Loss = 0.0690\n",
      "[79 / 250]: Loss = 0.0801\n",
      "[80 / 250]: Loss = 0.0734\n",
      "[81 / 250]: Loss = 0.0733\n",
      "[82 / 250]: Loss = 0.0746\n",
      "[83 / 250]: Loss = 0.0543\n",
      "[84 / 250]: Loss = 0.0577\n",
      "[85 / 250]: Loss = 0.0630\n",
      "[86 / 250]: Loss = 0.0736\n",
      "[87 / 250]: Loss = 0.0859\n",
      "[88 / 250]: Loss = 0.0792\n",
      "[89 / 250]: Loss = 0.0676\n",
      "[90 / 250]: Loss = 0.0845\n",
      "[91 / 250]: Loss = 0.0766\n",
      "[92 / 250]: Loss = 0.0824\n",
      "[93 / 250]: Loss = 0.0656\n",
      "[94 / 250]: Loss = 0.0708\n",
      "[95 / 250]: Loss = 0.0752\n",
      "[96 / 250]: Loss = 0.0804\n",
      "[97 / 250]: Loss = 0.0662\n",
      "[98 / 250]: Loss = 0.0749\n",
      "[99 / 250]: Loss = 0.0621\n",
      "[100 / 250]: Loss = 0.0831\n",
      "[101 / 250]: Loss = 0.0721\n",
      "[102 / 250]: Loss = 0.0679\n",
      "[103 / 250]: Loss = 0.0623\n",
      "[104 / 250]: Loss = 0.0626\n",
      "[105 / 250]: Loss = 0.0601\n",
      "[106 / 250]: Loss = 0.0761\n",
      "[107 / 250]: Loss = 0.0608\n",
      "[108 / 250]: Loss = 0.0740\n",
      "[109 / 250]: Loss = 0.0628\n",
      "[110 / 250]: Loss = 0.0709\n",
      "[111 / 250]: Loss = 0.0726\n",
      "[112 / 250]: Loss = 0.0731\n",
      "[113 / 250]: Loss = 0.0647\n",
      "[114 / 250]: Loss = 0.0655\n",
      "[115 / 250]: Loss = 0.0728\n",
      "[116 / 250]: Loss = 0.0690\n",
      "[117 / 250]: Loss = 0.0659\n",
      "[118 / 250]: Loss = 0.0536\n",
      "[119 / 250]: Loss = 0.0707\n",
      "[120 / 250]: Loss = 0.0785\n",
      "[121 / 250]: Loss = 0.0648\n",
      "[122 / 250]: Loss = 0.0627\n",
      "[123 / 250]: Loss = 0.0700\n",
      "[124 / 250]: Loss = 0.0737\n",
      "[125 / 250]: Loss = 0.0640\n",
      "[126 / 250]: Loss = 0.0663\n",
      "[127 / 250]: Loss = 0.0747\n",
      "[128 / 250]: Loss = 0.0703\n",
      "[129 / 250]: Loss = 0.0619\n",
      "[130 / 250]: Loss = 0.0720\n",
      "[131 / 250]: Loss = 0.0687\n",
      "[132 / 250]: Loss = 0.0620\n",
      "[133 / 250]: Loss = 0.0616\n",
      "[134 / 250]: Loss = 0.0646\n",
      "[135 / 250]: Loss = 0.0757\n",
      "[136 / 250]: Loss = 0.0875\n",
      "[137 / 250]: Loss = 0.0684\n",
      "[138 / 250]: Loss = 0.0782\n",
      "[139 / 250]: Loss = 0.0740\n",
      "[140 / 250]: Loss = 0.0532\n",
      "[141 / 250]: Loss = 0.0637\n",
      "[142 / 250]: Loss = 0.0818\n",
      "[143 / 250]: Loss = 0.0725\n",
      "[144 / 250]: Loss = 0.0603\n",
      "[145 / 250]: Loss = 0.0637\n",
      "[146 / 250]: Loss = 0.0665\n",
      "[147 / 250]: Loss = 0.0744\n",
      "[148 / 250]: Loss = 0.0621\n",
      "[149 / 250]: Loss = 0.0651\n",
      "[150 / 250]: Loss = 0.0485\n",
      "[151 / 250]: Loss = 0.0663\n",
      "[152 / 250]: Loss = 0.0456\n",
      "[153 / 250]: Loss = 0.0557\n",
      "[154 / 250]: Loss = 0.0657\n",
      "[155 / 250]: Loss = 0.0829\n",
      "[156 / 250]: Loss = 0.0595\n",
      "[157 / 250]: Loss = 0.0532\n",
      "[158 / 250]: Loss = 0.0570\n",
      "[159 / 250]: Loss = 0.0729\n",
      "[160 / 250]: Loss = 0.0784\n",
      "[161 / 250]: Loss = 0.0581\n",
      "[162 / 250]: Loss = 0.0832\n",
      "[163 / 250]: Loss = 0.0695\n",
      "[164 / 250]: Loss = 0.0641\n",
      "[165 / 250]: Loss = 0.0761\n",
      "[166 / 250]: Loss = 0.0751\n",
      "[167 / 250]: Loss = 0.0519\n",
      "[168 / 250]: Loss = 0.0617\n",
      "[169 / 250]: Loss = 0.0796\n",
      "[170 / 250]: Loss = 0.0680\n",
      "[171 / 250]: Loss = 0.0664\n",
      "[172 / 250]: Loss = 0.0488\n",
      "[173 / 250]: Loss = 0.0817\n",
      "[174 / 250]: Loss = 0.0662\n",
      "[175 / 250]: Loss = 0.0748\n",
      "[176 / 250]: Loss = 0.0760\n",
      "[177 / 250]: Loss = 0.0735\n",
      "[178 / 250]: Loss = 0.0637\n",
      "[179 / 250]: Loss = 0.0606\n",
      "[180 / 250]: Loss = 0.0675\n",
      "[181 / 250]: Loss = 0.0537\n",
      "[182 / 250]: Loss = 0.0579\n",
      "[183 / 250]: Loss = 0.0618\n",
      "[184 / 250]: Loss = 0.0695\n",
      "[185 / 250]: Loss = 0.0746\n",
      "[186 / 250]: Loss = 0.0552\n",
      "[187 / 250]: Loss = 0.0522\n",
      "[188 / 250]: Loss = 0.0587\n",
      "[189 / 250]: Loss = 0.0590\n",
      "[190 / 250]: Loss = 0.0589\n",
      "[191 / 250]: Loss = 0.0542\n",
      "[192 / 250]: Loss = 0.0642\n",
      "[193 / 250]: Loss = 0.0585\n",
      "[194 / 250]: Loss = 0.0683\n",
      "[195 / 250]: Loss = 0.0606\n",
      "[196 / 250]: Loss = 0.0711\n",
      "[197 / 250]: Loss = 0.0481\n",
      "[198 / 250]: Loss = 0.0571\n",
      "[199 / 250]: Loss = 0.0591\n",
      "[200 / 250]: Loss = 0.0612\n",
      "[201 / 250]: Loss = 0.0611\n",
      "[202 / 250]: Loss = 0.0611\n",
      "[203 / 250]: Loss = 0.0630\n",
      "[204 / 250]: Loss = 0.0594\n",
      "[205 / 250]: Loss = 0.0678\n",
      "[206 / 250]: Loss = 0.0616\n",
      "[207 / 250]: Loss = 0.0575\n",
      "[208 / 250]: Loss = 0.0570\n",
      "[209 / 250]: Loss = 0.0648\n",
      "[210 / 250]: Loss = 0.0509\n",
      "[211 / 250]: Loss = 0.0611\n",
      "[212 / 250]: Loss = 0.0652\n",
      "[213 / 250]: Loss = 0.0629\n",
      "[214 / 250]: Loss = 0.0691\n",
      "[215 / 250]: Loss = 0.0506\n",
      "[216 / 250]: Loss = 0.0707\n",
      "[217 / 250]: Loss = 0.0653\n",
      "[218 / 250]: Loss = 0.0811\n",
      "[219 / 250]: Loss = 0.0650\n",
      "[220 / 250]: Loss = 0.0619\n",
      "[221 / 250]: Loss = 0.0767\n",
      "[222 / 250]: Loss = 0.0544\n",
      "[223 / 250]: Loss = 0.0747\n",
      "[224 / 250]: Loss = 0.0658\n",
      "[225 / 250]: Loss = 0.0583\n",
      "[226 / 250]: Loss = 0.0658\n",
      "[227 / 250]: Loss = 0.0690\n",
      "[228 / 250]: Loss = 0.0643\n",
      "[229 / 250]: Loss = 0.0626\n",
      "[230 / 250]: Loss = 0.0598\n",
      "[231 / 250]: Loss = 0.0514\n",
      "[232 / 250]: Loss = 0.0603\n",
      "[233 / 250]: Loss = 0.0688\n",
      "[234 / 250]: Loss = 0.0661\n",
      "[235 / 250]: Loss = 0.0512\n",
      "[236 / 250]: Loss = 0.0705\n",
      "[237 / 250]: Loss = 0.0617\n",
      "[238 / 250]: Loss = 0.0675\n",
      "[239 / 250]: Loss = 0.0726\n",
      "[240 / 250]: Loss = 0.0639\n",
      "[241 / 250]: Loss = 0.0670\n",
      "[242 / 250]: Loss = 0.0736\n",
      "[243 / 250]: Loss = 0.0601\n",
      "[244 / 250]: Loss = 0.0615\n",
      "[245 / 250]: Loss = 0.0556\n",
      "[246 / 250]: Loss = 0.0504\n",
      "[247 / 250]: Loss = 0.0561\n",
      "[248 / 250]: Loss = 0.0515\n",
      "[249 / 250]: Loss = 0.0661\n",
      "[0 / 32]: Loss = 0.0614\n",
      "[1 / 32]: Loss = 0.0578\n",
      "[2 / 32]: Loss = 0.0725\n",
      "[3 / 32]: Loss = 0.0744\n",
      "[4 / 32]: Loss = 0.0666\n",
      "[5 / 32]: Loss = 0.0520\n",
      "[6 / 32]: Loss = 0.0713\n",
      "[7 / 32]: Loss = 0.0624\n",
      "[8 / 32]: Loss = 0.0684\n",
      "[9 / 32]: Loss = 0.0615\n",
      "[10 / 32]: Loss = 0.0617\n",
      "[11 / 32]: Loss = 0.0643\n",
      "[12 / 32]: Loss = 0.0600\n",
      "[13 / 32]: Loss = 0.0630\n",
      "[14 / 32]: Loss = 0.0654\n",
      "[15 / 32]: Loss = 0.0629\n",
      "[16 / 32]: Loss = 0.0575\n",
      "[17 / 32]: Loss = 0.0551\n",
      "[18 / 32]: Loss = 0.0630\n",
      "[19 / 32]: Loss = 0.0743\n",
      "[20 / 32]: Loss = 0.0550\n",
      "[21 / 32]: Loss = 0.0581\n",
      "[22 / 32]: Loss = 0.0741\n",
      "[23 / 32]: Loss = 0.0688\n",
      "[24 / 32]: Loss = 0.0563\n",
      "[25 / 32]: Loss = 0.0608\n",
      "[26 / 32]: Loss = 0.0662\n",
      "[27 / 32]: Loss = 0.0593\n",
      "[28 / 32]: Loss = 0.0712\n",
      "[29 / 32]: Loss = 0.0627\n",
      "[30 / 32]: Loss = 0.0660\n",
      "[31 / 32]: Loss = 0.0551\n",
      "Epoch 3 / 10, Epoch Time = 167.61s: Train Loss = 0.0706, Train AUC = 0.9253, Val Loss = 0.0634, Val AUC = 0.9364\n",
      "[0 / 250]: Loss = 0.0508\n",
      "[1 / 250]: Loss = 0.0581\n",
      "[2 / 250]: Loss = 0.0520\n",
      "[3 / 250]: Loss = 0.0524\n",
      "[4 / 250]: Loss = 0.0623\n",
      "[5 / 250]: Loss = 0.0581\n",
      "[6 / 250]: Loss = 0.0600\n",
      "[7 / 250]: Loss = 0.0622\n",
      "[8 / 250]: Loss = 0.0698\n",
      "[9 / 250]: Loss = 0.0666\n",
      "[10 / 250]: Loss = 0.0479\n",
      "[11 / 250]: Loss = 0.0562\n",
      "[12 / 250]: Loss = 0.0526\n",
      "[13 / 250]: Loss = 0.0564\n",
      "[14 / 250]: Loss = 0.0576\n",
      "[15 / 250]: Loss = 0.0613\n",
      "[16 / 250]: Loss = 0.0500\n",
      "[17 / 250]: Loss = 0.0458\n",
      "[18 / 250]: Loss = 0.0622\n",
      "[19 / 250]: Loss = 0.0584\n",
      "[20 / 250]: Loss = 0.0603\n",
      "[21 / 250]: Loss = 0.0636\n",
      "[22 / 250]: Loss = 0.0536\n",
      "[23 / 250]: Loss = 0.0516\n",
      "[24 / 250]: Loss = 0.0466\n",
      "[25 / 250]: Loss = 0.0485\n",
      "[26 / 250]: Loss = 0.0480\n",
      "[27 / 250]: Loss = 0.0559\n",
      "[28 / 250]: Loss = 0.0673\n",
      "[29 / 250]: Loss = 0.0573\n",
      "[30 / 250]: Loss = 0.0664\n",
      "[31 / 250]: Loss = 0.0491\n",
      "[32 / 250]: Loss = 0.0609\n",
      "[33 / 250]: Loss = 0.0624\n",
      "[34 / 250]: Loss = 0.0618\n",
      "[35 / 250]: Loss = 0.0473\n",
      "[36 / 250]: Loss = 0.0544\n",
      "[37 / 250]: Loss = 0.0452\n",
      "[38 / 250]: Loss = 0.0575\n",
      "[39 / 250]: Loss = 0.0621\n",
      "[40 / 250]: Loss = 0.0557\n",
      "[41 / 250]: Loss = 0.0538\n",
      "[42 / 250]: Loss = 0.0509\n",
      "[43 / 250]: Loss = 0.0552\n",
      "[44 / 250]: Loss = 0.0503\n",
      "[45 / 250]: Loss = 0.0462\n",
      "[46 / 250]: Loss = 0.0519\n",
      "[47 / 250]: Loss = 0.0535\n",
      "[48 / 250]: Loss = 0.0575\n",
      "[49 / 250]: Loss = 0.0606\n",
      "[50 / 250]: Loss = 0.0619\n",
      "[51 / 250]: Loss = 0.0587\n",
      "[52 / 250]: Loss = 0.0529\n",
      "[53 / 250]: Loss = 0.0691\n",
      "[54 / 250]: Loss = 0.0436\n",
      "[55 / 250]: Loss = 0.0560\n",
      "[56 / 250]: Loss = 0.0800\n",
      "[57 / 250]: Loss = 0.0554\n",
      "[58 / 250]: Loss = 0.0582\n",
      "[59 / 250]: Loss = 0.0714\n",
      "[60 / 250]: Loss = 0.0552\n",
      "[61 / 250]: Loss = 0.0549\n",
      "[62 / 250]: Loss = 0.0568\n",
      "[63 / 250]: Loss = 0.0568\n",
      "[64 / 250]: Loss = 0.0544\n",
      "[65 / 250]: Loss = 0.0578\n",
      "[66 / 250]: Loss = 0.0475\n",
      "[67 / 250]: Loss = 0.0451\n",
      "[68 / 250]: Loss = 0.0549\n",
      "[69 / 250]: Loss = 0.0487\n",
      "[70 / 250]: Loss = 0.0566\n",
      "[71 / 250]: Loss = 0.0643\n",
      "[72 / 250]: Loss = 0.0550\n",
      "[73 / 250]: Loss = 0.0536\n",
      "[74 / 250]: Loss = 0.0604\n",
      "[75 / 250]: Loss = 0.0527\n",
      "[76 / 250]: Loss = 0.0499\n",
      "[77 / 250]: Loss = 0.0726\n",
      "[78 / 250]: Loss = 0.0575\n",
      "[79 / 250]: Loss = 0.0538\n",
      "[80 / 250]: Loss = 0.0577\n",
      "[81 / 250]: Loss = 0.0529\n",
      "[82 / 250]: Loss = 0.0565\n",
      "[83 / 250]: Loss = 0.0513\n",
      "[84 / 250]: Loss = 0.0650\n",
      "[85 / 250]: Loss = 0.0511\n",
      "[86 / 250]: Loss = 0.0592\n",
      "[87 / 250]: Loss = 0.0462\n",
      "[88 / 250]: Loss = 0.0560\n",
      "[89 / 250]: Loss = 0.0565\n",
      "[90 / 250]: Loss = 0.0586\n",
      "[91 / 250]: Loss = 0.0510\n",
      "[92 / 250]: Loss = 0.0468\n",
      "[93 / 250]: Loss = 0.0501\n",
      "[94 / 250]: Loss = 0.0570\n",
      "[95 / 250]: Loss = 0.0617\n",
      "[96 / 250]: Loss = 0.0642\n",
      "[97 / 250]: Loss = 0.0431\n",
      "[98 / 250]: Loss = 0.0523\n",
      "[99 / 250]: Loss = 0.0472\n",
      "[100 / 250]: Loss = 0.0524\n",
      "[101 / 250]: Loss = 0.0571\n",
      "[102 / 250]: Loss = 0.0511\n",
      "[103 / 250]: Loss = 0.0519\n",
      "[104 / 250]: Loss = 0.0395\n",
      "[105 / 250]: Loss = 0.0504\n",
      "[106 / 250]: Loss = 0.0636\n",
      "[107 / 250]: Loss = 0.0677\n",
      "[108 / 250]: Loss = 0.0583\n",
      "[109 / 250]: Loss = 0.0740\n",
      "[110 / 250]: Loss = 0.0543\n",
      "[111 / 250]: Loss = 0.0462\n",
      "[112 / 250]: Loss = 0.0634\n",
      "[113 / 250]: Loss = 0.0525\n",
      "[114 / 250]: Loss = 0.0645\n",
      "[115 / 250]: Loss = 0.0548\n",
      "[116 / 250]: Loss = 0.0483\n",
      "[117 / 250]: Loss = 0.0528\n",
      "[118 / 250]: Loss = 0.0494\n",
      "[119 / 250]: Loss = 0.0550\n",
      "[120 / 250]: Loss = 0.0528\n",
      "[121 / 250]: Loss = 0.0433\n",
      "[122 / 250]: Loss = 0.0558\n",
      "[123 / 250]: Loss = 0.0514\n",
      "[124 / 250]: Loss = 0.0567\n",
      "[125 / 250]: Loss = 0.0546\n",
      "[126 / 250]: Loss = 0.0616\n",
      "[127 / 250]: Loss = 0.0632\n",
      "[128 / 250]: Loss = 0.0500\n",
      "[129 / 250]: Loss = 0.0447\n",
      "[130 / 250]: Loss = 0.0501\n",
      "[131 / 250]: Loss = 0.0568\n",
      "[132 / 250]: Loss = 0.0581\n",
      "[133 / 250]: Loss = 0.0561\n",
      "[134 / 250]: Loss = 0.0476\n",
      "[135 / 250]: Loss = 0.0686\n",
      "[136 / 250]: Loss = 0.0496\n",
      "[137 / 250]: Loss = 0.0522\n",
      "[138 / 250]: Loss = 0.0550\n",
      "[139 / 250]: Loss = 0.0502\n",
      "[140 / 250]: Loss = 0.0479\n",
      "[141 / 250]: Loss = 0.0526\n",
      "[142 / 250]: Loss = 0.0516\n",
      "[143 / 250]: Loss = 0.0526\n",
      "[144 / 250]: Loss = 0.0595\n",
      "[145 / 250]: Loss = 0.0525\n",
      "[146 / 250]: Loss = 0.0586\n",
      "[147 / 250]: Loss = 0.0572\n",
      "[148 / 250]: Loss = 0.0742\n",
      "[149 / 250]: Loss = 0.0593\n",
      "[150 / 250]: Loss = 0.0521\n",
      "[151 / 250]: Loss = 0.0447\n",
      "[152 / 250]: Loss = 0.0602\n",
      "[153 / 250]: Loss = 0.0525\n",
      "[154 / 250]: Loss = 0.0584\n",
      "[155 / 250]: Loss = 0.0394\n",
      "[156 / 250]: Loss = 0.0627\n",
      "[157 / 250]: Loss = 0.0505\n",
      "[158 / 250]: Loss = 0.0544\n",
      "[159 / 250]: Loss = 0.0562\n",
      "[160 / 250]: Loss = 0.0450\n",
      "[161 / 250]: Loss = 0.0605\n",
      "[162 / 250]: Loss = 0.0558\n",
      "[163 / 250]: Loss = 0.0550\n",
      "[164 / 250]: Loss = 0.0455\n",
      "[165 / 250]: Loss = 0.0507\n",
      "[166 / 250]: Loss = 0.0560\n",
      "[167 / 250]: Loss = 0.0538\n",
      "[168 / 250]: Loss = 0.0479\n",
      "[169 / 250]: Loss = 0.0526\n",
      "[170 / 250]: Loss = 0.0637\n",
      "[171 / 250]: Loss = 0.0478\n",
      "[172 / 250]: Loss = 0.0632\n",
      "[173 / 250]: Loss = 0.0644\n",
      "[174 / 250]: Loss = 0.0543\n",
      "[175 / 250]: Loss = 0.0596\n",
      "[176 / 250]: Loss = 0.0563\n",
      "[177 / 250]: Loss = 0.0600\n",
      "[178 / 250]: Loss = 0.0547\n",
      "[179 / 250]: Loss = 0.0507\n",
      "[180 / 250]: Loss = 0.0509\n",
      "[181 / 250]: Loss = 0.0717\n",
      "[182 / 250]: Loss = 0.0580\n",
      "[183 / 250]: Loss = 0.0468\n",
      "[184 / 250]: Loss = 0.0526\n",
      "[185 / 250]: Loss = 0.0540\n",
      "[186 / 250]: Loss = 0.0551\n",
      "[187 / 250]: Loss = 0.0504\n",
      "[188 / 250]: Loss = 0.0535\n",
      "[189 / 250]: Loss = 0.0414\n",
      "[190 / 250]: Loss = 0.0506\n",
      "[191 / 250]: Loss = 0.0555\n",
      "[192 / 250]: Loss = 0.0585\n",
      "[193 / 250]: Loss = 0.0571\n",
      "[194 / 250]: Loss = 0.0493\n",
      "[195 / 250]: Loss = 0.0557\n",
      "[196 / 250]: Loss = 0.0418\n",
      "[197 / 250]: Loss = 0.0555\n",
      "[198 / 250]: Loss = 0.0575\n",
      "[199 / 250]: Loss = 0.0615\n",
      "[200 / 250]: Loss = 0.0535\n",
      "[201 / 250]: Loss = 0.0499\n",
      "[202 / 250]: Loss = 0.0502\n",
      "[203 / 250]: Loss = 0.0440\n",
      "[204 / 250]: Loss = 0.0462\n",
      "[205 / 250]: Loss = 0.0365\n",
      "[206 / 250]: Loss = 0.0566\n",
      "[207 / 250]: Loss = 0.0462\n",
      "[208 / 250]: Loss = 0.0420\n",
      "[209 / 250]: Loss = 0.0451\n",
      "[210 / 250]: Loss = 0.0449\n",
      "[211 / 250]: Loss = 0.0459\n",
      "[212 / 250]: Loss = 0.0456\n",
      "[213 / 250]: Loss = 0.0686\n",
      "[214 / 250]: Loss = 0.0453\n",
      "[215 / 250]: Loss = 0.0556\n",
      "[216 / 250]: Loss = 0.0488\n",
      "[217 / 250]: Loss = 0.0557\n",
      "[218 / 250]: Loss = 0.0483\n",
      "[219 / 250]: Loss = 0.0602\n",
      "[220 / 250]: Loss = 0.0435\n",
      "[221 / 250]: Loss = 0.0414\n",
      "[222 / 250]: Loss = 0.0486\n",
      "[223 / 250]: Loss = 0.0506\n",
      "[224 / 250]: Loss = 0.0482\n",
      "[225 / 250]: Loss = 0.0553\n",
      "[226 / 250]: Loss = 0.0475\n",
      "[227 / 250]: Loss = 0.0379\n",
      "[228 / 250]: Loss = 0.0417\n",
      "[229 / 250]: Loss = 0.0499\n",
      "[230 / 250]: Loss = 0.0733\n",
      "[231 / 250]: Loss = 0.0513\n",
      "[232 / 250]: Loss = 0.0393\n",
      "[233 / 250]: Loss = 0.0652\n",
      "[234 / 250]: Loss = 0.0547\n",
      "[235 / 250]: Loss = 0.0651\n",
      "[236 / 250]: Loss = 0.0484\n",
      "[237 / 250]: Loss = 0.0477\n",
      "[238 / 250]: Loss = 0.0521\n",
      "[239 / 250]: Loss = 0.0648\n",
      "[240 / 250]: Loss = 0.0496\n",
      "[241 / 250]: Loss = 0.0600\n",
      "[242 / 250]: Loss = 0.0488\n",
      "[243 / 250]: Loss = 0.0613\n",
      "[244 / 250]: Loss = 0.0519\n",
      "[245 / 250]: Loss = 0.0508\n",
      "[246 / 250]: Loss = 0.0480\n",
      "[247 / 250]: Loss = 0.0586\n",
      "[248 / 250]: Loss = 0.0439\n",
      "[249 / 250]: Loss = 0.0441\n",
      "[0 / 32]: Loss = 0.0569\n",
      "[1 / 32]: Loss = 0.0480\n",
      "[2 / 32]: Loss = 0.0551\n",
      "[3 / 32]: Loss = 0.0467\n",
      "[4 / 32]: Loss = 0.0564\n",
      "[5 / 32]: Loss = 0.0624\n",
      "[6 / 32]: Loss = 0.0538\n",
      "[7 / 32]: Loss = 0.0575\n",
      "[8 / 32]: Loss = 0.0515\n",
      "[9 / 32]: Loss = 0.0640\n",
      "[10 / 32]: Loss = 0.0478\n",
      "[11 / 32]: Loss = 0.0553\n",
      "[12 / 32]: Loss = 0.0532\n",
      "[13 / 32]: Loss = 0.0666\n",
      "[14 / 32]: Loss = 0.0636\n",
      "[15 / 32]: Loss = 0.0495\n",
      "[16 / 32]: Loss = 0.0580\n",
      "[17 / 32]: Loss = 0.0565\n",
      "[18 / 32]: Loss = 0.0533\n",
      "[19 / 32]: Loss = 0.0617\n",
      "[20 / 32]: Loss = 0.0578\n",
      "[21 / 32]: Loss = 0.0562\n",
      "[22 / 32]: Loss = 0.0559\n",
      "[23 / 32]: Loss = 0.0550\n",
      "[24 / 32]: Loss = 0.0611\n",
      "[25 / 32]: Loss = 0.0613\n",
      "[26 / 32]: Loss = 0.0542\n",
      "[27 / 32]: Loss = 0.0550\n",
      "[28 / 32]: Loss = 0.0548\n",
      "[29 / 32]: Loss = 0.0538\n",
      "[30 / 32]: Loss = 0.0564\n",
      "[31 / 32]: Loss = 0.0574\n",
      "Epoch 4 / 10, Epoch Time = 167.77s: Train Loss = 0.0543, Train AUC = 0.9591, Val Loss = 0.0561, Val AUC = 0.9605\n",
      "[0 / 250]: Loss = 0.0425\n",
      "[1 / 250]: Loss = 0.0623\n",
      "[2 / 250]: Loss = 0.0483\n",
      "[3 / 250]: Loss = 0.0671\n",
      "[4 / 250]: Loss = 0.0475\n",
      "[5 / 250]: Loss = 0.0420\n",
      "[6 / 250]: Loss = 0.0547\n",
      "[7 / 250]: Loss = 0.0555\n",
      "[8 / 250]: Loss = 0.0507\n",
      "[9 / 250]: Loss = 0.0518\n",
      "[10 / 250]: Loss = 0.0535\n",
      "[11 / 250]: Loss = 0.0616\n",
      "[12 / 250]: Loss = 0.0589\n",
      "[13 / 250]: Loss = 0.0373\n",
      "[14 / 250]: Loss = 0.0563\n",
      "[15 / 250]: Loss = 0.0393\n",
      "[16 / 250]: Loss = 0.0468\n",
      "[17 / 250]: Loss = 0.0490\n",
      "[18 / 250]: Loss = 0.0500\n",
      "[19 / 250]: Loss = 0.0411\n",
      "[20 / 250]: Loss = 0.0390\n",
      "[21 / 250]: Loss = 0.0586\n",
      "[22 / 250]: Loss = 0.0411\n",
      "[23 / 250]: Loss = 0.0467\n",
      "[24 / 250]: Loss = 0.0409\n",
      "[25 / 250]: Loss = 0.0490\n",
      "[26 / 250]: Loss = 0.0463\n",
      "[27 / 250]: Loss = 0.0417\n",
      "[28 / 250]: Loss = 0.0545\n",
      "[29 / 250]: Loss = 0.0505\n",
      "[30 / 250]: Loss = 0.0465\n",
      "[31 / 250]: Loss = 0.0418\n",
      "[32 / 250]: Loss = 0.0491\n",
      "[33 / 250]: Loss = 0.0415\n",
      "[34 / 250]: Loss = 0.0458\n",
      "[35 / 250]: Loss = 0.0453\n",
      "[36 / 250]: Loss = 0.0343\n",
      "[37 / 250]: Loss = 0.0506\n",
      "[38 / 250]: Loss = 0.0587\n",
      "[39 / 250]: Loss = 0.0567\n",
      "[40 / 250]: Loss = 0.0519\n",
      "[41 / 250]: Loss = 0.0584\n",
      "[42 / 250]: Loss = 0.0397\n",
      "[43 / 250]: Loss = 0.0437\n",
      "[44 / 250]: Loss = 0.0542\n",
      "[45 / 250]: Loss = 0.0556\n",
      "[46 / 250]: Loss = 0.0466\n",
      "[47 / 250]: Loss = 0.0502\n",
      "[48 / 250]: Loss = 0.0501\n",
      "[49 / 250]: Loss = 0.0456\n",
      "[50 / 250]: Loss = 0.0415\n",
      "[51 / 250]: Loss = 0.0443\n",
      "[52 / 250]: Loss = 0.0508\n",
      "[53 / 250]: Loss = 0.0362\n",
      "[54 / 250]: Loss = 0.0513\n",
      "[55 / 250]: Loss = 0.0322\n",
      "[56 / 250]: Loss = 0.0461\n",
      "[57 / 250]: Loss = 0.0465\n",
      "[58 / 250]: Loss = 0.0494\n",
      "[59 / 250]: Loss = 0.0586\n",
      "[60 / 250]: Loss = 0.0556\n",
      "[61 / 250]: Loss = 0.0542\n",
      "[62 / 250]: Loss = 0.0535\n",
      "[63 / 250]: Loss = 0.0438\n",
      "[64 / 250]: Loss = 0.0438\n",
      "[65 / 250]: Loss = 0.0400\n",
      "[66 / 250]: Loss = 0.0468\n",
      "[67 / 250]: Loss = 0.0512\n",
      "[68 / 250]: Loss = 0.0455\n",
      "[69 / 250]: Loss = 0.0442\n",
      "[70 / 250]: Loss = 0.0541\n",
      "[71 / 250]: Loss = 0.0553\n",
      "[72 / 250]: Loss = 0.0459\n",
      "[73 / 250]: Loss = 0.0482\n",
      "[74 / 250]: Loss = 0.0496\n",
      "[75 / 250]: Loss = 0.0456\n",
      "[76 / 250]: Loss = 0.0459\n",
      "[77 / 250]: Loss = 0.0422\n",
      "[78 / 250]: Loss = 0.0497\n",
      "[79 / 250]: Loss = 0.0512\n",
      "[80 / 250]: Loss = 0.0506\n",
      "[81 / 250]: Loss = 0.0487\n",
      "[82 / 250]: Loss = 0.0522\n",
      "[83 / 250]: Loss = 0.0490\n",
      "[84 / 250]: Loss = 0.0490\n",
      "[85 / 250]: Loss = 0.0459\n",
      "[86 / 250]: Loss = 0.0537\n",
      "[87 / 250]: Loss = 0.0597\n",
      "[88 / 250]: Loss = 0.0472\n",
      "[89 / 250]: Loss = 0.0558\n",
      "[90 / 250]: Loss = 0.0479\n",
      "[91 / 250]: Loss = 0.0358\n",
      "[92 / 250]: Loss = 0.0444\n",
      "[93 / 250]: Loss = 0.0446\n",
      "[94 / 250]: Loss = 0.0461\n",
      "[95 / 250]: Loss = 0.0432\n",
      "[96 / 250]: Loss = 0.0527\n",
      "[97 / 250]: Loss = 0.0544\n",
      "[98 / 250]: Loss = 0.0468\n",
      "[99 / 250]: Loss = 0.0614\n",
      "[100 / 250]: Loss = 0.0545\n",
      "[101 / 250]: Loss = 0.0451\n",
      "[102 / 250]: Loss = 0.0566\n",
      "[103 / 250]: Loss = 0.0519\n",
      "[104 / 250]: Loss = 0.0448\n",
      "[105 / 250]: Loss = 0.0501\n",
      "[106 / 250]: Loss = 0.0483\n",
      "[107 / 250]: Loss = 0.0466\n",
      "[108 / 250]: Loss = 0.0448\n",
      "[109 / 250]: Loss = 0.0511\n",
      "[110 / 250]: Loss = 0.0379\n",
      "[111 / 250]: Loss = 0.0538\n",
      "[112 / 250]: Loss = 0.0585\n",
      "[113 / 250]: Loss = 0.0471\n",
      "[114 / 250]: Loss = 0.0492\n",
      "[115 / 250]: Loss = 0.0540\n",
      "[116 / 250]: Loss = 0.0371\n",
      "[117 / 250]: Loss = 0.0557\n",
      "[118 / 250]: Loss = 0.0419\n",
      "[119 / 250]: Loss = 0.0521\n",
      "[120 / 250]: Loss = 0.0461\n",
      "[121 / 250]: Loss = 0.0387\n",
      "[122 / 250]: Loss = 0.0460\n",
      "[123 / 250]: Loss = 0.0371\n",
      "[124 / 250]: Loss = 0.0323\n",
      "[125 / 250]: Loss = 0.0495\n",
      "[126 / 250]: Loss = 0.0371\n",
      "[127 / 250]: Loss = 0.0544\n",
      "[128 / 250]: Loss = 0.0540\n",
      "[129 / 250]: Loss = 0.0567\n",
      "[130 / 250]: Loss = 0.0428\n",
      "[131 / 250]: Loss = 0.0484\n",
      "[132 / 250]: Loss = 0.0545\n",
      "[133 / 250]: Loss = 0.0508\n",
      "[134 / 250]: Loss = 0.0479\n",
      "[135 / 250]: Loss = 0.0531\n",
      "[136 / 250]: Loss = 0.0451\n",
      "[137 / 250]: Loss = 0.0534\n",
      "[138 / 250]: Loss = 0.0527\n",
      "[139 / 250]: Loss = 0.0439\n",
      "[140 / 250]: Loss = 0.0409\n",
      "[141 / 250]: Loss = 0.0378\n",
      "[142 / 250]: Loss = 0.0461\n",
      "[143 / 250]: Loss = 0.0406\n",
      "[144 / 250]: Loss = 0.0429\n",
      "[145 / 250]: Loss = 0.0553\n",
      "[146 / 250]: Loss = 0.0511\n",
      "[147 / 250]: Loss = 0.0395\n",
      "[148 / 250]: Loss = 0.0520\n",
      "[149 / 250]: Loss = 0.0515\n",
      "[150 / 250]: Loss = 0.0576\n",
      "[151 / 250]: Loss = 0.0345\n",
      "[152 / 250]: Loss = 0.0534\n",
      "[153 / 250]: Loss = 0.0405\n",
      "[154 / 250]: Loss = 0.0489\n",
      "[155 / 250]: Loss = 0.0586\n",
      "[156 / 250]: Loss = 0.0468\n",
      "[157 / 250]: Loss = 0.0397\n",
      "[158 / 250]: Loss = 0.0440\n",
      "[159 / 250]: Loss = 0.0494\n",
      "[160 / 250]: Loss = 0.0436\n",
      "[161 / 250]: Loss = 0.0503\n",
      "[162 / 250]: Loss = 0.0461\n",
      "[163 / 250]: Loss = 0.0372\n",
      "[164 / 250]: Loss = 0.0428\n",
      "[165 / 250]: Loss = 0.0456\n",
      "[166 / 250]: Loss = 0.0483\n",
      "[167 / 250]: Loss = 0.0394\n",
      "[168 / 250]: Loss = 0.0453\n",
      "[169 / 250]: Loss = 0.0536\n",
      "[170 / 250]: Loss = 0.0417\n",
      "[171 / 250]: Loss = 0.0366\n",
      "[172 / 250]: Loss = 0.0481\n",
      "[173 / 250]: Loss = 0.0325\n",
      "[174 / 250]: Loss = 0.0465\n",
      "[175 / 250]: Loss = 0.0474\n",
      "[176 / 250]: Loss = 0.0582\n",
      "[177 / 250]: Loss = 0.0497\n",
      "[178 / 250]: Loss = 0.0477\n",
      "[179 / 250]: Loss = 0.0490\n",
      "[180 / 250]: Loss = 0.0404\n",
      "[181 / 250]: Loss = 0.0535\n",
      "[182 / 250]: Loss = 0.0410\n",
      "[183 / 250]: Loss = 0.0536\n",
      "[184 / 250]: Loss = 0.0447\n",
      "[185 / 250]: Loss = 0.0465\n",
      "[186 / 250]: Loss = 0.0478\n",
      "[187 / 250]: Loss = 0.0486\n",
      "[188 / 250]: Loss = 0.0565\n",
      "[189 / 250]: Loss = 0.0453\n",
      "[190 / 250]: Loss = 0.0467\n",
      "[191 / 250]: Loss = 0.0616\n",
      "[192 / 250]: Loss = 0.0429\n",
      "[193 / 250]: Loss = 0.0416\n",
      "[194 / 250]: Loss = 0.0488\n",
      "[195 / 250]: Loss = 0.0487\n",
      "[196 / 250]: Loss = 0.0360\n",
      "[197 / 250]: Loss = 0.0408\n",
      "[198 / 250]: Loss = 0.0445\n",
      "[199 / 250]: Loss = 0.0454\n",
      "[200 / 250]: Loss = 0.0443\n",
      "[201 / 250]: Loss = 0.0370\n",
      "[202 / 250]: Loss = 0.0408\n",
      "[203 / 250]: Loss = 0.0434\n",
      "[204 / 250]: Loss = 0.0476\n",
      "[205 / 250]: Loss = 0.0417\n",
      "[206 / 250]: Loss = 0.0530\n",
      "[207 / 250]: Loss = 0.0431\n",
      "[208 / 250]: Loss = 0.0552\n",
      "[209 / 250]: Loss = 0.0578\n",
      "[210 / 250]: Loss = 0.0478\n",
      "[211 / 250]: Loss = 0.0364\n",
      "[212 / 250]: Loss = 0.0401\n",
      "[213 / 250]: Loss = 0.0437\n",
      "[214 / 250]: Loss = 0.0528\n",
      "[215 / 250]: Loss = 0.0381\n",
      "[216 / 250]: Loss = 0.0412\n",
      "[217 / 250]: Loss = 0.0461\n",
      "[218 / 250]: Loss = 0.0373\n",
      "[219 / 250]: Loss = 0.0358\n",
      "[220 / 250]: Loss = 0.0530\n",
      "[221 / 250]: Loss = 0.0523\n",
      "[222 / 250]: Loss = 0.0408\n",
      "[223 / 250]: Loss = 0.0445\n",
      "[224 / 250]: Loss = 0.0515\n",
      "[225 / 250]: Loss = 0.0552\n",
      "[226 / 250]: Loss = 0.0458\n",
      "[227 / 250]: Loss = 0.0678\n",
      "[228 / 250]: Loss = 0.0497\n",
      "[229 / 250]: Loss = 0.0540\n",
      "[230 / 250]: Loss = 0.0532\n",
      "[231 / 250]: Loss = 0.0421\n",
      "[232 / 250]: Loss = 0.0484\n",
      "[233 / 250]: Loss = 0.0363\n",
      "[234 / 250]: Loss = 0.0456\n",
      "[235 / 250]: Loss = 0.0426\n",
      "[236 / 250]: Loss = 0.0567\n",
      "[237 / 250]: Loss = 0.0465\n",
      "[238 / 250]: Loss = 0.0497\n",
      "[239 / 250]: Loss = 0.0483\n",
      "[240 / 250]: Loss = 0.0544\n",
      "[241 / 250]: Loss = 0.0413\n",
      "[242 / 250]: Loss = 0.0355\n",
      "[243 / 250]: Loss = 0.0353\n",
      "[244 / 250]: Loss = 0.0453\n",
      "[245 / 250]: Loss = 0.0462\n",
      "[246 / 250]: Loss = 0.0454\n",
      "[247 / 250]: Loss = 0.0434\n",
      "[248 / 250]: Loss = 0.0469\n",
      "[249 / 250]: Loss = 0.0637\n",
      "[0 / 32]: Loss = 0.0458\n",
      "[1 / 32]: Loss = 0.0599\n",
      "[2 / 32]: Loss = 0.0570\n",
      "[3 / 32]: Loss = 0.0566\n",
      "[4 / 32]: Loss = 0.0492\n",
      "[5 / 32]: Loss = 0.0634\n",
      "[6 / 32]: Loss = 0.0568\n",
      "[7 / 32]: Loss = 0.0545\n",
      "[8 / 32]: Loss = 0.0450\n",
      "[9 / 32]: Loss = 0.0565\n",
      "[10 / 32]: Loss = 0.0519\n",
      "[11 / 32]: Loss = 0.0433\n",
      "[12 / 32]: Loss = 0.0542\n",
      "[13 / 32]: Loss = 0.0563\n",
      "[14 / 32]: Loss = 0.0565\n",
      "[15 / 32]: Loss = 0.0546\n",
      "[16 / 32]: Loss = 0.0550\n",
      "[17 / 32]: Loss = 0.0422\n",
      "[18 / 32]: Loss = 0.0474\n",
      "[19 / 32]: Loss = 0.0503\n",
      "[20 / 32]: Loss = 0.0506\n",
      "[21 / 32]: Loss = 0.0547\n",
      "[22 / 32]: Loss = 0.0539\n",
      "[23 / 32]: Loss = 0.0460\n",
      "[24 / 32]: Loss = 0.0640\n",
      "[25 / 32]: Loss = 0.0548\n",
      "[26 / 32]: Loss = 0.0571\n",
      "[27 / 32]: Loss = 0.0584\n",
      "[28 / 32]: Loss = 0.0480\n",
      "[29 / 32]: Loss = 0.0549\n",
      "[30 / 32]: Loss = 0.0497\n",
      "[31 / 32]: Loss = 0.0473\n",
      "Epoch 5 / 10, Epoch Time = 167.72s: Train Loss = 0.0476, Train AUC = 0.9724, Val Loss = 0.0530, Val AUC = 0.9680\n",
      "[0 / 250]: Loss = 0.0532\n",
      "[1 / 250]: Loss = 0.0436\n",
      "[2 / 250]: Loss = 0.0430\n",
      "[3 / 250]: Loss = 0.0479\n",
      "[4 / 250]: Loss = 0.0638\n",
      "[5 / 250]: Loss = 0.0426\n",
      "[6 / 250]: Loss = 0.0326\n",
      "[7 / 250]: Loss = 0.0500\n",
      "[8 / 250]: Loss = 0.0357\n",
      "[9 / 250]: Loss = 0.0519\n",
      "[10 / 250]: Loss = 0.0376\n",
      "[11 / 250]: Loss = 0.0435\n",
      "[12 / 250]: Loss = 0.0437\n",
      "[13 / 250]: Loss = 0.0414\n",
      "[14 / 250]: Loss = 0.0502\n",
      "[15 / 250]: Loss = 0.0425\n",
      "[16 / 250]: Loss = 0.0436\n",
      "[17 / 250]: Loss = 0.0530\n",
      "[18 / 250]: Loss = 0.0375\n",
      "[19 / 250]: Loss = 0.0329\n",
      "[20 / 250]: Loss = 0.0429\n",
      "[21 / 250]: Loss = 0.0441\n",
      "[22 / 250]: Loss = 0.0319\n",
      "[23 / 250]: Loss = 0.0367\n",
      "[24 / 250]: Loss = 0.0507\n",
      "[25 / 250]: Loss = 0.0360\n",
      "[26 / 250]: Loss = 0.0465\n",
      "[27 / 250]: Loss = 0.0330\n",
      "[28 / 250]: Loss = 0.0484\n",
      "[29 / 250]: Loss = 0.0438\n",
      "[30 / 250]: Loss = 0.0388\n",
      "[31 / 250]: Loss = 0.0453\n",
      "[32 / 250]: Loss = 0.0466\n",
      "[33 / 250]: Loss = 0.0302\n",
      "[34 / 250]: Loss = 0.0478\n",
      "[35 / 250]: Loss = 0.0490\n",
      "[36 / 250]: Loss = 0.0446\n",
      "[37 / 250]: Loss = 0.0400\n",
      "[38 / 250]: Loss = 0.0381\n",
      "[39 / 250]: Loss = 0.0466\n",
      "[40 / 250]: Loss = 0.0456\n",
      "[41 / 250]: Loss = 0.0500\n",
      "[42 / 250]: Loss = 0.0459\n",
      "[43 / 250]: Loss = 0.0459\n",
      "[44 / 250]: Loss = 0.0441\n",
      "[45 / 250]: Loss = 0.0357\n",
      "[46 / 250]: Loss = 0.0420\n",
      "[47 / 250]: Loss = 0.0482\n",
      "[48 / 250]: Loss = 0.0416\n",
      "[49 / 250]: Loss = 0.0385\n",
      "[50 / 250]: Loss = 0.0491\n",
      "[51 / 250]: Loss = 0.0436\n",
      "[52 / 250]: Loss = 0.0517\n",
      "[53 / 250]: Loss = 0.0442\n",
      "[54 / 250]: Loss = 0.0414\n",
      "[55 / 250]: Loss = 0.0435\n",
      "[56 / 250]: Loss = 0.0434\n",
      "[57 / 250]: Loss = 0.0335\n",
      "[58 / 250]: Loss = 0.0393\n",
      "[59 / 250]: Loss = 0.0542\n",
      "[60 / 250]: Loss = 0.0465\n",
      "[61 / 250]: Loss = 0.0434\n",
      "[62 / 250]: Loss = 0.0398\n",
      "[63 / 250]: Loss = 0.0521\n",
      "[64 / 250]: Loss = 0.0455\n",
      "[65 / 250]: Loss = 0.0446\n",
      "[66 / 250]: Loss = 0.0336\n",
      "[67 / 250]: Loss = 0.0505\n",
      "[68 / 250]: Loss = 0.0397\n",
      "[69 / 250]: Loss = 0.0398\n",
      "[70 / 250]: Loss = 0.0472\n",
      "[71 / 250]: Loss = 0.0444\n",
      "[72 / 250]: Loss = 0.0419\n",
      "[73 / 250]: Loss = 0.0527\n",
      "[74 / 250]: Loss = 0.0490\n",
      "[75 / 250]: Loss = 0.0428\n",
      "[76 / 250]: Loss = 0.0376\n",
      "[77 / 250]: Loss = 0.0518\n",
      "[78 / 250]: Loss = 0.0460\n",
      "[79 / 250]: Loss = 0.0393\n",
      "[80 / 250]: Loss = 0.0443\n",
      "[81 / 250]: Loss = 0.0284\n",
      "[82 / 250]: Loss = 0.0498\n",
      "[83 / 250]: Loss = 0.0463\n",
      "[84 / 250]: Loss = 0.0370\n",
      "[85 / 250]: Loss = 0.0282\n",
      "[86 / 250]: Loss = 0.0428\n",
      "[87 / 250]: Loss = 0.0387\n",
      "[88 / 250]: Loss = 0.0506\n",
      "[89 / 250]: Loss = 0.0495\n",
      "[90 / 250]: Loss = 0.0515\n",
      "[91 / 250]: Loss = 0.0514\n",
      "[92 / 250]: Loss = 0.0485\n",
      "[93 / 250]: Loss = 0.0367\n",
      "[94 / 250]: Loss = 0.0454\n",
      "[95 / 250]: Loss = 0.0375\n",
      "[96 / 250]: Loss = 0.0444\n",
      "[97 / 250]: Loss = 0.0378\n",
      "[98 / 250]: Loss = 0.0435\n",
      "[99 / 250]: Loss = 0.0489\n",
      "[100 / 250]: Loss = 0.0524\n",
      "[101 / 250]: Loss = 0.0474\n",
      "[102 / 250]: Loss = 0.0425\n",
      "[103 / 250]: Loss = 0.0426\n",
      "[104 / 250]: Loss = 0.0406\n",
      "[105 / 250]: Loss = 0.0375\n",
      "[106 / 250]: Loss = 0.0427\n",
      "[107 / 250]: Loss = 0.0461\n",
      "[108 / 250]: Loss = 0.0437\n",
      "[109 / 250]: Loss = 0.0436\n",
      "[110 / 250]: Loss = 0.0474\n",
      "[111 / 250]: Loss = 0.0516\n",
      "[112 / 250]: Loss = 0.0393\n",
      "[113 / 250]: Loss = 0.0428\n",
      "[114 / 250]: Loss = 0.0435\n",
      "[115 / 250]: Loss = 0.0459\n",
      "[116 / 250]: Loss = 0.0434\n",
      "[117 / 250]: Loss = 0.0455\n",
      "[118 / 250]: Loss = 0.0467\n",
      "[119 / 250]: Loss = 0.0403\n",
      "[120 / 250]: Loss = 0.0454\n",
      "[121 / 250]: Loss = 0.0353\n",
      "[122 / 250]: Loss = 0.0426\n",
      "[123 / 250]: Loss = 0.0422\n",
      "[124 / 250]: Loss = 0.0407\n",
      "[125 / 250]: Loss = 0.0418\n",
      "[126 / 250]: Loss = 0.0499\n",
      "[127 / 250]: Loss = 0.0363\n",
      "[128 / 250]: Loss = 0.0426\n",
      "[129 / 250]: Loss = 0.0372\n",
      "[130 / 250]: Loss = 0.0416\n",
      "[131 / 250]: Loss = 0.0455\n",
      "[132 / 250]: Loss = 0.0381\n",
      "[133 / 250]: Loss = 0.0383\n",
      "[134 / 250]: Loss = 0.0433\n",
      "[135 / 250]: Loss = 0.0415\n",
      "[136 / 250]: Loss = 0.0451\n",
      "[137 / 250]: Loss = 0.0499\n",
      "[138 / 250]: Loss = 0.0412\n",
      "[139 / 250]: Loss = 0.0456\n",
      "[140 / 250]: Loss = 0.0409\n",
      "[141 / 250]: Loss = 0.0423\n",
      "[142 / 250]: Loss = 0.0484\n",
      "[143 / 250]: Loss = 0.0402\n",
      "[144 / 250]: Loss = 0.0398\n",
      "[145 / 250]: Loss = 0.0483\n",
      "[146 / 250]: Loss = 0.0408\n",
      "[147 / 250]: Loss = 0.0422\n",
      "[148 / 250]: Loss = 0.0516\n",
      "[149 / 250]: Loss = 0.0508\n",
      "[150 / 250]: Loss = 0.0334\n",
      "[151 / 250]: Loss = 0.0396\n",
      "[152 / 250]: Loss = 0.0443\n",
      "[153 / 250]: Loss = 0.0503\n",
      "[154 / 250]: Loss = 0.0327\n",
      "[155 / 250]: Loss = 0.0515\n",
      "[156 / 250]: Loss = 0.0400\n",
      "[157 / 250]: Loss = 0.0336\n",
      "[158 / 250]: Loss = 0.0449\n",
      "[159 / 250]: Loss = 0.0452\n",
      "[160 / 250]: Loss = 0.0372\n",
      "[161 / 250]: Loss = 0.0458\n",
      "[162 / 250]: Loss = 0.0380\n",
      "[163 / 250]: Loss = 0.0377\n",
      "[164 / 250]: Loss = 0.0467\n",
      "[165 / 250]: Loss = 0.0381\n",
      "[166 / 250]: Loss = 0.0500\n",
      "[167 / 250]: Loss = 0.0447\n",
      "[168 / 250]: Loss = 0.0410\n",
      "[169 / 250]: Loss = 0.0370\n",
      "[170 / 250]: Loss = 0.0472\n",
      "[171 / 250]: Loss = 0.0489\n",
      "[172 / 250]: Loss = 0.0405\n",
      "[173 / 250]: Loss = 0.0505\n",
      "[174 / 250]: Loss = 0.0409\n",
      "[175 / 250]: Loss = 0.0426\n",
      "[176 / 250]: Loss = 0.0438\n",
      "[177 / 250]: Loss = 0.0413\n",
      "[178 / 250]: Loss = 0.0295\n",
      "[179 / 250]: Loss = 0.0432\n",
      "[180 / 250]: Loss = 0.0485\n",
      "[181 / 250]: Loss = 0.0409\n",
      "[182 / 250]: Loss = 0.0345\n",
      "[183 / 250]: Loss = 0.0430\n",
      "[184 / 250]: Loss = 0.0353\n",
      "[185 / 250]: Loss = 0.0466\n",
      "[186 / 250]: Loss = 0.0375\n",
      "[187 / 250]: Loss = 0.0370\n",
      "[188 / 250]: Loss = 0.0354\n",
      "[189 / 250]: Loss = 0.0423\n",
      "[190 / 250]: Loss = 0.0340\n",
      "[191 / 250]: Loss = 0.0381\n",
      "[192 / 250]: Loss = 0.0543\n",
      "[193 / 250]: Loss = 0.0266\n",
      "[194 / 250]: Loss = 0.0517\n",
      "[195 / 250]: Loss = 0.0356\n",
      "[196 / 250]: Loss = 0.0485\n",
      "[197 / 250]: Loss = 0.0459\n",
      "[198 / 250]: Loss = 0.0508\n",
      "[199 / 250]: Loss = 0.0423\n",
      "[200 / 250]: Loss = 0.0410\n",
      "[201 / 250]: Loss = 0.0540\n",
      "[202 / 250]: Loss = 0.0401\n",
      "[203 / 250]: Loss = 0.0535\n",
      "[204 / 250]: Loss = 0.0512\n",
      "[205 / 250]: Loss = 0.0313\n",
      "[206 / 250]: Loss = 0.0415\n",
      "[207 / 250]: Loss = 0.0443\n",
      "[208 / 250]: Loss = 0.0358\n",
      "[209 / 250]: Loss = 0.0383\n",
      "[210 / 250]: Loss = 0.0489\n",
      "[211 / 250]: Loss = 0.0414\n",
      "[212 / 250]: Loss = 0.0450\n",
      "[213 / 250]: Loss = 0.0466\n",
      "[214 / 250]: Loss = 0.0271\n",
      "[215 / 250]: Loss = 0.0318\n",
      "[216 / 250]: Loss = 0.0444\n",
      "[217 / 250]: Loss = 0.0378\n",
      "[218 / 250]: Loss = 0.0534\n",
      "[219 / 250]: Loss = 0.0511\n",
      "[220 / 250]: Loss = 0.0496\n",
      "[221 / 250]: Loss = 0.0399\n",
      "[222 / 250]: Loss = 0.0452\n",
      "[223 / 250]: Loss = 0.0402\n",
      "[224 / 250]: Loss = 0.0377\n",
      "[225 / 250]: Loss = 0.0380\n",
      "[226 / 250]: Loss = 0.0283\n",
      "[227 / 250]: Loss = 0.0426\n",
      "[228 / 250]: Loss = 0.0453\n",
      "[229 / 250]: Loss = 0.0406\n",
      "[230 / 250]: Loss = 0.0411\n",
      "[231 / 250]: Loss = 0.0346\n",
      "[232 / 250]: Loss = 0.0506\n",
      "[233 / 250]: Loss = 0.0368\n",
      "[234 / 250]: Loss = 0.0402\n",
      "[235 / 250]: Loss = 0.0431\n",
      "[236 / 250]: Loss = 0.0470\n",
      "[237 / 250]: Loss = 0.0432\n",
      "[238 / 250]: Loss = 0.0434\n",
      "[239 / 250]: Loss = 0.0378\n",
      "[240 / 250]: Loss = 0.0411\n",
      "[241 / 250]: Loss = 0.0394\n",
      "[242 / 250]: Loss = 0.0454\n",
      "[243 / 250]: Loss = 0.0380\n",
      "[244 / 250]: Loss = 0.0337\n",
      "[245 / 250]: Loss = 0.0350\n",
      "[246 / 250]: Loss = 0.0478\n",
      "[247 / 250]: Loss = 0.0475\n",
      "[248 / 250]: Loss = 0.0550\n",
      "[249 / 250]: Loss = 0.0485\n",
      "[0 / 32]: Loss = 0.0482\n",
      "[1 / 32]: Loss = 0.0496\n",
      "[2 / 32]: Loss = 0.0551\n",
      "[3 / 32]: Loss = 0.0480\n",
      "[4 / 32]: Loss = 0.0551\n",
      "[5 / 32]: Loss = 0.0477\n",
      "[6 / 32]: Loss = 0.0542\n",
      "[7 / 32]: Loss = 0.0496\n",
      "[8 / 32]: Loss = 0.0491\n",
      "[9 / 32]: Loss = 0.0496\n",
      "[10 / 32]: Loss = 0.0532\n",
      "[11 / 32]: Loss = 0.0486\n",
      "[12 / 32]: Loss = 0.0490\n",
      "[13 / 32]: Loss = 0.0594\n",
      "[14 / 32]: Loss = 0.0454\n",
      "[15 / 32]: Loss = 0.0432\n",
      "[16 / 32]: Loss = 0.0545\n",
      "[17 / 32]: Loss = 0.0535\n",
      "[18 / 32]: Loss = 0.0538\n",
      "[19 / 32]: Loss = 0.0508\n",
      "[20 / 32]: Loss = 0.0618\n",
      "[21 / 32]: Loss = 0.0638\n",
      "[22 / 32]: Loss = 0.0455\n",
      "[23 / 32]: Loss = 0.0515\n",
      "[24 / 32]: Loss = 0.0496\n",
      "[25 / 32]: Loss = 0.0435\n",
      "[26 / 32]: Loss = 0.0563\n",
      "[27 / 32]: Loss = 0.0401\n",
      "[28 / 32]: Loss = 0.0439\n",
      "[29 / 32]: Loss = 0.0434\n",
      "[30 / 32]: Loss = 0.0628\n",
      "[31 / 32]: Loss = 0.0565\n",
      "Epoch 6 / 10, Epoch Time = 167.66s: Train Loss = 0.0430, Train AUC = 0.9790, Val Loss = 0.0511, Val AUC = 0.9723\n",
      "[0 / 250]: Loss = 0.0356\n",
      "[1 / 250]: Loss = 0.0395\n",
      "[2 / 250]: Loss = 0.0401\n",
      "[3 / 250]: Loss = 0.0405\n",
      "[4 / 250]: Loss = 0.0513\n",
      "[5 / 250]: Loss = 0.0391\n",
      "[6 / 250]: Loss = 0.0365\n",
      "[7 / 250]: Loss = 0.0482\n",
      "[8 / 250]: Loss = 0.0415\n",
      "[9 / 250]: Loss = 0.0431\n",
      "[10 / 250]: Loss = 0.0377\n",
      "[11 / 250]: Loss = 0.0492\n",
      "[12 / 250]: Loss = 0.0485\n",
      "[13 / 250]: Loss = 0.0463\n",
      "[14 / 250]: Loss = 0.0446\n",
      "[15 / 250]: Loss = 0.0382\n",
      "[16 / 250]: Loss = 0.0427\n",
      "[17 / 250]: Loss = 0.0385\n",
      "[18 / 250]: Loss = 0.0368\n",
      "[19 / 250]: Loss = 0.0396\n",
      "[20 / 250]: Loss = 0.0500\n",
      "[21 / 250]: Loss = 0.0416\n",
      "[22 / 250]: Loss = 0.0438\n",
      "[23 / 250]: Loss = 0.0381\n",
      "[24 / 250]: Loss = 0.0380\n",
      "[25 / 250]: Loss = 0.0425\n",
      "[26 / 250]: Loss = 0.0401\n",
      "[27 / 250]: Loss = 0.0408\n",
      "[28 / 250]: Loss = 0.0365\n",
      "[29 / 250]: Loss = 0.0441\n",
      "[30 / 250]: Loss = 0.0316\n",
      "[31 / 250]: Loss = 0.0308\n",
      "[32 / 250]: Loss = 0.0423\n",
      "[33 / 250]: Loss = 0.0413\n",
      "[34 / 250]: Loss = 0.0373\n",
      "[35 / 250]: Loss = 0.0501\n",
      "[36 / 250]: Loss = 0.0424\n",
      "[37 / 250]: Loss = 0.0378\n",
      "[38 / 250]: Loss = 0.0370\n",
      "[39 / 250]: Loss = 0.0504\n",
      "[40 / 250]: Loss = 0.0326\n",
      "[41 / 250]: Loss = 0.0392\n",
      "[42 / 250]: Loss = 0.0381\n",
      "[43 / 250]: Loss = 0.0387\n",
      "[44 / 250]: Loss = 0.0298\n",
      "[45 / 250]: Loss = 0.0463\n",
      "[46 / 250]: Loss = 0.0434\n",
      "[47 / 250]: Loss = 0.0428\n",
      "[48 / 250]: Loss = 0.0368\n",
      "[49 / 250]: Loss = 0.0373\n",
      "[50 / 250]: Loss = 0.0423\n",
      "[51 / 250]: Loss = 0.0438\n",
      "[52 / 250]: Loss = 0.0386\n",
      "[53 / 250]: Loss = 0.0342\n",
      "[54 / 250]: Loss = 0.0337\n",
      "[55 / 250]: Loss = 0.0345\n",
      "[56 / 250]: Loss = 0.0362\n",
      "[57 / 250]: Loss = 0.0469\n",
      "[58 / 250]: Loss = 0.0297\n",
      "[59 / 250]: Loss = 0.0419\n",
      "[60 / 250]: Loss = 0.0476\n",
      "[61 / 250]: Loss = 0.0539\n",
      "[62 / 250]: Loss = 0.0364\n",
      "[63 / 250]: Loss = 0.0358\n",
      "[64 / 250]: Loss = 0.0334\n",
      "[65 / 250]: Loss = 0.0433\n",
      "[66 / 250]: Loss = 0.0483\n",
      "[67 / 250]: Loss = 0.0392\n",
      "[68 / 250]: Loss = 0.0346\n",
      "[69 / 250]: Loss = 0.0394\n",
      "[70 / 250]: Loss = 0.0425\n",
      "[71 / 250]: Loss = 0.0484\n",
      "[72 / 250]: Loss = 0.0323\n",
      "[73 / 250]: Loss = 0.0337\n",
      "[74 / 250]: Loss = 0.0464\n",
      "[75 / 250]: Loss = 0.0442\n",
      "[76 / 250]: Loss = 0.0364\n",
      "[77 / 250]: Loss = 0.0322\n",
      "[78 / 250]: Loss = 0.0465\n",
      "[79 / 250]: Loss = 0.0397\n",
      "[80 / 250]: Loss = 0.0424\n",
      "[81 / 250]: Loss = 0.0420\n",
      "[82 / 250]: Loss = 0.0409\n",
      "[83 / 250]: Loss = 0.0466\n",
      "[84 / 250]: Loss = 0.0365\n",
      "[85 / 250]: Loss = 0.0463\n",
      "[86 / 250]: Loss = 0.0373\n",
      "[87 / 250]: Loss = 0.0301\n",
      "[88 / 250]: Loss = 0.0364\n",
      "[89 / 250]: Loss = 0.0357\n",
      "[90 / 250]: Loss = 0.0452\n",
      "[91 / 250]: Loss = 0.0377\n",
      "[92 / 250]: Loss = 0.0345\n",
      "[93 / 250]: Loss = 0.0450\n",
      "[94 / 250]: Loss = 0.0398\n",
      "[95 / 250]: Loss = 0.0391\n",
      "[96 / 250]: Loss = 0.0307\n",
      "[97 / 250]: Loss = 0.0384\n",
      "[98 / 250]: Loss = 0.0406\n",
      "[99 / 250]: Loss = 0.0364\n",
      "[100 / 250]: Loss = 0.0272\n",
      "[101 / 250]: Loss = 0.0354\n",
      "[102 / 250]: Loss = 0.0312\n",
      "[103 / 250]: Loss = 0.0324\n",
      "[104 / 250]: Loss = 0.0419\n",
      "[105 / 250]: Loss = 0.0376\n",
      "[106 / 250]: Loss = 0.0368\n",
      "[107 / 250]: Loss = 0.0470\n",
      "[108 / 250]: Loss = 0.0417\n",
      "[109 / 250]: Loss = 0.0357\n",
      "[110 / 250]: Loss = 0.0302\n",
      "[111 / 250]: Loss = 0.0307\n",
      "[112 / 250]: Loss = 0.0310\n",
      "[113 / 250]: Loss = 0.0418\n",
      "[114 / 250]: Loss = 0.0306\n",
      "[115 / 250]: Loss = 0.0412\n",
      "[116 / 250]: Loss = 0.0431\n",
      "[117 / 250]: Loss = 0.0529\n",
      "[118 / 250]: Loss = 0.0356\n",
      "[119 / 250]: Loss = 0.0443\n",
      "[120 / 250]: Loss = 0.0365\n",
      "[121 / 250]: Loss = 0.0490\n",
      "[122 / 250]: Loss = 0.0407\n",
      "[123 / 250]: Loss = 0.0383\n",
      "[124 / 250]: Loss = 0.0404\n",
      "[125 / 250]: Loss = 0.0350\n",
      "[126 / 250]: Loss = 0.0395\n",
      "[127 / 250]: Loss = 0.0381\n",
      "[128 / 250]: Loss = 0.0359\n",
      "[129 / 250]: Loss = 0.0456\n",
      "[130 / 250]: Loss = 0.0404\n",
      "[131 / 250]: Loss = 0.0442\n",
      "[132 / 250]: Loss = 0.0320\n",
      "[133 / 250]: Loss = 0.0442\n",
      "[134 / 250]: Loss = 0.0424\n",
      "[135 / 250]: Loss = 0.0477\n",
      "[136 / 250]: Loss = 0.0336\n",
      "[137 / 250]: Loss = 0.0363\n",
      "[138 / 250]: Loss = 0.0439\n",
      "[139 / 250]: Loss = 0.0403\n",
      "[140 / 250]: Loss = 0.0466\n",
      "[141 / 250]: Loss = 0.0500\n",
      "[142 / 250]: Loss = 0.0317\n",
      "[143 / 250]: Loss = 0.0398\n",
      "[144 / 250]: Loss = 0.0409\n",
      "[145 / 250]: Loss = 0.0457\n",
      "[146 / 250]: Loss = 0.0420\n",
      "[147 / 250]: Loss = 0.0366\n",
      "[148 / 250]: Loss = 0.0440\n",
      "[149 / 250]: Loss = 0.0370\n",
      "[150 / 250]: Loss = 0.0410\n",
      "[151 / 250]: Loss = 0.0353\n",
      "[152 / 250]: Loss = 0.0388\n",
      "[153 / 250]: Loss = 0.0523\n",
      "[154 / 250]: Loss = 0.0393\n",
      "[155 / 250]: Loss = 0.0340\n",
      "[156 / 250]: Loss = 0.0388\n",
      "[157 / 250]: Loss = 0.0385\n",
      "[158 / 250]: Loss = 0.0363\n",
      "[159 / 250]: Loss = 0.0401\n",
      "[160 / 250]: Loss = 0.0364\n",
      "[161 / 250]: Loss = 0.0454\n",
      "[162 / 250]: Loss = 0.0546\n",
      "[163 / 250]: Loss = 0.0285\n",
      "[164 / 250]: Loss = 0.0361\n",
      "[165 / 250]: Loss = 0.0242\n",
      "[166 / 250]: Loss = 0.0432\n",
      "[167 / 250]: Loss = 0.0427\n",
      "[168 / 250]: Loss = 0.0373\n",
      "[169 / 250]: Loss = 0.0343\n",
      "[170 / 250]: Loss = 0.0320\n",
      "[171 / 250]: Loss = 0.0463\n",
      "[172 / 250]: Loss = 0.0403\n",
      "[173 / 250]: Loss = 0.0386\n",
      "[174 / 250]: Loss = 0.0364\n",
      "[175 / 250]: Loss = 0.0364\n",
      "[176 / 250]: Loss = 0.0424\n",
      "[177 / 250]: Loss = 0.0366\n",
      "[178 / 250]: Loss = 0.0341\n",
      "[179 / 250]: Loss = 0.0374\n",
      "[180 / 250]: Loss = 0.0487\n",
      "[181 / 250]: Loss = 0.0437\n",
      "[182 / 250]: Loss = 0.0470\n",
      "[183 / 250]: Loss = 0.0331\n",
      "[184 / 250]: Loss = 0.0343\n",
      "[185 / 250]: Loss = 0.0363\n",
      "[186 / 250]: Loss = 0.0379\n",
      "[187 / 250]: Loss = 0.0355\n",
      "[188 / 250]: Loss = 0.0406\n",
      "[189 / 250]: Loss = 0.0433\n",
      "[190 / 250]: Loss = 0.0370\n",
      "[191 / 250]: Loss = 0.0396\n",
      "[192 / 250]: Loss = 0.0414\n",
      "[193 / 250]: Loss = 0.0438\n",
      "[194 / 250]: Loss = 0.0358\n",
      "[195 / 250]: Loss = 0.0416\n",
      "[196 / 250]: Loss = 0.0289\n",
      "[197 / 250]: Loss = 0.0258\n",
      "[198 / 250]: Loss = 0.0406\n",
      "[199 / 250]: Loss = 0.0479\n",
      "[200 / 250]: Loss = 0.0417\n",
      "[201 / 250]: Loss = 0.0370\n",
      "[202 / 250]: Loss = 0.0439\n",
      "[203 / 250]: Loss = 0.0341\n",
      "[204 / 250]: Loss = 0.0458\n",
      "[205 / 250]: Loss = 0.0305\n",
      "[206 / 250]: Loss = 0.0413\n",
      "[207 / 250]: Loss = 0.0399\n",
      "[208 / 250]: Loss = 0.0432\n",
      "[209 / 250]: Loss = 0.0427\n",
      "[210 / 250]: Loss = 0.0288\n",
      "[211 / 250]: Loss = 0.0403\n",
      "[212 / 250]: Loss = 0.0373\n",
      "[213 / 250]: Loss = 0.0355\n",
      "[214 / 250]: Loss = 0.0345\n",
      "[215 / 250]: Loss = 0.0346\n",
      "[216 / 250]: Loss = 0.0429\n",
      "[217 / 250]: Loss = 0.0354\n",
      "[218 / 250]: Loss = 0.0379\n",
      "[219 / 250]: Loss = 0.0374\n",
      "[220 / 250]: Loss = 0.0392\n",
      "[221 / 250]: Loss = 0.0467\n",
      "[222 / 250]: Loss = 0.0452\n",
      "[223 / 250]: Loss = 0.0283\n",
      "[224 / 250]: Loss = 0.0359\n",
      "[225 / 250]: Loss = 0.0304\n",
      "[226 / 250]: Loss = 0.0331\n",
      "[227 / 250]: Loss = 0.0361\n",
      "[228 / 250]: Loss = 0.0316\n",
      "[229 / 250]: Loss = 0.0399\n",
      "[230 / 250]: Loss = 0.0309\n",
      "[231 / 250]: Loss = 0.0352\n",
      "[232 / 250]: Loss = 0.0502\n",
      "[233 / 250]: Loss = 0.0343\n",
      "[234 / 250]: Loss = 0.0559\n",
      "[235 / 250]: Loss = 0.0371\n",
      "[236 / 250]: Loss = 0.0292\n",
      "[237 / 250]: Loss = 0.0360\n",
      "[238 / 250]: Loss = 0.0464\n",
      "[239 / 250]: Loss = 0.0278\n",
      "[240 / 250]: Loss = 0.0518\n",
      "[241 / 250]: Loss = 0.0318\n",
      "[242 / 250]: Loss = 0.0446\n",
      "[243 / 250]: Loss = 0.0365\n",
      "[244 / 250]: Loss = 0.0257\n",
      "[245 / 250]: Loss = 0.0430\n",
      "[246 / 250]: Loss = 0.0359\n",
      "[247 / 250]: Loss = 0.0409\n",
      "[248 / 250]: Loss = 0.0414\n",
      "[249 / 250]: Loss = 0.0402\n",
      "[0 / 32]: Loss = 0.0599\n",
      "[1 / 32]: Loss = 0.0564\n",
      "[2 / 32]: Loss = 0.0396\n",
      "[3 / 32]: Loss = 0.0510\n",
      "[4 / 32]: Loss = 0.0553\n",
      "[5 / 32]: Loss = 0.0566\n",
      "[6 / 32]: Loss = 0.0480\n",
      "[7 / 32]: Loss = 0.0554\n",
      "[8 / 32]: Loss = 0.0443\n",
      "[9 / 32]: Loss = 0.0505\n",
      "[10 / 32]: Loss = 0.0552\n",
      "[11 / 32]: Loss = 0.0493\n",
      "[12 / 32]: Loss = 0.0569\n",
      "[13 / 32]: Loss = 0.0454\n",
      "[14 / 32]: Loss = 0.0459\n",
      "[15 / 32]: Loss = 0.0483\n",
      "[16 / 32]: Loss = 0.0520\n",
      "[17 / 32]: Loss = 0.0412\n",
      "[18 / 32]: Loss = 0.0551\n",
      "[19 / 32]: Loss = 0.0505\n",
      "[20 / 32]: Loss = 0.0569\n",
      "[21 / 32]: Loss = 0.0523\n",
      "[22 / 32]: Loss = 0.0408\n",
      "[23 / 32]: Loss = 0.0447\n",
      "[24 / 32]: Loss = 0.0427\n",
      "[25 / 32]: Loss = 0.0553\n",
      "[26 / 32]: Loss = 0.0532\n",
      "[27 / 32]: Loss = 0.0459\n",
      "[28 / 32]: Loss = 0.0419\n",
      "[29 / 32]: Loss = 0.0378\n",
      "[30 / 32]: Loss = 0.0651\n",
      "[31 / 32]: Loss = 0.0607\n",
      "Epoch 7 / 10, Epoch Time = 167.71s: Train Loss = 0.0393, Train AUC = 0.9825, Val Loss = 0.0504, Val AUC = 0.9747\n",
      "[0 / 250]: Loss = 0.0313\n",
      "[1 / 250]: Loss = 0.0332\n",
      "[2 / 250]: Loss = 0.0304\n",
      "[3 / 250]: Loss = 0.0337\n",
      "[4 / 250]: Loss = 0.0308\n",
      "[5 / 250]: Loss = 0.0427\n",
      "[6 / 250]: Loss = 0.0308\n",
      "[7 / 250]: Loss = 0.0388\n",
      "[8 / 250]: Loss = 0.0347\n",
      "[9 / 250]: Loss = 0.0331\n",
      "[10 / 250]: Loss = 0.0343\n",
      "[11 / 250]: Loss = 0.0441\n",
      "[12 / 250]: Loss = 0.0474\n",
      "[13 / 250]: Loss = 0.0409\n",
      "[14 / 250]: Loss = 0.0339\n",
      "[15 / 250]: Loss = 0.0290\n",
      "[16 / 250]: Loss = 0.0319\n",
      "[17 / 250]: Loss = 0.0443\n",
      "[18 / 250]: Loss = 0.0392\n",
      "[19 / 250]: Loss = 0.0314\n",
      "[20 / 250]: Loss = 0.0302\n",
      "[21 / 250]: Loss = 0.0330\n",
      "[22 / 250]: Loss = 0.0393\n",
      "[23 / 250]: Loss = 0.0345\n",
      "[24 / 250]: Loss = 0.0454\n",
      "[25 / 250]: Loss = 0.0409\n",
      "[26 / 250]: Loss = 0.0393\n",
      "[27 / 250]: Loss = 0.0411\n",
      "[28 / 250]: Loss = 0.0420\n",
      "[29 / 250]: Loss = 0.0397\n",
      "[30 / 250]: Loss = 0.0394\n",
      "[31 / 250]: Loss = 0.0377\n",
      "[32 / 250]: Loss = 0.0317\n",
      "[33 / 250]: Loss = 0.0404\n",
      "[34 / 250]: Loss = 0.0383\n",
      "[35 / 250]: Loss = 0.0458\n",
      "[36 / 250]: Loss = 0.0507\n",
      "[37 / 250]: Loss = 0.0398\n",
      "[38 / 250]: Loss = 0.0420\n",
      "[39 / 250]: Loss = 0.0351\n",
      "[40 / 250]: Loss = 0.0517\n",
      "[41 / 250]: Loss = 0.0314\n",
      "[42 / 250]: Loss = 0.0386\n",
      "[43 / 250]: Loss = 0.0255\n",
      "[44 / 250]: Loss = 0.0294\n",
      "[45 / 250]: Loss = 0.0362\n",
      "[46 / 250]: Loss = 0.0422\n",
      "[47 / 250]: Loss = 0.0365\n",
      "[48 / 250]: Loss = 0.0335\n",
      "[49 / 250]: Loss = 0.0468\n",
      "[50 / 250]: Loss = 0.0248\n",
      "[51 / 250]: Loss = 0.0329\n",
      "[52 / 250]: Loss = 0.0421\n",
      "[53 / 250]: Loss = 0.0255\n",
      "[54 / 250]: Loss = 0.0301\n",
      "[55 / 250]: Loss = 0.0368\n",
      "[56 / 250]: Loss = 0.0428\n",
      "[57 / 250]: Loss = 0.0404\n",
      "[58 / 250]: Loss = 0.0292\n",
      "[59 / 250]: Loss = 0.0268\n",
      "[60 / 250]: Loss = 0.0323\n",
      "[61 / 250]: Loss = 0.0301\n",
      "[62 / 250]: Loss = 0.0332\n",
      "[63 / 250]: Loss = 0.0370\n",
      "[64 / 250]: Loss = 0.0390\n",
      "[65 / 250]: Loss = 0.0395\n",
      "[66 / 250]: Loss = 0.0338\n",
      "[67 / 250]: Loss = 0.0303\n",
      "[68 / 250]: Loss = 0.0493\n",
      "[69 / 250]: Loss = 0.0443\n",
      "[70 / 250]: Loss = 0.0541\n",
      "[71 / 250]: Loss = 0.0380\n",
      "[72 / 250]: Loss = 0.0358\n",
      "[73 / 250]: Loss = 0.0342\n",
      "[74 / 250]: Loss = 0.0367\n",
      "[75 / 250]: Loss = 0.0349\n",
      "[76 / 250]: Loss = 0.0382\n",
      "[77 / 250]: Loss = 0.0421\n",
      "[78 / 250]: Loss = 0.0361\n",
      "[79 / 250]: Loss = 0.0281\n",
      "[80 / 250]: Loss = 0.0352\n",
      "[81 / 250]: Loss = 0.0425\n",
      "[82 / 250]: Loss = 0.0321\n",
      "[83 / 250]: Loss = 0.0314\n",
      "[84 / 250]: Loss = 0.0352\n",
      "[85 / 250]: Loss = 0.0337\n",
      "[86 / 250]: Loss = 0.0405\n",
      "[87 / 250]: Loss = 0.0324\n",
      "[88 / 250]: Loss = 0.0373\n",
      "[89 / 250]: Loss = 0.0409\n",
      "[90 / 250]: Loss = 0.0393\n",
      "[91 / 250]: Loss = 0.0336\n",
      "[92 / 250]: Loss = 0.0305\n",
      "[93 / 250]: Loss = 0.0307\n",
      "[94 / 250]: Loss = 0.0384\n",
      "[95 / 250]: Loss = 0.0335\n",
      "[96 / 250]: Loss = 0.0368\n",
      "[97 / 250]: Loss = 0.0382\n",
      "[98 / 250]: Loss = 0.0369\n",
      "[99 / 250]: Loss = 0.0421\n",
      "[100 / 250]: Loss = 0.0315\n",
      "[101 / 250]: Loss = 0.0319\n",
      "[102 / 250]: Loss = 0.0335\n",
      "[103 / 250]: Loss = 0.0413\n",
      "[104 / 250]: Loss = 0.0268\n",
      "[105 / 250]: Loss = 0.0336\n",
      "[106 / 250]: Loss = 0.0365\n",
      "[107 / 250]: Loss = 0.0330\n",
      "[108 / 250]: Loss = 0.0452\n",
      "[109 / 250]: Loss = 0.0380\n",
      "[110 / 250]: Loss = 0.0438\n",
      "[111 / 250]: Loss = 0.0231\n",
      "[112 / 250]: Loss = 0.0380\n",
      "[113 / 250]: Loss = 0.0363\n",
      "[114 / 250]: Loss = 0.0251\n",
      "[115 / 250]: Loss = 0.0284\n",
      "[116 / 250]: Loss = 0.0350\n",
      "[117 / 250]: Loss = 0.0381\n",
      "[118 / 250]: Loss = 0.0350\n",
      "[119 / 250]: Loss = 0.0498\n",
      "[120 / 250]: Loss = 0.0336\n",
      "[121 / 250]: Loss = 0.0351\n",
      "[122 / 250]: Loss = 0.0351\n",
      "[123 / 250]: Loss = 0.0440\n",
      "[124 / 250]: Loss = 0.0418\n",
      "[125 / 250]: Loss = 0.0396\n",
      "[126 / 250]: Loss = 0.0315\n",
      "[127 / 250]: Loss = 0.0395\n",
      "[128 / 250]: Loss = 0.0436\n",
      "[129 / 250]: Loss = 0.0355\n",
      "[130 / 250]: Loss = 0.0343\n",
      "[131 / 250]: Loss = 0.0266\n",
      "[132 / 250]: Loss = 0.0546\n",
      "[133 / 250]: Loss = 0.0364\n",
      "[134 / 250]: Loss = 0.0270\n",
      "[135 / 250]: Loss = 0.0364\n",
      "[136 / 250]: Loss = 0.0435\n",
      "[137 / 250]: Loss = 0.0413\n",
      "[138 / 250]: Loss = 0.0367\n",
      "[139 / 250]: Loss = 0.0339\n",
      "[140 / 250]: Loss = 0.0349\n",
      "[141 / 250]: Loss = 0.0325\n",
      "[142 / 250]: Loss = 0.0407\n",
      "[143 / 250]: Loss = 0.0414\n",
      "[144 / 250]: Loss = 0.0383\n",
      "[145 / 250]: Loss = 0.0414\n",
      "[146 / 250]: Loss = 0.0363\n",
      "[147 / 250]: Loss = 0.0363\n",
      "[148 / 250]: Loss = 0.0399\n",
      "[149 / 250]: Loss = 0.0225\n",
      "[150 / 250]: Loss = 0.0308\n",
      "[151 / 250]: Loss = 0.0476\n",
      "[152 / 250]: Loss = 0.0337\n",
      "[153 / 250]: Loss = 0.0258\n",
      "[154 / 250]: Loss = 0.0469\n",
      "[155 / 250]: Loss = 0.0414\n",
      "[156 / 250]: Loss = 0.0429\n",
      "[157 / 250]: Loss = 0.0411\n",
      "[158 / 250]: Loss = 0.0277\n",
      "[159 / 250]: Loss = 0.0286\n",
      "[160 / 250]: Loss = 0.0419\n",
      "[161 / 250]: Loss = 0.0325\n",
      "[162 / 250]: Loss = 0.0367\n",
      "[163 / 250]: Loss = 0.0437\n",
      "[164 / 250]: Loss = 0.0317\n",
      "[165 / 250]: Loss = 0.0381\n",
      "[166 / 250]: Loss = 0.0314\n",
      "[167 / 250]: Loss = 0.0303\n",
      "[168 / 250]: Loss = 0.0365\n",
      "[169 / 250]: Loss = 0.0375\n",
      "[170 / 250]: Loss = 0.0266\n",
      "[171 / 250]: Loss = 0.0394\n",
      "[172 / 250]: Loss = 0.0429\n",
      "[173 / 250]: Loss = 0.0366\n",
      "[174 / 250]: Loss = 0.0389\n",
      "[175 / 250]: Loss = 0.0268\n",
      "[176 / 250]: Loss = 0.0396\n",
      "[177 / 250]: Loss = 0.0340\n",
      "[178 / 250]: Loss = 0.0411\n",
      "[179 / 250]: Loss = 0.0355\n",
      "[180 / 250]: Loss = 0.0377\n",
      "[181 / 250]: Loss = 0.0394\n",
      "[182 / 250]: Loss = 0.0323\n",
      "[183 / 250]: Loss = 0.0349\n",
      "[184 / 250]: Loss = 0.0314\n",
      "[185 / 250]: Loss = 0.0279\n",
      "[186 / 250]: Loss = 0.0330\n",
      "[187 / 250]: Loss = 0.0420\n",
      "[188 / 250]: Loss = 0.0362\n",
      "[189 / 250]: Loss = 0.0423\n",
      "[190 / 250]: Loss = 0.0411\n",
      "[191 / 250]: Loss = 0.0293\n",
      "[192 / 250]: Loss = 0.0398\n",
      "[193 / 250]: Loss = 0.0313\n",
      "[194 / 250]: Loss = 0.0327\n",
      "[195 / 250]: Loss = 0.0342\n",
      "[196 / 250]: Loss = 0.0302\n",
      "[197 / 250]: Loss = 0.0323\n",
      "[198 / 250]: Loss = 0.0315\n",
      "[199 / 250]: Loss = 0.0370\n",
      "[200 / 250]: Loss = 0.0322\n",
      "[201 / 250]: Loss = 0.0367\n",
      "[202 / 250]: Loss = 0.0372\n",
      "[203 / 250]: Loss = 0.0355\n",
      "[204 / 250]: Loss = 0.0343\n",
      "[205 / 250]: Loss = 0.0345\n",
      "[206 / 250]: Loss = 0.0413\n",
      "[207 / 250]: Loss = 0.0319\n",
      "[208 / 250]: Loss = 0.0352\n",
      "[209 / 250]: Loss = 0.0378\n",
      "[210 / 250]: Loss = 0.0350\n",
      "[211 / 250]: Loss = 0.0341\n",
      "[212 / 250]: Loss = 0.0299\n",
      "[213 / 250]: Loss = 0.0418\n",
      "[214 / 250]: Loss = 0.0351\n",
      "[215 / 250]: Loss = 0.0331\n",
      "[216 / 250]: Loss = 0.0400\n",
      "[217 / 250]: Loss = 0.0388\n",
      "[218 / 250]: Loss = 0.0378\n",
      "[219 / 250]: Loss = 0.0350\n",
      "[220 / 250]: Loss = 0.0387\n",
      "[221 / 250]: Loss = 0.0238\n",
      "[222 / 250]: Loss = 0.0396\n",
      "[223 / 250]: Loss = 0.0374\n",
      "[224 / 250]: Loss = 0.0400\n",
      "[225 / 250]: Loss = 0.0370\n",
      "[226 / 250]: Loss = 0.0430\n",
      "[227 / 250]: Loss = 0.0394\n",
      "[228 / 250]: Loss = 0.0390\n",
      "[229 / 250]: Loss = 0.0327\n",
      "[230 / 250]: Loss = 0.0326\n",
      "[231 / 250]: Loss = 0.0414\n",
      "[232 / 250]: Loss = 0.0288\n",
      "[233 / 250]: Loss = 0.0365\n",
      "[234 / 250]: Loss = 0.0405\n",
      "[235 / 250]: Loss = 0.0312\n",
      "[236 / 250]: Loss = 0.0325\n",
      "[237 / 250]: Loss = 0.0323\n",
      "[238 / 250]: Loss = 0.0301\n",
      "[239 / 250]: Loss = 0.0392\n",
      "[240 / 250]: Loss = 0.0421\n",
      "[241 / 250]: Loss = 0.0330\n",
      "[242 / 250]: Loss = 0.0330\n",
      "[243 / 250]: Loss = 0.0316\n",
      "[244 / 250]: Loss = 0.0285\n",
      "[245 / 250]: Loss = 0.0320\n",
      "[246 / 250]: Loss = 0.0261\n",
      "[247 / 250]: Loss = 0.0276\n",
      "[248 / 250]: Loss = 0.0310\n",
      "[249 / 250]: Loss = 0.0419\n",
      "[0 / 32]: Loss = 0.0431\n",
      "[1 / 32]: Loss = 0.0516\n",
      "[2 / 32]: Loss = 0.0457\n",
      "[3 / 32]: Loss = 0.0514\n",
      "[4 / 32]: Loss = 0.0537\n",
      "[5 / 32]: Loss = 0.0432\n",
      "[6 / 32]: Loss = 0.0574\n",
      "[7 / 32]: Loss = 0.0523\n",
      "[8 / 32]: Loss = 0.0609\n",
      "[9 / 32]: Loss = 0.0577\n",
      "[10 / 32]: Loss = 0.0474\n",
      "[11 / 32]: Loss = 0.0571\n",
      "[12 / 32]: Loss = 0.0497\n",
      "[13 / 32]: Loss = 0.0459\n",
      "[14 / 32]: Loss = 0.0570\n",
      "[15 / 32]: Loss = 0.0522\n",
      "[16 / 32]: Loss = 0.0515\n",
      "[17 / 32]: Loss = 0.0397\n",
      "[18 / 32]: Loss = 0.0386\n",
      "[19 / 32]: Loss = 0.0428\n",
      "[20 / 32]: Loss = 0.0507\n",
      "[21 / 32]: Loss = 0.0474\n",
      "[22 / 32]: Loss = 0.0487\n",
      "[23 / 32]: Loss = 0.0468\n",
      "[24 / 32]: Loss = 0.0464\n",
      "[25 / 32]: Loss = 0.0537\n",
      "[26 / 32]: Loss = 0.0531\n",
      "[27 / 32]: Loss = 0.0421\n",
      "[28 / 32]: Loss = 0.0518\n",
      "[29 / 32]: Loss = 0.0464\n",
      "[30 / 32]: Loss = 0.0521\n",
      "[31 / 32]: Loss = 0.0799\n",
      "Epoch 8 / 10, Epoch Time = 167.75s: Train Loss = 0.0361, Train AUC = 0.9855, Val Loss = 0.0506, Val AUC = 0.9758\n",
      "[0 / 250]: Loss = 0.0375\n",
      "[1 / 250]: Loss = 0.0314\n",
      "[2 / 250]: Loss = 0.0327\n",
      "[3 / 250]: Loss = 0.0371\n",
      "[4 / 250]: Loss = 0.0336\n",
      "[5 / 250]: Loss = 0.0353\n",
      "[6 / 250]: Loss = 0.0326\n",
      "[7 / 250]: Loss = 0.0445\n",
      "[8 / 250]: Loss = 0.0353\n",
      "[9 / 250]: Loss = 0.0212\n",
      "[10 / 250]: Loss = 0.0327\n",
      "[11 / 250]: Loss = 0.0307\n",
      "[12 / 250]: Loss = 0.0380\n",
      "[13 / 250]: Loss = 0.0338\n",
      "[14 / 250]: Loss = 0.0314\n",
      "[15 / 250]: Loss = 0.0266\n",
      "[16 / 250]: Loss = 0.0412\n",
      "[17 / 250]: Loss = 0.0355\n",
      "[18 / 250]: Loss = 0.0253\n",
      "[19 / 250]: Loss = 0.0375\n",
      "[20 / 250]: Loss = 0.0293\n",
      "[21 / 250]: Loss = 0.0300\n",
      "[22 / 250]: Loss = 0.0440\n",
      "[23 / 250]: Loss = 0.0375\n",
      "[24 / 250]: Loss = 0.0325\n",
      "[25 / 250]: Loss = 0.0294\n",
      "[26 / 250]: Loss = 0.0368\n",
      "[27 / 250]: Loss = 0.0343\n",
      "[28 / 250]: Loss = 0.0468\n",
      "[29 / 250]: Loss = 0.0389\n",
      "[30 / 250]: Loss = 0.0435\n",
      "[31 / 250]: Loss = 0.0386\n",
      "[32 / 250]: Loss = 0.0422\n",
      "[33 / 250]: Loss = 0.0299\n",
      "[34 / 250]: Loss = 0.0298\n",
      "[35 / 250]: Loss = 0.0380\n",
      "[36 / 250]: Loss = 0.0360\n",
      "[37 / 250]: Loss = 0.0324\n",
      "[38 / 250]: Loss = 0.0343\n",
      "[39 / 250]: Loss = 0.0285\n",
      "[40 / 250]: Loss = 0.0358\n",
      "[41 / 250]: Loss = 0.0303\n",
      "[42 / 250]: Loss = 0.0316\n",
      "[43 / 250]: Loss = 0.0219\n",
      "[44 / 250]: Loss = 0.0283\n",
      "[45 / 250]: Loss = 0.0296\n",
      "[46 / 250]: Loss = 0.0313\n",
      "[47 / 250]: Loss = 0.0337\n",
      "[48 / 250]: Loss = 0.0319\n",
      "[49 / 250]: Loss = 0.0382\n",
      "[50 / 250]: Loss = 0.0286\n",
      "[51 / 250]: Loss = 0.0357\n",
      "[52 / 250]: Loss = 0.0361\n",
      "[53 / 250]: Loss = 0.0368\n",
      "[54 / 250]: Loss = 0.0309\n",
      "[55 / 250]: Loss = 0.0327\n",
      "[56 / 250]: Loss = 0.0310\n",
      "[57 / 250]: Loss = 0.0244\n",
      "[58 / 250]: Loss = 0.0329\n",
      "[59 / 250]: Loss = 0.0336\n",
      "[60 / 250]: Loss = 0.0276\n",
      "[61 / 250]: Loss = 0.0311\n",
      "[62 / 250]: Loss = 0.0234\n",
      "[63 / 250]: Loss = 0.0266\n",
      "[64 / 250]: Loss = 0.0259\n",
      "[65 / 250]: Loss = 0.0403\n",
      "[66 / 250]: Loss = 0.0274\n",
      "[67 / 250]: Loss = 0.0294\n",
      "[68 / 250]: Loss = 0.0339\n",
      "[69 / 250]: Loss = 0.0281\n",
      "[70 / 250]: Loss = 0.0235\n",
      "[71 / 250]: Loss = 0.0301\n",
      "[72 / 250]: Loss = 0.0355\n",
      "[73 / 250]: Loss = 0.0237\n",
      "[74 / 250]: Loss = 0.0294\n",
      "[75 / 250]: Loss = 0.0306\n",
      "[76 / 250]: Loss = 0.0263\n",
      "[77 / 250]: Loss = 0.0268\n",
      "[78 / 250]: Loss = 0.0405\n",
      "[79 / 250]: Loss = 0.0379\n",
      "[80 / 250]: Loss = 0.0388\n",
      "[81 / 250]: Loss = 0.0273\n",
      "[82 / 250]: Loss = 0.0415\n",
      "[83 / 250]: Loss = 0.0322\n",
      "[84 / 250]: Loss = 0.0314\n",
      "[85 / 250]: Loss = 0.0369\n",
      "[86 / 250]: Loss = 0.0313\n",
      "[87 / 250]: Loss = 0.0318\n",
      "[88 / 250]: Loss = 0.0373\n",
      "[89 / 250]: Loss = 0.0290\n",
      "[90 / 250]: Loss = 0.0454\n",
      "[91 / 250]: Loss = 0.0301\n",
      "[92 / 250]: Loss = 0.0409\n",
      "[93 / 250]: Loss = 0.0338\n",
      "[94 / 250]: Loss = 0.0352\n",
      "[95 / 250]: Loss = 0.0365\n",
      "[96 / 250]: Loss = 0.0338\n",
      "[97 / 250]: Loss = 0.0352\n",
      "[98 / 250]: Loss = 0.0378\n",
      "[99 / 250]: Loss = 0.0307\n",
      "[100 / 250]: Loss = 0.0395\n",
      "[101 / 250]: Loss = 0.0321\n",
      "[102 / 250]: Loss = 0.0312\n",
      "[103 / 250]: Loss = 0.0304\n",
      "[104 / 250]: Loss = 0.0328\n",
      "[105 / 250]: Loss = 0.0354\n",
      "[106 / 250]: Loss = 0.0382\n",
      "[107 / 250]: Loss = 0.0442\n",
      "[108 / 250]: Loss = 0.0337\n",
      "[109 / 250]: Loss = 0.0301\n",
      "[110 / 250]: Loss = 0.0311\n",
      "[111 / 250]: Loss = 0.0282\n",
      "[112 / 250]: Loss = 0.0419\n",
      "[113 / 250]: Loss = 0.0373\n",
      "[114 / 250]: Loss = 0.0382\n",
      "[115 / 250]: Loss = 0.0400\n",
      "[116 / 250]: Loss = 0.0349\n",
      "[117 / 250]: Loss = 0.0310\n",
      "[118 / 250]: Loss = 0.0358\n",
      "[119 / 250]: Loss = 0.0266\n",
      "[120 / 250]: Loss = 0.0263\n",
      "[121 / 250]: Loss = 0.0275\n",
      "[122 / 250]: Loss = 0.0306\n",
      "[123 / 250]: Loss = 0.0352\n",
      "[124 / 250]: Loss = 0.0284\n",
      "[125 / 250]: Loss = 0.0394\n",
      "[126 / 250]: Loss = 0.0380\n",
      "[127 / 250]: Loss = 0.0356\n",
      "[128 / 250]: Loss = 0.0297\n",
      "[129 / 250]: Loss = 0.0364\n",
      "[130 / 250]: Loss = 0.0281\n",
      "[131 / 250]: Loss = 0.0392\n",
      "[132 / 250]: Loss = 0.0353\n",
      "[133 / 250]: Loss = 0.0336\n",
      "[134 / 250]: Loss = 0.0296\n",
      "[135 / 250]: Loss = 0.0447\n",
      "[136 / 250]: Loss = 0.0256\n",
      "[137 / 250]: Loss = 0.0288\n",
      "[138 / 250]: Loss = 0.0391\n",
      "[139 / 250]: Loss = 0.0301\n",
      "[140 / 250]: Loss = 0.0356\n",
      "[141 / 250]: Loss = 0.0227\n",
      "[142 / 250]: Loss = 0.0355\n",
      "[143 / 250]: Loss = 0.0290\n",
      "[144 / 250]: Loss = 0.0392\n",
      "[145 / 250]: Loss = 0.0312\n",
      "[146 / 250]: Loss = 0.0272\n",
      "[147 / 250]: Loss = 0.0357\n",
      "[148 / 250]: Loss = 0.0390\n",
      "[149 / 250]: Loss = 0.0255\n",
      "[150 / 250]: Loss = 0.0389\n",
      "[151 / 250]: Loss = 0.0288\n",
      "[152 / 250]: Loss = 0.0297\n",
      "[153 / 250]: Loss = 0.0378\n",
      "[154 / 250]: Loss = 0.0302\n",
      "[155 / 250]: Loss = 0.0326\n",
      "[156 / 250]: Loss = 0.0315\n",
      "[157 / 250]: Loss = 0.0240\n",
      "[158 / 250]: Loss = 0.0330\n",
      "[159 / 250]: Loss = 0.0321\n",
      "[160 / 250]: Loss = 0.0329\n",
      "[161 / 250]: Loss = 0.0314\n",
      "[162 / 250]: Loss = 0.0286\n",
      "[163 / 250]: Loss = 0.0364\n",
      "[164 / 250]: Loss = 0.0369\n",
      "[165 / 250]: Loss = 0.0397\n",
      "[166 / 250]: Loss = 0.0310\n",
      "[167 / 250]: Loss = 0.0342\n",
      "[168 / 250]: Loss = 0.0384\n",
      "[169 / 250]: Loss = 0.0317\n",
      "[170 / 250]: Loss = 0.0336\n",
      "[171 / 250]: Loss = 0.0300\n",
      "[172 / 250]: Loss = 0.0361\n",
      "[173 / 250]: Loss = 0.0279\n",
      "[174 / 250]: Loss = 0.0317\n",
      "[175 / 250]: Loss = 0.0308\n",
      "[176 / 250]: Loss = 0.0264\n",
      "[177 / 250]: Loss = 0.0329\n",
      "[178 / 250]: Loss = 0.0377\n",
      "[179 / 250]: Loss = 0.0386\n",
      "[180 / 250]: Loss = 0.0332\n",
      "[181 / 250]: Loss = 0.0303\n",
      "[182 / 250]: Loss = 0.0272\n",
      "[183 / 250]: Loss = 0.0376\n",
      "[184 / 250]: Loss = 0.0398\n",
      "[185 / 250]: Loss = 0.0323\n",
      "[186 / 250]: Loss = 0.0308\n",
      "[187 / 250]: Loss = 0.0364\n",
      "[188 / 250]: Loss = 0.0345\n",
      "[189 / 250]: Loss = 0.0317\n",
      "[190 / 250]: Loss = 0.0339\n",
      "[191 / 250]: Loss = 0.0346\n",
      "[192 / 250]: Loss = 0.0374\n",
      "[193 / 250]: Loss = 0.0335\n",
      "[194 / 250]: Loss = 0.0372\n",
      "[195 / 250]: Loss = 0.0383\n",
      "[196 / 250]: Loss = 0.0318\n",
      "[197 / 250]: Loss = 0.0298\n",
      "[198 / 250]: Loss = 0.0299\n",
      "[199 / 250]: Loss = 0.0334\n",
      "[200 / 250]: Loss = 0.0321\n",
      "[201 / 250]: Loss = 0.0392\n",
      "[202 / 250]: Loss = 0.0421\n",
      "[203 / 250]: Loss = 0.0341\n",
      "[204 / 250]: Loss = 0.0421\n",
      "[205 / 250]: Loss = 0.0280\n",
      "[206 / 250]: Loss = 0.0340\n",
      "[207 / 250]: Loss = 0.0296\n",
      "[208 / 250]: Loss = 0.0256\n",
      "[209 / 250]: Loss = 0.0286\n",
      "[210 / 250]: Loss = 0.0329\n",
      "[211 / 250]: Loss = 0.0275\n",
      "[212 / 250]: Loss = 0.0338\n",
      "[213 / 250]: Loss = 0.0322\n",
      "[214 / 250]: Loss = 0.0307\n",
      "[215 / 250]: Loss = 0.0374\n",
      "[216 / 250]: Loss = 0.0336\n",
      "[217 / 250]: Loss = 0.0390\n",
      "[218 / 250]: Loss = 0.0330\n",
      "[219 / 250]: Loss = 0.0244\n",
      "[220 / 250]: Loss = 0.0286\n",
      "[221 / 250]: Loss = 0.0317\n",
      "[222 / 250]: Loss = 0.0331\n",
      "[223 / 250]: Loss = 0.0401\n",
      "[224 / 250]: Loss = 0.0380\n",
      "[225 / 250]: Loss = 0.0407\n",
      "[226 / 250]: Loss = 0.0318\n",
      "[227 / 250]: Loss = 0.0306\n",
      "[228 / 250]: Loss = 0.0327\n",
      "[229 / 250]: Loss = 0.0407\n",
      "[230 / 250]: Loss = 0.0474\n",
      "[231 / 250]: Loss = 0.0294\n",
      "[232 / 250]: Loss = 0.0223\n",
      "[233 / 250]: Loss = 0.0334\n",
      "[234 / 250]: Loss = 0.0361\n",
      "[235 / 250]: Loss = 0.0358\n",
      "[236 / 250]: Loss = 0.0370\n",
      "[237 / 250]: Loss = 0.0306\n",
      "[238 / 250]: Loss = 0.0343\n",
      "[239 / 250]: Loss = 0.0387\n",
      "[240 / 250]: Loss = 0.0371\n",
      "[241 / 250]: Loss = 0.0286\n",
      "[242 / 250]: Loss = 0.0281\n",
      "[243 / 250]: Loss = 0.0263\n",
      "[244 / 250]: Loss = 0.0255\n",
      "[245 / 250]: Loss = 0.0322\n",
      "[246 / 250]: Loss = 0.0313\n",
      "[247 / 250]: Loss = 0.0297\n",
      "[248 / 250]: Loss = 0.0310\n",
      "[249 / 250]: Loss = 0.0250\n",
      "[0 / 32]: Loss = 0.0445\n",
      "[1 / 32]: Loss = 0.0554\n",
      "[2 / 32]: Loss = 0.0428\n",
      "[3 / 32]: Loss = 0.0476\n",
      "[4 / 32]: Loss = 0.0468\n",
      "[5 / 32]: Loss = 0.0499\n",
      "[6 / 32]: Loss = 0.0427\n",
      "[7 / 32]: Loss = 0.0502\n",
      "[8 / 32]: Loss = 0.0568\n",
      "[9 / 32]: Loss = 0.0513\n",
      "[10 / 32]: Loss = 0.0446\n",
      "[11 / 32]: Loss = 0.0433\n",
      "[12 / 32]: Loss = 0.0436\n",
      "[13 / 32]: Loss = 0.0432\n",
      "[14 / 32]: Loss = 0.0417\n",
      "[15 / 32]: Loss = 0.0542\n",
      "[16 / 32]: Loss = 0.0500\n",
      "[17 / 32]: Loss = 0.0522\n",
      "[18 / 32]: Loss = 0.0590\n",
      "[19 / 32]: Loss = 0.0614\n",
      "[20 / 32]: Loss = 0.0448\n",
      "[21 / 32]: Loss = 0.0425\n",
      "[22 / 32]: Loss = 0.0511\n",
      "[23 / 32]: Loss = 0.0644\n",
      "[24 / 32]: Loss = 0.0494\n",
      "[25 / 32]: Loss = 0.0466\n",
      "[26 / 32]: Loss = 0.0507\n",
      "[27 / 32]: Loss = 0.0521\n",
      "[28 / 32]: Loss = 0.0454\n",
      "[29 / 32]: Loss = 0.0401\n",
      "[30 / 32]: Loss = 0.0576\n",
      "[31 / 32]: Loss = 0.0475\n",
      "Epoch 9 / 10, Epoch Time = 167.66s: Train Loss = 0.0332, Train AUC = 0.9879, Val Loss = 0.0492, Val AUC = 0.9776\n",
      "[0 / 250]: Loss = 0.0286\n",
      "[1 / 250]: Loss = 0.0274\n",
      "[2 / 250]: Loss = 0.0265\n",
      "[3 / 250]: Loss = 0.0330\n",
      "[4 / 250]: Loss = 0.0312\n",
      "[5 / 250]: Loss = 0.0293\n",
      "[6 / 250]: Loss = 0.0299\n",
      "[7 / 250]: Loss = 0.0299\n",
      "[8 / 250]: Loss = 0.0325\n",
      "[9 / 250]: Loss = 0.0337\n",
      "[10 / 250]: Loss = 0.0299\n",
      "[11 / 250]: Loss = 0.0342\n",
      "[12 / 250]: Loss = 0.0295\n",
      "[13 / 250]: Loss = 0.0359\n",
      "[14 / 250]: Loss = 0.0297\n",
      "[15 / 250]: Loss = 0.0325\n",
      "[16 / 250]: Loss = 0.0272\n",
      "[17 / 250]: Loss = 0.0272\n",
      "[18 / 250]: Loss = 0.0297\n",
      "[19 / 250]: Loss = 0.0354\n",
      "[20 / 250]: Loss = 0.0351\n",
      "[21 / 250]: Loss = 0.0374\n",
      "[22 / 250]: Loss = 0.0307\n",
      "[23 / 250]: Loss = 0.0274\n",
      "[24 / 250]: Loss = 0.0342\n",
      "[25 / 250]: Loss = 0.0289\n",
      "[26 / 250]: Loss = 0.0315\n",
      "[27 / 250]: Loss = 0.0267\n",
      "[28 / 250]: Loss = 0.0287\n",
      "[29 / 250]: Loss = 0.0268\n",
      "[30 / 250]: Loss = 0.0313\n",
      "[31 / 250]: Loss = 0.0281\n",
      "[32 / 250]: Loss = 0.0217\n",
      "[33 / 250]: Loss = 0.0260\n",
      "[34 / 250]: Loss = 0.0439\n",
      "[35 / 250]: Loss = 0.0334\n",
      "[36 / 250]: Loss = 0.0304\n",
      "[37 / 250]: Loss = 0.0280\n",
      "[38 / 250]: Loss = 0.0233\n",
      "[39 / 250]: Loss = 0.0302\n",
      "[40 / 250]: Loss = 0.0310\n",
      "[41 / 250]: Loss = 0.0353\n",
      "[42 / 250]: Loss = 0.0356\n",
      "[43 / 250]: Loss = 0.0334\n",
      "[44 / 250]: Loss = 0.0305\n",
      "[45 / 250]: Loss = 0.0332\n",
      "[46 / 250]: Loss = 0.0352\n",
      "[47 / 250]: Loss = 0.0384\n",
      "[48 / 250]: Loss = 0.0296\n",
      "[49 / 250]: Loss = 0.0336\n",
      "[50 / 250]: Loss = 0.0266\n",
      "[51 / 250]: Loss = 0.0372\n",
      "[52 / 250]: Loss = 0.0251\n",
      "[53 / 250]: Loss = 0.0382\n",
      "[54 / 250]: Loss = 0.0279\n",
      "[55 / 250]: Loss = 0.0316\n",
      "[56 / 250]: Loss = 0.0302\n",
      "[57 / 250]: Loss = 0.0281\n",
      "[58 / 250]: Loss = 0.0325\n",
      "[59 / 250]: Loss = 0.0278\n",
      "[60 / 250]: Loss = 0.0393\n",
      "[61 / 250]: Loss = 0.0227\n",
      "[62 / 250]: Loss = 0.0257\n",
      "[63 / 250]: Loss = 0.0281\n",
      "[64 / 250]: Loss = 0.0324\n",
      "[65 / 250]: Loss = 0.0255\n",
      "[66 / 250]: Loss = 0.0261\n",
      "[67 / 250]: Loss = 0.0237\n",
      "[68 / 250]: Loss = 0.0272\n",
      "[69 / 250]: Loss = 0.0259\n",
      "[70 / 250]: Loss = 0.0252\n",
      "[71 / 250]: Loss = 0.0251\n",
      "[72 / 250]: Loss = 0.0339\n",
      "[73 / 250]: Loss = 0.0336\n",
      "[74 / 250]: Loss = 0.0280\n",
      "[75 / 250]: Loss = 0.0304\n",
      "[76 / 250]: Loss = 0.0267\n",
      "[77 / 250]: Loss = 0.0339\n",
      "[78 / 250]: Loss = 0.0293\n",
      "[79 / 250]: Loss = 0.0257\n",
      "[80 / 250]: Loss = 0.0296\n",
      "[81 / 250]: Loss = 0.0331\n",
      "[82 / 250]: Loss = 0.0402\n",
      "[83 / 250]: Loss = 0.0300\n",
      "[84 / 250]: Loss = 0.0362\n",
      "[85 / 250]: Loss = 0.0309\n",
      "[86 / 250]: Loss = 0.0341\n",
      "[87 / 250]: Loss = 0.0335\n",
      "[88 / 250]: Loss = 0.0308\n",
      "[89 / 250]: Loss = 0.0395\n",
      "[90 / 250]: Loss = 0.0312\n",
      "[91 / 250]: Loss = 0.0240\n",
      "[92 / 250]: Loss = 0.0335\n",
      "[93 / 250]: Loss = 0.0258\n",
      "[94 / 250]: Loss = 0.0363\n",
      "[95 / 250]: Loss = 0.0267\n",
      "[96 / 250]: Loss = 0.0283\n",
      "[97 / 250]: Loss = 0.0251\n",
      "[98 / 250]: Loss = 0.0252\n",
      "[99 / 250]: Loss = 0.0368\n",
      "[100 / 250]: Loss = 0.0369\n",
      "[101 / 250]: Loss = 0.0261\n",
      "[102 / 250]: Loss = 0.0223\n",
      "[103 / 250]: Loss = 0.0358\n",
      "[104 / 250]: Loss = 0.0314\n",
      "[105 / 250]: Loss = 0.0319\n",
      "[106 / 250]: Loss = 0.0255\n",
      "[107 / 250]: Loss = 0.0391\n",
      "[108 / 250]: Loss = 0.0356\n",
      "[109 / 250]: Loss = 0.0319\n",
      "[110 / 250]: Loss = 0.0372\n",
      "[111 / 250]: Loss = 0.0244\n",
      "[112 / 250]: Loss = 0.0312\n",
      "[113 / 250]: Loss = 0.0221\n",
      "[114 / 250]: Loss = 0.0325\n",
      "[115 / 250]: Loss = 0.0340\n",
      "[116 / 250]: Loss = 0.0289\n",
      "[117 / 250]: Loss = 0.0310\n",
      "[118 / 250]: Loss = 0.0214\n",
      "[119 / 250]: Loss = 0.0299\n",
      "[120 / 250]: Loss = 0.0253\n",
      "[121 / 250]: Loss = 0.0299\n",
      "[122 / 250]: Loss = 0.0310\n",
      "[123 / 250]: Loss = 0.0249\n",
      "[124 / 250]: Loss = 0.0302\n",
      "[125 / 250]: Loss = 0.0441\n",
      "[126 / 250]: Loss = 0.0286\n",
      "[127 / 250]: Loss = 0.0323\n",
      "[128 / 250]: Loss = 0.0233\n",
      "[129 / 250]: Loss = 0.0336\n",
      "[130 / 250]: Loss = 0.0204\n",
      "[131 / 250]: Loss = 0.0358\n",
      "[132 / 250]: Loss = 0.0258\n",
      "[133 / 250]: Loss = 0.0328\n",
      "[134 / 250]: Loss = 0.0265\n",
      "[135 / 250]: Loss = 0.0343\n",
      "[136 / 250]: Loss = 0.0253\n",
      "[137 / 250]: Loss = 0.0302\n",
      "[138 / 250]: Loss = 0.0368\n",
      "[139 / 250]: Loss = 0.0344\n",
      "[140 / 250]: Loss = 0.0320\n",
      "[141 / 250]: Loss = 0.0282\n",
      "[142 / 250]: Loss = 0.0338\n",
      "[143 / 250]: Loss = 0.0275\n",
      "[144 / 250]: Loss = 0.0285\n",
      "[145 / 250]: Loss = 0.0314\n",
      "[146 / 250]: Loss = 0.0268\n",
      "[147 / 250]: Loss = 0.0268\n",
      "[148 / 250]: Loss = 0.0268\n",
      "[149 / 250]: Loss = 0.0309\n",
      "[150 / 250]: Loss = 0.0327\n",
      "[151 / 250]: Loss = 0.0376\n",
      "[152 / 250]: Loss = 0.0345\n",
      "[153 / 250]: Loss = 0.0351\n",
      "[154 / 250]: Loss = 0.0265\n",
      "[155 / 250]: Loss = 0.0292\n",
      "[156 / 250]: Loss = 0.0283\n",
      "[157 / 250]: Loss = 0.0348\n",
      "[158 / 250]: Loss = 0.0303\n",
      "[159 / 250]: Loss = 0.0323\n",
      "[160 / 250]: Loss = 0.0287\n",
      "[161 / 250]: Loss = 0.0246\n",
      "[162 / 250]: Loss = 0.0270\n",
      "[163 / 250]: Loss = 0.0319\n",
      "[164 / 250]: Loss = 0.0307\n",
      "[165 / 250]: Loss = 0.0240\n",
      "[166 / 250]: Loss = 0.0372\n",
      "[167 / 250]: Loss = 0.0267\n",
      "[168 / 250]: Loss = 0.0305\n",
      "[169 / 250]: Loss = 0.0340\n",
      "[170 / 250]: Loss = 0.0363\n",
      "[171 / 250]: Loss = 0.0323\n",
      "[172 / 250]: Loss = 0.0357\n",
      "[173 / 250]: Loss = 0.0351\n",
      "[174 / 250]: Loss = 0.0316\n",
      "[175 / 250]: Loss = 0.0255\n",
      "[176 / 250]: Loss = 0.0315\n",
      "[177 / 250]: Loss = 0.0266\n",
      "[178 / 250]: Loss = 0.0266\n",
      "[179 / 250]: Loss = 0.0371\n",
      "[180 / 250]: Loss = 0.0295\n",
      "[181 / 250]: Loss = 0.0298\n",
      "[182 / 250]: Loss = 0.0304\n",
      "[183 / 250]: Loss = 0.0243\n",
      "[184 / 250]: Loss = 0.0296\n",
      "[185 / 250]: Loss = 0.0370\n",
      "[186 / 250]: Loss = 0.0294\n",
      "[187 / 250]: Loss = 0.0266\n",
      "[188 / 250]: Loss = 0.0333\n",
      "[189 / 250]: Loss = 0.0312\n",
      "[190 / 250]: Loss = 0.0293\n",
      "[191 / 250]: Loss = 0.0290\n",
      "[192 / 250]: Loss = 0.0353\n",
      "[193 / 250]: Loss = 0.0254\n",
      "[194 / 250]: Loss = 0.0347\n",
      "[195 / 250]: Loss = 0.0337\n",
      "[196 / 250]: Loss = 0.0292\n",
      "[197 / 250]: Loss = 0.0360\n",
      "[198 / 250]: Loss = 0.0358\n",
      "[199 / 250]: Loss = 0.0354\n",
      "[200 / 250]: Loss = 0.0297\n",
      "[201 / 250]: Loss = 0.0285\n",
      "[202 / 250]: Loss = 0.0365\n",
      "[203 / 250]: Loss = 0.0344\n",
      "[204 / 250]: Loss = 0.0213\n",
      "[205 / 250]: Loss = 0.0245\n",
      "[206 / 250]: Loss = 0.0320\n",
      "[207 / 250]: Loss = 0.0276\n",
      "[208 / 250]: Loss = 0.0360\n",
      "[209 / 250]: Loss = 0.0300\n",
      "[210 / 250]: Loss = 0.0263\n",
      "[211 / 250]: Loss = 0.0231\n",
      "[212 / 250]: Loss = 0.0374\n",
      "[213 / 250]: Loss = 0.0228\n",
      "[214 / 250]: Loss = 0.0262\n",
      "[215 / 250]: Loss = 0.0274\n",
      "[216 / 250]: Loss = 0.0310\n",
      "[217 / 250]: Loss = 0.0336\n",
      "[218 / 250]: Loss = 0.0340\n",
      "[219 / 250]: Loss = 0.0253\n",
      "[220 / 250]: Loss = 0.0294\n",
      "[221 / 250]: Loss = 0.0286\n",
      "[222 / 250]: Loss = 0.0362\n",
      "[223 / 250]: Loss = 0.0243\n",
      "[224 / 250]: Loss = 0.0297\n",
      "[225 / 250]: Loss = 0.0324\n",
      "[226 / 250]: Loss = 0.0279\n",
      "[227 / 250]: Loss = 0.0293\n",
      "[228 / 250]: Loss = 0.0312\n",
      "[229 / 250]: Loss = 0.0316\n",
      "[230 / 250]: Loss = 0.0336\n",
      "[231 / 250]: Loss = 0.0194\n",
      "[232 / 250]: Loss = 0.0295\n",
      "[233 / 250]: Loss = 0.0284\n",
      "[234 / 250]: Loss = 0.0347\n",
      "[235 / 250]: Loss = 0.0290\n",
      "[236 / 250]: Loss = 0.0339\n",
      "[237 / 250]: Loss = 0.0462\n",
      "[238 / 250]: Loss = 0.0241\n",
      "[239 / 250]: Loss = 0.0271\n",
      "[240 / 250]: Loss = 0.0290\n",
      "[241 / 250]: Loss = 0.0332\n",
      "[242 / 250]: Loss = 0.0288\n",
      "[243 / 250]: Loss = 0.0382\n",
      "[244 / 250]: Loss = 0.0232\n",
      "[245 / 250]: Loss = 0.0231\n",
      "[246 / 250]: Loss = 0.0271\n",
      "[247 / 250]: Loss = 0.0326\n",
      "[248 / 250]: Loss = 0.0281\n",
      "[249 / 250]: Loss = 0.0227\n",
      "[0 / 32]: Loss = 0.0600\n",
      "[1 / 32]: Loss = 0.0612\n",
      "[2 / 32]: Loss = 0.0513\n",
      "[3 / 32]: Loss = 0.0592\n",
      "[4 / 32]: Loss = 0.0632\n",
      "[5 / 32]: Loss = 0.0440\n",
      "[6 / 32]: Loss = 0.0406\n",
      "[7 / 32]: Loss = 0.0522\n",
      "[8 / 32]: Loss = 0.0527\n",
      "[9 / 32]: Loss = 0.0444\n",
      "[10 / 32]: Loss = 0.0467\n",
      "[11 / 32]: Loss = 0.0431\n",
      "[12 / 32]: Loss = 0.0403\n",
      "[13 / 32]: Loss = 0.0554\n",
      "[14 / 32]: Loss = 0.0459\n",
      "[15 / 32]: Loss = 0.0463\n",
      "[16 / 32]: Loss = 0.0394\n",
      "[17 / 32]: Loss = 0.0525\n",
      "[18 / 32]: Loss = 0.0438\n",
      "[19 / 32]: Loss = 0.0574\n",
      "[20 / 32]: Loss = 0.0561\n",
      "[21 / 32]: Loss = 0.0428\n",
      "[22 / 32]: Loss = 0.0455\n",
      "[23 / 32]: Loss = 0.0511\n",
      "[24 / 32]: Loss = 0.0445\n",
      "[25 / 32]: Loss = 0.0507\n",
      "[26 / 32]: Loss = 0.0441\n",
      "[27 / 32]: Loss = 0.0446\n",
      "[28 / 32]: Loss = 0.0597\n",
      "[29 / 32]: Loss = 0.0528\n",
      "[30 / 32]: Loss = 0.0393\n",
      "[31 / 32]: Loss = 0.0496\n",
      "Epoch 10 / 10, Epoch Time = 167.78s: Train Loss = 0.0304, Train AUC = 0.9899, Val Loss = 0.0494, Val AUC = 0.9786\n"
     ]
    }
   ],
   "source": [
    "vocab_size  = len(token_to_id)\n",
    "embed_size  = 300\n",
    "hidden_size = 32\n",
    "num_classes = 6\n",
    "\n",
    "\n",
    "model        = RCNN(torch.FloatTensor(embedding_matrix),\n",
    "                  vocab_size, \n",
    "                  embed_size,\n",
    "                  hidden_size,\n",
    "                  num_classes\n",
    "                  ).cuda()\n",
    "\n",
    "criterion    = nn.BCEWithLogitsLoss().cuda()\n",
    "optimizer    = optim.Adam([param for param in model.parameters() if param.requires_grad], lr=0.001)\n",
    "\n",
    "X_train      = as_matrix(data_train['tokenized_comments'], \n",
    "                         token_to_id, \n",
    "                         word_dropout=0.000, \n",
    "                         UNK_IX=UNK_IX, \n",
    "                         PAD_IX=PAD_IX,\n",
    "                         max_len=MAX_LEN\n",
    "                        )\n",
    "\n",
    "train_labels = data_train.loc[:, TARGET_COLS].values \n",
    "\n",
    "X_test       = as_matrix(data_val['tokenized_comments'],\n",
    "                         token_to_id, \n",
    "                         word_dropout=0.000, \n",
    "                         UNK_IX=UNK_IX, \n",
    "                         PAD_IX=PAD_IX,\n",
    "                         max_len=MAX_LEN\n",
    "                        )\n",
    "\n",
    "test_labels  = data_val.loc[:, TARGET_COLS].values\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, train_labels), epochs_count=10, \n",
    "    batch_size=512, val_data=(X_test, test_labels), val_batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 2 / 2, Epoch Time = 167.66s: Train Loss = 0.0427, Train AUC = 0.9793, Val Loss = 0.0483, Val AUC = 0.9781"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN(nn.Module):\n",
    "    def __init__(self, weights, vocab_size, embed_size, hidden_size, num_classes):\n",
    "        super(RCNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size  = vocab_size\n",
    "        self.embed_size  = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.embedding.weight = nn.Parameter(weights)\n",
    "        \n",
    "        self.Wl  = nn.Parameter(data=torch.Tensor(self.hidden_size, self.hidden_size), requires_grad=True)\n",
    "        self.Wsl = nn.Parameter(data=torch.Tensor(self.hidden_size, self.embed_size), requires_grad=True) \n",
    "        \n",
    "        self.Wr  = nn.Parameter(data=torch.Tensor(self.hidden_size, self.hidden_size), requires_grad=True)\n",
    "        self.Wsr = nn.Parameter(data=torch.Tensor(self.hidden_size, self.embed_size), requires_grad=True) \n",
    "        \n",
    "        \n",
    "        self.cl  = nn.Parameter(data=torch.Tensor(1, self.hidden_size), requires_grad=True)\n",
    "        self.cr  = nn.Parameter(data=torch.Tensor(1, self.hidden_size), requires_grad=True)\n",
    "        \n",
    "        self.relu = nn.ReLU() \n",
    "        self.fc   = nn.Linear(self.hidden_size * 2 + self.embed_size, self.num_classes)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.Wl, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wsl, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wr, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wsr, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.cl, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.cr, a=np.sqrt(5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # create left and right context vectors to be equal to be\n",
    "        # equal to (batch_size, hidden_size)\n",
    "        \n",
    "        cl        = self.cl.repeat(x.size(0), 1)\n",
    "        cr        = self.cr.repeat(x.size(0), 1)\n",
    "        \n",
    "        \n",
    "        embed     = self.embedding(x)\n",
    "        cxt       = cl.t()\n",
    "        \n",
    "        left_context  = []\n",
    "        right_context = []\n",
    "        \n",
    "        # O(n)\n",
    "        for i in range(1, x.size(1)):\n",
    "            cxt         = torch.mm(self.Wl, cxt) + torch.mm(self.Wsl, embed[:, i-1, :].t())\n",
    "            left_context.append(cxt)\n",
    "        \n",
    "        cxt = cr.t()\n",
    "        \n",
    "        # O(n)\n",
    "        for i in range(x.size(1)-2, -1, -1):\n",
    "            cxt         = torch.mm(self.Wr, cxt) + torch.mm(self.Wsr, embed[:, i-1, :].t())\n",
    "            right_context.append(cxt)\n",
    "        \n",
    "        \n",
    "        left_context  = torch.cat([cl.t()] + left_context, dim=1)\n",
    "        left_context  = left_context.view(x.size(0), x.size(1), -1)\n",
    "        \n",
    "        right_context = torch.cat(right_context + [cr.t()], dim=1).t()\n",
    "        right_context = right_context.view(x.size(0), x.size(1), -1)\n",
    "        \n",
    "        # word representation\n",
    "        word_repr = torch.cat((left_context, embed, right_context), dim=2)\n",
    "        \n",
    "#         print('WORD REPR ', word_repr.shape)\n",
    "        \n",
    "#         out = self.fc1(word_repr)\n",
    "#         out = self.relu(out)\n",
    "        \n",
    "        # text representation\n",
    "        out = word_repr.max(dim=1)[0]\n",
    "        \n",
    "        # final layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size  = 3\n",
    "hidden_size = 2\n",
    "embed_size  = 2\n",
    "num_classes = 2\n",
    "\n",
    "X = torch.LongTensor([[0, 1],\n",
    "                      [1, 0],\n",
    "                      [0, 0]\n",
    "                     ])\n",
    "\n",
    "model = RCNN(torch.Tensor(vocab_size, embed_size),\n",
    "             vocab_size,\n",
    "             embed_size,\n",
    "             hidden_size,\n",
    "             num_classes\n",
    "            )\n",
    "logits = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0631, -0.4866],\n",
       "        [-0.1683, -0.3037],\n",
       "        [-0.1000, -0.3597]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Temp, self).__init__()\n",
    "        self.cr = nn.Parameter(data=torch.Tensor(1, 3), requires_grad=True)     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        cr = self.cr.repeat(x.size(0), 1)\n",
    "        \n",
    "        return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = Temp()\n",
    "logits = model(torch.Tensor(3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.2047e-37,  4.5673e-41,  5.4213e-13]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for params in model.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2047e-37,  4.5673e-41,  5.4213e-13],\n",
       "        [-1.2047e-37,  4.5673e-41,  5.4213e-13],\n",
       "        [-1.2047e-37,  4.5673e-41,  5.4213e-13]], grad_fn=<RepeatBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
