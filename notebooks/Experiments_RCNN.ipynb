{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "SEED = 41\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH        = '../data/raw/'\n",
    "PROCESSED_DATA_PATH  = '../data/processed/' \n",
    "\n",
    "MAX_LEN = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample():\n",
    "    return pd.read_csv(os.path.join(PROCESSED_DATA_PATH, 'train_sample.csv'))\n",
    "\n",
    "def load_full():\n",
    "    train       = pd.read_csv(os.path.join(RAW_DATA_PATH, 'train.csv'))\n",
    "    test        = pd.read_csv(os.path.join(RAW_DATA_PATH, 'test.csv'))\n",
    "    test_labels = pd.read_csv(os.path.join(RAW_DATA_PATH, 'test_labels.csv'))\n",
    "    \n",
    "    return train, test, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.54 s, sys: 164 ms, total: 1.7 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, _, _ = load_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train = load_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLS = ['toxic', \n",
    "               'severe_toxic', \n",
    "               'obscene', \n",
    "               'threat', \n",
    "               'insult', \n",
    "               'identity_hate'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tokenizer\n",
    "tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.53 s, sys: 296 ms, total: 5.82 s\n",
      "Wall time: 5.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_tokenized_comments = list(map(tokenizer.tokenize, train.comment_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.96 s, sys: 3.89 s, total: 9.85 s\n",
      "Wall time: 9.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.loc[:, 'tokenized_comments'] = list(map(' '.join, map(tokenizer.tokenize, train.comment_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create word freq mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter()\n",
    "\n",
    "for tok_comments in train_tokenized_comments:\n",
    "    token_counts.update(tok_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 32838\n"
     ]
    }
   ],
   "source": [
    "# we can put a threshold on the token frequency to reduce the vocabulary\n",
    "tokens    = {}\n",
    "min_count = 10\n",
    "\n",
    "for token, freq in token_counts.items():\n",
    "    if freq >= min_count:\n",
    "        tokens[token] = freq\n",
    "        \n",
    "print('Size of the vocabulary: {}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wv_embedding_matrix(words):\n",
    "    word2vec_dict = word2vec.KeyedVectors.load_word2vec_format(os.path.join(PROCESSED_DATA_PATH, 'word2vec.bin.gz'), binary=True)\n",
    "    embed_size    = 300\n",
    "\n",
    "    embedding_index = dict()\n",
    "    for word in word2vec_dict.wv.vocab:\n",
    "        embedding_index[word] = word2vec_dict.word_vec(word)\n",
    "\n",
    "    print('Loaded %d word vectors'%(len(embedding_index)))\n",
    "\n",
    "    all_embs          = np.stack(list(embedding_index.values()))\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "    UNK, PAD       = 'UNK', 'PAD'\n",
    "    UNK_IX, PAD_IX = len(words), len(words) + 1\n",
    "\n",
    "    nb_words = len(words) + 2\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "    embed_cnt = 0\n",
    "    for i, word in enumerate(list(words.keys()) + [UNK, PAD]):\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            embed_cnt +=1\n",
    "\n",
    "    print('total embedded ', embed_cnt, ' common words')\n",
    "    del embedding_index\n",
    "    gc.collect()\n",
    "\n",
    "    return embedding_matrix, UNK, PAD, UNK_IX, PAD_IX\n",
    "\n",
    "\n",
    "def load_fake_embedding_matrix(words):\n",
    "    UNK, PAD       = 'UNK', 'PAD'\n",
    "    UNK_IX, PAD_IX = len(words), len(words) + 1\n",
    "\n",
    "    nb_words = len(words) + 2\n",
    "    emb_mean = .2\n",
    "    embed_size = 300\n",
    "    emb_std  = 2.3\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "    return embedding_matrix, UNK, PAD, UNK_IX, PAD_IX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token to ID mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token to index (manual)\n",
    "# UNK, PAD       = 'UNK', 'PAD'\n",
    "# UNK_IX, PAD_IX =  0, 1\n",
    "\n",
    "# token_to_id = {UNK: UNK_IX,\n",
    "#                PAD: PAD_IX\n",
    "#               }\n",
    "\n",
    "# for token in tokens.keys():\n",
    "#     token_to_id[token] = len(token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000000 word vectors\n",
      "total embedded  29714  common words\n",
      "CPU times: user 2min 37s, sys: 8.49 s, total: 2min 45s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# token to index ( word2vec embeddings )\n",
    "embedding_matrix, UNK, PAD, UNK_IX, PAD_IX = load_wv_embedding_matrix(tokens)\n",
    "# embedding_matrix, UNK, PAD, UNK_IX, PAD_IX = load_fake_embedding_matrix(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id      = {word: index for index, word in enumerate(tokens.keys())}\n",
    "token_to_id[UNK] = UNK_IX\n",
    "token_to_id[PAD] = PAD_IX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad Sequences and convert map tokens to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, token_to_id, word_dropout, UNK_IX, PAD_IX, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "\n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "\n",
    "    if word_dropout != 0:\n",
    "        matrix = apply_word_dropout(matrix, 1 - word_dropout, replace_with=UNK_IX, pad_ix=PAD_IX)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with, pad_ix):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1-keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  127656\n",
      "Validation size =  31915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "data_train.index     = range(len(data_train))\n",
    "data_val.index       = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(matrix, labels, batch_size, predict_mode='train'):\n",
    "    indices = np.arange(len(matrix))\n",
    "    if predict_mode == 'train':\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, len(matrix), batch_size):\n",
    "        end = min(start + batch_size, len(matrix))\n",
    "        \n",
    "        batch_indices = indices[start: end]\n",
    "        X = matrix[batch_indices]\n",
    "        \n",
    "        if predict_mode != 'train': yield X\n",
    "        else: yield X, labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RCNN(nn.Module):\n",
    "#     def __init__(self, weights, vocab_size, embed_size, hidden_size, num_classes):\n",
    "#         super(RCNN, self).__init__()\n",
    "        \n",
    "#         self.vocab_size  = vocab_size\n",
    "#         self.embed_size  = embed_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_classes = num_classes\n",
    "        \n",
    "#         self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "#         self.embedding.weight = nn.Parameter(weights)\n",
    "        \n",
    "#         self.Wl  = nn.Parameter(data=torch.Tensor(self.hidden_size, self.hidden_size), requires_grad=True)\n",
    "#         self.Wsl = nn.Parameter(data=torch.Tensor(self.hidden_size, self.embed_size), requires_grad=True) \n",
    "        \n",
    "#         self.Wr  = nn.Parameter(data=torch.Tensor(self.hidden_size, self.hidden_size), requires_grad=True)\n",
    "#         self.Wsr = nn.Parameter(data=torch.Tensor(self.hidden_size, self.embed_size), requires_grad=True) \n",
    "        \n",
    "        \n",
    "#         self.cl  = nn.Parameter(data=torch.Tensor(1, self.hidden_size), requires_grad=True)\n",
    "#         self.cr  = nn.Parameter(data=torch.Tensor(1, self.hidden_size), requires_grad=True)\n",
    "        \n",
    "#         self.relu = nn.ReLU() \n",
    "#         self.fc   = nn.Linear(self.hidden_size * 2 + self.embed_size, self.num_classes)\n",
    "        \n",
    "#         self.reset_parameters()\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         nn.init.kaiming_uniform_(self.Wl, a=np.sqrt(5))\n",
    "#         nn.init.kaiming_uniform_(self.Wsl, a=np.sqrt(5))\n",
    "#         nn.init.kaiming_uniform_(self.Wr, a=np.sqrt(5))\n",
    "#         nn.init.kaiming_uniform_(self.Wsr, a=np.sqrt(5))\n",
    "#         nn.init.kaiming_uniform_(self.cl, a=np.sqrt(5))\n",
    "#         nn.init.kaiming_uniform_(self.cr, a=np.sqrt(5))\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         # create left and right context vectors to be equal to be\n",
    "#         # equal to (batch_size, hidden_size)\n",
    "        \n",
    "#         cl        = self.cl.repeat(x.size(0), 1)\n",
    "#         cr        = self.cr.repeat(x.size(0), 1)\n",
    "        \n",
    "        \n",
    "#         embed     = self.embedding(x)\n",
    "#         cxt       = cl.t()\n",
    "        \n",
    "#         left_context  = []\n",
    "#         right_context = []\n",
    "        \n",
    "#         # O(n)\n",
    "#         for i in range(1, x.size(1)):\n",
    "#             cxt         = self.relu(torch.mm(self.Wl, cxt) + torch.mm(self.Wsl, embed[:, i-1, :].t()))\n",
    "#             left_context.append(cxt)\n",
    "        \n",
    "#         cxt = cr.t()\n",
    "        \n",
    "#         # O(n)\n",
    "#         for i in range(x.size(1)-2, -1, -1):\n",
    "#             cxt         = self.relu(torch.mm(self.Wr, cxt) + torch.mm(self.Wsr, embed[:, i-1, :].t()))\n",
    "#             right_context.append(cxt)\n",
    "        \n",
    "        \n",
    "#         left_context  = torch.cat([cl.t()] + left_context, dim=1)\n",
    "#         left_context  = left_context.view(x.size(0), x.size(1), -1)\n",
    "        \n",
    "#         right_context = torch.cat(right_context + [cr.t()], dim=1).t()\n",
    "#         right_context = right_context.view(x.size(0), x.size(1), -1)\n",
    "        \n",
    "#         # word representation\n",
    "#         word_repr = torch.cat((left_context, embed, right_context), dim=2)\n",
    "        \n",
    "# #         print('WORD REPR ', word_repr.shape)\n",
    "        \n",
    "# #         out = self.fc1(word_repr)\n",
    "# #         out = self.relu(out)\n",
    "        \n",
    "#         # text representation\n",
    "#         out = word_repr.max(dim=1)[0]\n",
    "        \n",
    "#         # final layer\n",
    "#         out = self.fc(out)\n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN2(nn.Module):\n",
    "    def __init__(self, weights, vocab_size, embed_size, hidden_size, num_classes):\n",
    "        super(RCNN2, self).__init__()\n",
    "        \n",
    "        self.vocab_size  = vocab_size\n",
    "        self.embed_size  = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # define embedding\n",
    "        self.embedding        = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.embedding.weight = nn.Parameter(weights)\n",
    "        \n",
    "        # lstm\n",
    "        self.lstm      = nn.LSTM(self.embed_size, self.hidden_size)\n",
    "        \n",
    "        # time-distributed dense\n",
    "        self.td_dense  = nn.Linear(self.hidden_size * 2 + self.embed_size, 32)\n",
    "        \n",
    "        # activation layer\n",
    "        self.relu      = nn.ReLU()\n",
    "        self.tanh      = nn.Tanh()\n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc        = nn.Linear(32, self.num_classes)\n",
    "        \n",
    "        # spatial dropout\n",
    "        self.spatial_dropout = nn.Dropout2d(0.5)\n",
    "        \n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        \n",
    "        x: Batch of sentences\n",
    "        \"\"\"\n",
    "        \n",
    "        # embedding\n",
    "        embed = self.embedding(x)\n",
    "        \n",
    "        # fwd seq\n",
    "        fwd_seq = F.pad(embed, (0, 0, 1, 0, 0, 0))[:, :-1, :]\n",
    "        \n",
    "        # pass through lstm layer\n",
    "        lout, _ = self.lstm(fwd_seq)\n",
    "        \n",
    "        # rev seq\n",
    "        rev_seq = F.pad(embed, (0, 0, 1, 0, 0, 0))[:, 1:, :]\n",
    "        rev_seq = torch.flip(rev_seq, [1])\n",
    "        \n",
    "        rout, _ = self.lstm(rev_seq)\n",
    "        rout    = torch.flip(rout, [1])\n",
    "        \n",
    "        # word representation\n",
    "        w_repr  = torch.cat((lout, embed, rout), dim=2)\n",
    "        \n",
    "        # time distributed dense layer\n",
    "        out     = self.td_dense(w_repr)\n",
    "        \n",
    "        # pass it through relu activation\n",
    "        out     = self.tanh(out)\n",
    "        \n",
    "        # text representation\n",
    "        t_repr, _ = out.max(dim=1)\n",
    "        \n",
    "        t_repr    = self.dropout(t_repr)\n",
    "        \n",
    "        out       = self.fc(t_repr)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, criterion, data, batch_size, optimizer=None):\n",
    "    epoch_loss, total_size = 0, 0\n",
    "    per_label_preds = [[], [], [], [], [], []]\n",
    "    per_label_true  = [[], [], [], [], [], []]\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    model.train(is_train)\n",
    "    \n",
    "    data, labels = data\n",
    "    batchs_count = math.ceil(data.shape[0] / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        for i, (X_batch, y_batch) in enumerate(iterate_batches(data, labels, batch_size)):\n",
    "            X_batch, y_batch = torch.cuda.LongTensor(X_batch), torch.cuda.FloatTensor(y_batch)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            loss   = criterion(logits, y_batch)\n",
    "            \n",
    "            if is_train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # convert true target\n",
    "            batch_target = y_batch.cpu().detach().numpy()\n",
    "            logits_cpu   = logits.cpu().detach().numpy()\n",
    "            \n",
    "            # per_label_preds\n",
    "            for j in range(6):\n",
    "                label_preds     = logits_cpu[:, j]\n",
    "                per_label_preds[j].extend(label_preds)\n",
    "                per_label_true[j].extend(batch_target[:, j])\n",
    "                            \n",
    "            # calculate log loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            print('\\r[{} / {}]: Loss = {:.4f}'.format(\n",
    "                  i, batchs_count, loss.item(), end=''))\n",
    "    \n",
    "    label_auc = []\n",
    "    \n",
    "    for i in range(6):\n",
    "        label_auc.append(roc_auc_score(per_label_true[i], per_label_preds[i]))\n",
    "    \n",
    "    return epoch_loss / batchs_count, np.mean(label_auc)\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, \n",
    "        batch_size=32, val_data=None, val_batch_size=None):\n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_auc = do_epoch(\n",
    "            model, criterion, train_data, batch_size, optimizer\n",
    "        )\n",
    "        \n",
    "        output_info = '\\rEpoch {} / {}, Epoch Time = {:.2f}s: Train Loss = {:.4f}, Train AUC = {:.4f}'\n",
    "        if not val_data is None:\n",
    "            val_loss, val_auc   = do_epoch(model, criterion, val_data, val_batch_size, None)\n",
    "            \n",
    "            epoch_time   = time.time() - start_time\n",
    "            output_info += ', Val Loss = {:.4f}, Val AUC = {:.4f}'\n",
    "            print(output_info.format(epoch+1, epochs_count, epoch_time, \n",
    "                                     train_loss,\n",
    "                                     train_auc,\n",
    "                                     val_loss,\n",
    "                                     val_auc\n",
    "                                    ))\n",
    "        else:\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(output_info.format(epoch+1, epochs_count, epoch_time, train_loss, train_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = as_matrix(data_train['tokenized_comments'], \n",
    "                   token_to_id, \n",
    "                   word_dropout=0, \n",
    "                   UNK_IX=UNK_IX, \n",
    "                   PAD_IX=PAD_IX,\n",
    "                   max_len=MAX_LEN\n",
    "                  )\n",
    "\n",
    "labels = data_train.loc[:, TARGET_COLS].values\n",
    "X, y   = next(iterate_batches(matrix, labels, batch_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cuda.LongTensor(X)\n",
    "y = torch.cuda.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size  = len(token_to_id)\n",
    "embed_size  = 300\n",
    "hidden_size = 2\n",
    "num_classes = 6\n",
    "\n",
    "model =  RCNN2(torch.FloatTensor(embedding_matrix),\n",
    "              vocab_size, \n",
    "              embed_size,\n",
    "              hidden_size,\n",
    "              num_classes\n",
    "              ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2126,  0.0702,  0.1236, -0.2934, -0.0940,  0.1928],\n",
      "        [-0.1989,  0.1868,  0.0017, -0.2311,  0.0167,  0.1820]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "logits = model(X)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on full batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 / 499]: Loss = 0.7376\n",
      "[1 / 499]: Loss = 0.7134\n",
      "[2 / 499]: Loss = 0.6913\n",
      "[3 / 499]: Loss = 0.6705\n",
      "[4 / 499]: Loss = 0.6481\n",
      "[5 / 499]: Loss = 0.6241\n",
      "[6 / 499]: Loss = 0.6030\n",
      "[7 / 499]: Loss = 0.5758\n",
      "[8 / 499]: Loss = 0.5467\n",
      "[9 / 499]: Loss = 0.5248\n",
      "[10 / 499]: Loss = 0.5057\n",
      "[11 / 499]: Loss = 0.4825\n",
      "[12 / 499]: Loss = 0.4602\n",
      "[13 / 499]: Loss = 0.4432\n",
      "[14 / 499]: Loss = 0.4254\n",
      "[15 / 499]: Loss = 0.4103\n",
      "[16 / 499]: Loss = 0.3904\n",
      "[17 / 499]: Loss = 0.3749\n",
      "[18 / 499]: Loss = 0.3535\n",
      "[19 / 499]: Loss = 0.3448\n",
      "[20 / 499]: Loss = 0.3129\n",
      "[21 / 499]: Loss = 0.2963\n",
      "[22 / 499]: Loss = 0.3116\n",
      "[23 / 499]: Loss = 0.2956\n",
      "[24 / 499]: Loss = 0.2598\n",
      "[25 / 499]: Loss = 0.2636\n",
      "[26 / 499]: Loss = 0.2788\n",
      "[27 / 499]: Loss = 0.2663\n",
      "[28 / 499]: Loss = 0.2672\n",
      "[29 / 499]: Loss = 0.2557\n",
      "[30 / 499]: Loss = 0.2564\n",
      "[31 / 499]: Loss = 0.2567\n",
      "[32 / 499]: Loss = 0.2441\n",
      "[33 / 499]: Loss = 0.2418\n",
      "[34 / 499]: Loss = 0.2317\n",
      "[35 / 499]: Loss = 0.2213\n",
      "[36 / 499]: Loss = 0.2153\n",
      "[37 / 499]: Loss = 0.2368\n",
      "[38 / 499]: Loss = 0.1963\n",
      "[39 / 499]: Loss = 0.2055\n",
      "[40 / 499]: Loss = 0.2050\n",
      "[41 / 499]: Loss = 0.1922\n",
      "[42 / 499]: Loss = 0.2129\n",
      "[43 / 499]: Loss = 0.2067\n",
      "[44 / 499]: Loss = 0.2128\n",
      "[45 / 499]: Loss = 0.2104\n",
      "[46 / 499]: Loss = 0.2112\n",
      "[47 / 499]: Loss = 0.2032\n",
      "[48 / 499]: Loss = 0.1874\n",
      "[49 / 499]: Loss = 0.1970\n",
      "[50 / 499]: Loss = 0.1982\n",
      "[51 / 499]: Loss = 0.1786\n",
      "[52 / 499]: Loss = 0.1980\n",
      "[53 / 499]: Loss = 0.1740\n",
      "[54 / 499]: Loss = 0.1728\n",
      "[55 / 499]: Loss = 0.1986\n",
      "[56 / 499]: Loss = 0.1801\n",
      "[57 / 499]: Loss = 0.2125\n",
      "[58 / 499]: Loss = 0.1785\n",
      "[59 / 499]: Loss = 0.1956\n",
      "[60 / 499]: Loss = 0.1920\n",
      "[61 / 499]: Loss = 0.1809\n",
      "[62 / 499]: Loss = 0.1919\n",
      "[63 / 499]: Loss = 0.1878\n",
      "[64 / 499]: Loss = 0.1807\n",
      "[65 / 499]: Loss = 0.1630\n",
      "[66 / 499]: Loss = 0.1392\n",
      "[67 / 499]: Loss = 0.1586\n",
      "[68 / 499]: Loss = 0.1712\n",
      "[69 / 499]: Loss = 0.1672\n",
      "[70 / 499]: Loss = 0.1754\n",
      "[71 / 499]: Loss = 0.1606\n",
      "[72 / 499]: Loss = 0.1937\n",
      "[73 / 499]: Loss = 0.1717\n",
      "[74 / 499]: Loss = 0.1540\n",
      "[75 / 499]: Loss = 0.1598\n",
      "[76 / 499]: Loss = 0.1676\n",
      "[77 / 499]: Loss = 0.1881\n",
      "[78 / 499]: Loss = 0.1740\n",
      "[79 / 499]: Loss = 0.1544\n",
      "[80 / 499]: Loss = 0.1619\n",
      "[81 / 499]: Loss = 0.1623\n",
      "[82 / 499]: Loss = 0.1870\n",
      "[83 / 499]: Loss = 0.1433\n",
      "[84 / 499]: Loss = 0.1360\n",
      "[85 / 499]: Loss = 0.1812\n",
      "[86 / 499]: Loss = 0.1513\n",
      "[87 / 499]: Loss = 0.1829\n",
      "[88 / 499]: Loss = 0.1716\n",
      "[89 / 499]: Loss = 0.1921\n",
      "[90 / 499]: Loss = 0.1272\n",
      "[91 / 499]: Loss = 0.1610\n",
      "[92 / 499]: Loss = 0.1368\n",
      "[93 / 499]: Loss = 0.1530\n",
      "[94 / 499]: Loss = 0.1745\n",
      "[95 / 499]: Loss = 0.1696\n",
      "[96 / 499]: Loss = 0.1464\n",
      "[97 / 499]: Loss = 0.1556\n",
      "[98 / 499]: Loss = 0.1290\n",
      "[99 / 499]: Loss = 0.1206\n",
      "[100 / 499]: Loss = 0.1620\n",
      "[101 / 499]: Loss = 0.1460\n",
      "[102 / 499]: Loss = 0.1407\n",
      "[103 / 499]: Loss = 0.1392\n",
      "[104 / 499]: Loss = 0.1858\n",
      "[105 / 499]: Loss = 0.1336\n",
      "[106 / 499]: Loss = 0.1339\n",
      "[107 / 499]: Loss = 0.1633\n",
      "[108 / 499]: Loss = 0.1738\n",
      "[109 / 499]: Loss = 0.1944\n",
      "[110 / 499]: Loss = 0.1409\n",
      "[111 / 499]: Loss = 0.1427\n",
      "[112 / 499]: Loss = 0.1395\n",
      "[113 / 499]: Loss = 0.1723\n",
      "[114 / 499]: Loss = 0.1396\n",
      "[115 / 499]: Loss = 0.1559\n",
      "[116 / 499]: Loss = 0.1627\n",
      "[117 / 499]: Loss = 0.1652\n",
      "[118 / 499]: Loss = 0.1804\n",
      "[119 / 499]: Loss = 0.1640\n",
      "[120 / 499]: Loss = 0.1333\n",
      "[121 / 499]: Loss = 0.1447\n",
      "[122 / 499]: Loss = 0.1572\n",
      "[123 / 499]: Loss = 0.1370\n",
      "[124 / 499]: Loss = 0.1664\n",
      "[125 / 499]: Loss = 0.1538\n",
      "[126 / 499]: Loss = 0.0994\n",
      "[127 / 499]: Loss = 0.1698\n",
      "[128 / 499]: Loss = 0.1626\n",
      "[129 / 499]: Loss = 0.1579\n",
      "[130 / 499]: Loss = 0.1015\n",
      "[131 / 499]: Loss = 0.1840\n",
      "[132 / 499]: Loss = 0.1742\n",
      "[133 / 499]: Loss = 0.1278\n",
      "[134 / 499]: Loss = 0.1491\n",
      "[135 / 499]: Loss = 0.1542\n",
      "[136 / 499]: Loss = 0.1448\n",
      "[137 / 499]: Loss = 0.1234\n",
      "[138 / 499]: Loss = 0.1450\n",
      "[139 / 499]: Loss = 0.1468\n",
      "[140 / 499]: Loss = 0.1374\n",
      "[141 / 499]: Loss = 0.1182\n",
      "[142 / 499]: Loss = 0.1490\n",
      "[143 / 499]: Loss = 0.1608\n",
      "[144 / 499]: Loss = 0.1248\n",
      "[145 / 499]: Loss = 0.1176\n",
      "[146 / 499]: Loss = 0.1294\n",
      "[147 / 499]: Loss = 0.1562\n",
      "[148 / 499]: Loss = 0.1563\n",
      "[149 / 499]: Loss = 0.0964\n",
      "[150 / 499]: Loss = 0.1467\n",
      "[151 / 499]: Loss = 0.1490\n",
      "[152 / 499]: Loss = 0.1507\n",
      "[153 / 499]: Loss = 0.1328\n",
      "[154 / 499]: Loss = 0.1128\n",
      "[155 / 499]: Loss = 0.1410\n",
      "[156 / 499]: Loss = 0.1176\n",
      "[157 / 499]: Loss = 0.1274\n",
      "[158 / 499]: Loss = 0.1623\n",
      "[159 / 499]: Loss = 0.1306\n",
      "[160 / 499]: Loss = 0.1322\n",
      "[161 / 499]: Loss = 0.1293\n",
      "[162 / 499]: Loss = 0.1099\n",
      "[163 / 499]: Loss = 0.1486\n",
      "[164 / 499]: Loss = 0.1604\n",
      "[165 / 499]: Loss = 0.1551\n",
      "[166 / 499]: Loss = 0.1482\n",
      "[167 / 499]: Loss = 0.1346\n",
      "[168 / 499]: Loss = 0.1679\n",
      "[169 / 499]: Loss = 0.1245\n",
      "[170 / 499]: Loss = 0.1335\n",
      "[171 / 499]: Loss = 0.1095\n",
      "[172 / 499]: Loss = 0.1345\n",
      "[173 / 499]: Loss = 0.1196\n",
      "[174 / 499]: Loss = 0.1651\n",
      "[175 / 499]: Loss = 0.1440\n",
      "[176 / 499]: Loss = 0.1302\n",
      "[177 / 499]: Loss = 0.1344\n",
      "[178 / 499]: Loss = 0.1025\n",
      "[179 / 499]: Loss = 0.1492\n",
      "[180 / 499]: Loss = 0.1039\n",
      "[181 / 499]: Loss = 0.1782\n",
      "[182 / 499]: Loss = 0.1210\n",
      "[183 / 499]: Loss = 0.1568\n",
      "[184 / 499]: Loss = 0.1229\n",
      "[185 / 499]: Loss = 0.1304\n",
      "[186 / 499]: Loss = 0.1758\n",
      "[187 / 499]: Loss = 0.1229\n",
      "[188 / 499]: Loss = 0.1402\n",
      "[189 / 499]: Loss = 0.1195\n",
      "[190 / 499]: Loss = 0.1326\n",
      "[191 / 499]: Loss = 0.1185\n",
      "[192 / 499]: Loss = 0.1137\n",
      "[193 / 499]: Loss = 0.1260\n",
      "[194 / 499]: Loss = 0.1155\n",
      "[195 / 499]: Loss = 0.1405\n",
      "[196 / 499]: Loss = 0.1672\n",
      "[197 / 499]: Loss = 0.1234\n",
      "[198 / 499]: Loss = 0.1300\n",
      "[199 / 499]: Loss = 0.1478\n",
      "[200 / 499]: Loss = 0.1318\n",
      "[201 / 499]: Loss = 0.1615\n",
      "[202 / 499]: Loss = 0.1058\n",
      "[203 / 499]: Loss = 0.1362\n",
      "[204 / 499]: Loss = 0.1212\n",
      "[205 / 499]: Loss = 0.1546\n",
      "[206 / 499]: Loss = 0.1572\n",
      "[207 / 499]: Loss = 0.0846\n",
      "[208 / 499]: Loss = 0.1542\n",
      "[209 / 499]: Loss = 0.1466\n",
      "[210 / 499]: Loss = 0.0973\n",
      "[211 / 499]: Loss = 0.1598\n",
      "[212 / 499]: Loss = 0.1166\n",
      "[213 / 499]: Loss = 0.1139\n",
      "[214 / 499]: Loss = 0.1614\n",
      "[215 / 499]: Loss = 0.1256\n",
      "[216 / 499]: Loss = 0.1206\n",
      "[217 / 499]: Loss = 0.0990\n",
      "[218 / 499]: Loss = 0.0995\n",
      "[219 / 499]: Loss = 0.1229\n",
      "[220 / 499]: Loss = 0.1760\n",
      "[221 / 499]: Loss = 0.1333\n",
      "[222 / 499]: Loss = 0.1484\n",
      "[223 / 499]: Loss = 0.1200\n",
      "[224 / 499]: Loss = 0.1517\n",
      "[225 / 499]: Loss = 0.1156\n",
      "[226 / 499]: Loss = 0.1206\n",
      "[227 / 499]: Loss = 0.1540\n",
      "[228 / 499]: Loss = 0.1338\n",
      "[229 / 499]: Loss = 0.1299\n",
      "[230 / 499]: Loss = 0.1652\n",
      "[231 / 499]: Loss = 0.1208\n",
      "[232 / 499]: Loss = 0.1427\n",
      "[233 / 499]: Loss = 0.1396\n",
      "[234 / 499]: Loss = 0.1565\n",
      "[235 / 499]: Loss = 0.1162\n",
      "[236 / 499]: Loss = 0.1147\n",
      "[237 / 499]: Loss = 0.1223\n",
      "[238 / 499]: Loss = 0.1685\n",
      "[239 / 499]: Loss = 0.1101\n",
      "[240 / 499]: Loss = 0.1616\n",
      "[241 / 499]: Loss = 0.1341\n",
      "[242 / 499]: Loss = 0.1341\n",
      "[243 / 499]: Loss = 0.0885\n",
      "[244 / 499]: Loss = 0.1335\n",
      "[245 / 499]: Loss = 0.1541\n",
      "[246 / 499]: Loss = 0.1261\n",
      "[247 / 499]: Loss = 0.1070\n",
      "[248 / 499]: Loss = 0.1280\n",
      "[249 / 499]: Loss = 0.1026\n",
      "[250 / 499]: Loss = 0.1067\n",
      "[251 / 499]: Loss = 0.1231\n",
      "[252 / 499]: Loss = 0.1219\n",
      "[253 / 499]: Loss = 0.1349\n",
      "[254 / 499]: Loss = 0.1515\n",
      "[255 / 499]: Loss = 0.1602\n",
      "[256 / 499]: Loss = 0.0971\n",
      "[257 / 499]: Loss = 0.1315\n",
      "[258 / 499]: Loss = 0.1130\n",
      "[259 / 499]: Loss = 0.1074\n",
      "[260 / 499]: Loss = 0.1310\n",
      "[261 / 499]: Loss = 0.1231\n",
      "[262 / 499]: Loss = 0.1313\n",
      "[263 / 499]: Loss = 0.1199\n",
      "[264 / 499]: Loss = 0.1479\n",
      "[265 / 499]: Loss = 0.1115\n",
      "[266 / 499]: Loss = 0.1324\n",
      "[267 / 499]: Loss = 0.1176\n",
      "[268 / 499]: Loss = 0.1309\n",
      "[269 / 499]: Loss = 0.1137\n",
      "[270 / 499]: Loss = 0.1330\n",
      "[271 / 499]: Loss = 0.1514\n",
      "[272 / 499]: Loss = 0.1278\n",
      "[273 / 499]: Loss = 0.1465\n",
      "[274 / 499]: Loss = 0.1318\n",
      "[275 / 499]: Loss = 0.1372\n",
      "[276 / 499]: Loss = 0.1487\n",
      "[277 / 499]: Loss = 0.0892\n",
      "[278 / 499]: Loss = 0.1047\n",
      "[279 / 499]: Loss = 0.1505\n",
      "[280 / 499]: Loss = 0.1361\n",
      "[281 / 499]: Loss = 0.1049\n",
      "[282 / 499]: Loss = 0.1524\n",
      "[283 / 499]: Loss = 0.1443\n",
      "[284 / 499]: Loss = 0.1431\n",
      "[285 / 499]: Loss = 0.1498\n",
      "[286 / 499]: Loss = 0.1029\n",
      "[287 / 499]: Loss = 0.1626\n",
      "[288 / 499]: Loss = 0.1390\n",
      "[289 / 499]: Loss = 0.1080\n",
      "[290 / 499]: Loss = 0.1181\n",
      "[291 / 499]: Loss = 0.1134\n",
      "[292 / 499]: Loss = 0.1217\n",
      "[293 / 499]: Loss = 0.1241\n",
      "[294 / 499]: Loss = 0.1380\n",
      "[295 / 499]: Loss = 0.1300\n",
      "[296 / 499]: Loss = 0.1375\n",
      "[297 / 499]: Loss = 0.1337\n",
      "[298 / 499]: Loss = 0.1293\n",
      "[299 / 499]: Loss = 0.0896\n",
      "[300 / 499]: Loss = 0.1364\n",
      "[301 / 499]: Loss = 0.1160\n",
      "[302 / 499]: Loss = 0.1225\n",
      "[303 / 499]: Loss = 0.1153\n",
      "[304 / 499]: Loss = 0.1416\n",
      "[305 / 499]: Loss = 0.1379\n",
      "[306 / 499]: Loss = 0.1311\n",
      "[307 / 499]: Loss = 0.1013\n",
      "[308 / 499]: Loss = 0.1200\n",
      "[309 / 499]: Loss = 0.1020\n",
      "[310 / 499]: Loss = 0.1198\n",
      "[311 / 499]: Loss = 0.1133\n",
      "[312 / 499]: Loss = 0.1324\n",
      "[313 / 499]: Loss = 0.1576\n",
      "[314 / 499]: Loss = 0.1239\n",
      "[315 / 499]: Loss = 0.1482\n",
      "[316 / 499]: Loss = 0.1080\n",
      "[317 / 499]: Loss = 0.1211\n",
      "[318 / 499]: Loss = 0.1214\n",
      "[319 / 499]: Loss = 0.0994\n",
      "[320 / 499]: Loss = 0.1330\n",
      "[321 / 499]: Loss = 0.1221\n",
      "[322 / 499]: Loss = 0.1274\n",
      "[323 / 499]: Loss = 0.1369\n",
      "[324 / 499]: Loss = 0.0990\n",
      "[325 / 499]: Loss = 0.1563\n",
      "[326 / 499]: Loss = 0.1149\n",
      "[327 / 499]: Loss = 0.1099\n",
      "[328 / 499]: Loss = 0.1490\n",
      "[329 / 499]: Loss = 0.1489\n",
      "[330 / 499]: Loss = 0.1245\n",
      "[331 / 499]: Loss = 0.1160\n",
      "[332 / 499]: Loss = 0.1402\n",
      "[333 / 499]: Loss = 0.1642\n",
      "[334 / 499]: Loss = 0.1202\n",
      "[335 / 499]: Loss = 0.1375\n",
      "[336 / 499]: Loss = 0.1373\n",
      "[337 / 499]: Loss = 0.1255\n",
      "[338 / 499]: Loss = 0.1211\n",
      "[339 / 499]: Loss = 0.1058\n",
      "[340 / 499]: Loss = 0.1090\n",
      "[341 / 499]: Loss = 0.0964\n",
      "[342 / 499]: Loss = 0.1129\n",
      "[343 / 499]: Loss = 0.1028\n",
      "[344 / 499]: Loss = 0.1155\n",
      "[345 / 499]: Loss = 0.1352\n",
      "[346 / 499]: Loss = 0.1265\n",
      "[347 / 499]: Loss = 0.1055\n",
      "[348 / 499]: Loss = 0.1253\n",
      "[349 / 499]: Loss = 0.1318\n",
      "[350 / 499]: Loss = 0.1080\n",
      "[351 / 499]: Loss = 0.1352\n",
      "[352 / 499]: Loss = 0.1442\n",
      "[353 / 499]: Loss = 0.1360\n",
      "[354 / 499]: Loss = 0.1037\n",
      "[355 / 499]: Loss = 0.1308\n",
      "[356 / 499]: Loss = 0.1362\n",
      "[357 / 499]: Loss = 0.1148\n",
      "[358 / 499]: Loss = 0.1061\n",
      "[359 / 499]: Loss = 0.1192\n",
      "[360 / 499]: Loss = 0.1013\n",
      "[361 / 499]: Loss = 0.0879\n",
      "[362 / 499]: Loss = 0.1215\n",
      "[363 / 499]: Loss = 0.1245\n",
      "[364 / 499]: Loss = 0.1271\n",
      "[365 / 499]: Loss = 0.1422\n",
      "[366 / 499]: Loss = 0.1179\n",
      "[367 / 499]: Loss = 0.1095\n",
      "[368 / 499]: Loss = 0.1121\n",
      "[369 / 499]: Loss = 0.1370\n",
      "[370 / 499]: Loss = 0.1194\n",
      "[371 / 499]: Loss = 0.1520\n",
      "[372 / 499]: Loss = 0.1007\n",
      "[373 / 499]: Loss = 0.1057\n",
      "[374 / 499]: Loss = 0.1312\n",
      "[375 / 499]: Loss = 0.1071\n",
      "[376 / 499]: Loss = 0.1191\n",
      "[377 / 499]: Loss = 0.1091\n",
      "[378 / 499]: Loss = 0.1031\n",
      "[379 / 499]: Loss = 0.1148\n",
      "[380 / 499]: Loss = 0.1308\n",
      "[381 / 499]: Loss = 0.0920\n",
      "[382 / 499]: Loss = 0.1239\n",
      "[383 / 499]: Loss = 0.1220\n",
      "[384 / 499]: Loss = 0.1219\n",
      "[385 / 499]: Loss = 0.1064\n",
      "[386 / 499]: Loss = 0.1303\n",
      "[387 / 499]: Loss = 0.0977\n",
      "[388 / 499]: Loss = 0.1045\n",
      "[389 / 499]: Loss = 0.1204\n",
      "[390 / 499]: Loss = 0.0804\n",
      "[391 / 499]: Loss = 0.1092\n",
      "[392 / 499]: Loss = 0.1133\n",
      "[393 / 499]: Loss = 0.0976\n",
      "[394 / 499]: Loss = 0.1159\n",
      "[395 / 499]: Loss = 0.1371\n",
      "[396 / 499]: Loss = 0.0930\n",
      "[397 / 499]: Loss = 0.1082\n",
      "[398 / 499]: Loss = 0.0972\n",
      "[399 / 499]: Loss = 0.0972\n",
      "[400 / 499]: Loss = 0.0889\n",
      "[401 / 499]: Loss = 0.1187\n",
      "[402 / 499]: Loss = 0.1288\n",
      "[403 / 499]: Loss = 0.0979\n",
      "[404 / 499]: Loss = 0.1059\n",
      "[405 / 499]: Loss = 0.0887\n",
      "[406 / 499]: Loss = 0.1102\n",
      "[407 / 499]: Loss = 0.1336\n",
      "[408 / 499]: Loss = 0.1182\n",
      "[409 / 499]: Loss = 0.0962\n",
      "[410 / 499]: Loss = 0.1033\n",
      "[411 / 499]: Loss = 0.1232\n",
      "[412 / 499]: Loss = 0.0912\n",
      "[413 / 499]: Loss = 0.1132\n",
      "[414 / 499]: Loss = 0.1161\n",
      "[415 / 499]: Loss = 0.0794\n",
      "[416 / 499]: Loss = 0.1023\n",
      "[417 / 499]: Loss = 0.1108\n",
      "[418 / 499]: Loss = 0.0827\n",
      "[419 / 499]: Loss = 0.1249\n",
      "[420 / 499]: Loss = 0.1224\n",
      "[421 / 499]: Loss = 0.1258\n",
      "[422 / 499]: Loss = 0.1086\n",
      "[423 / 499]: Loss = 0.1087\n",
      "[424 / 499]: Loss = 0.0951\n",
      "[425 / 499]: Loss = 0.0968\n",
      "[426 / 499]: Loss = 0.1257\n",
      "[427 / 499]: Loss = 0.1139\n",
      "[428 / 499]: Loss = 0.0969\n",
      "[429 / 499]: Loss = 0.0936\n",
      "[430 / 499]: Loss = 0.0863\n",
      "[431 / 499]: Loss = 0.1018\n",
      "[432 / 499]: Loss = 0.0947\n",
      "[433 / 499]: Loss = 0.1182\n",
      "[434 / 499]: Loss = 0.1226\n",
      "[435 / 499]: Loss = 0.1177\n",
      "[436 / 499]: Loss = 0.1040\n",
      "[437 / 499]: Loss = 0.0873\n",
      "[438 / 499]: Loss = 0.1025\n",
      "[439 / 499]: Loss = 0.1267\n",
      "[440 / 499]: Loss = 0.1055\n",
      "[441 / 499]: Loss = 0.0985\n",
      "[442 / 499]: Loss = 0.0990\n",
      "[443 / 499]: Loss = 0.0895\n",
      "[444 / 499]: Loss = 0.0957\n",
      "[445 / 499]: Loss = 0.0813\n",
      "[446 / 499]: Loss = 0.0897\n",
      "[447 / 499]: Loss = 0.1161\n",
      "[448 / 499]: Loss = 0.0697\n",
      "[449 / 499]: Loss = 0.0922\n",
      "[450 / 499]: Loss = 0.0887\n",
      "[451 / 499]: Loss = 0.1000\n",
      "[452 / 499]: Loss = 0.0956\n",
      "[453 / 499]: Loss = 0.1147\n",
      "[454 / 499]: Loss = 0.1001\n",
      "[455 / 499]: Loss = 0.1266\n",
      "[456 / 499]: Loss = 0.0946\n",
      "[457 / 499]: Loss = 0.0871\n",
      "[458 / 499]: Loss = 0.0659\n",
      "[459 / 499]: Loss = 0.0746\n",
      "[460 / 499]: Loss = 0.0807\n",
      "[461 / 499]: Loss = 0.0918\n",
      "[462 / 499]: Loss = 0.0941\n",
      "[463 / 499]: Loss = 0.1128\n",
      "[464 / 499]: Loss = 0.0881\n",
      "[465 / 499]: Loss = 0.1047\n",
      "[466 / 499]: Loss = 0.1016\n",
      "[467 / 499]: Loss = 0.0801\n",
      "[468 / 499]: Loss = 0.0789\n",
      "[469 / 499]: Loss = 0.0693\n",
      "[470 / 499]: Loss = 0.0990\n",
      "[471 / 499]: Loss = 0.0937\n",
      "[472 / 499]: Loss = 0.1229\n",
      "[473 / 499]: Loss = 0.1246\n",
      "[474 / 499]: Loss = 0.0941\n",
      "[475 / 499]: Loss = 0.0850\n",
      "[476 / 499]: Loss = 0.0853\n",
      "[477 / 499]: Loss = 0.0811\n",
      "[478 / 499]: Loss = 0.0925\n",
      "[479 / 499]: Loss = 0.0856\n",
      "[480 / 499]: Loss = 0.0684\n",
      "[481 / 499]: Loss = 0.0903\n",
      "[482 / 499]: Loss = 0.0936\n",
      "[483 / 499]: Loss = 0.0957\n",
      "[484 / 499]: Loss = 0.0966\n",
      "[485 / 499]: Loss = 0.0893\n",
      "[486 / 499]: Loss = 0.0787\n",
      "[487 / 499]: Loss = 0.0933\n",
      "[488 / 499]: Loss = 0.0628\n",
      "[489 / 499]: Loss = 0.0870\n",
      "[490 / 499]: Loss = 0.0623\n",
      "[491 / 499]: Loss = 0.0709\n",
      "[492 / 499]: Loss = 0.0837\n",
      "[493 / 499]: Loss = 0.0697\n",
      "[494 / 499]: Loss = 0.0896\n",
      "[495 / 499]: Loss = 0.0833\n",
      "[496 / 499]: Loss = 0.0800\n",
      "[497 / 499]: Loss = 0.0743\n",
      "[498 / 499]: Loss = 0.0685\n",
      "[0 / 32]: Loss = 0.0671\n",
      "[1 / 32]: Loss = 0.0700\n",
      "[2 / 32]: Loss = 0.0719\n",
      "[3 / 32]: Loss = 0.0799\n",
      "[4 / 32]: Loss = 0.0637\n",
      "[5 / 32]: Loss = 0.0754\n",
      "[6 / 32]: Loss = 0.0800\n",
      "[7 / 32]: Loss = 0.0687\n",
      "[8 / 32]: Loss = 0.0656\n",
      "[9 / 32]: Loss = 0.0706\n",
      "[10 / 32]: Loss = 0.0782\n",
      "[11 / 32]: Loss = 0.0673\n",
      "[12 / 32]: Loss = 0.0837\n",
      "[13 / 32]: Loss = 0.0741\n",
      "[14 / 32]: Loss = 0.0793\n",
      "[15 / 32]: Loss = 0.0675\n",
      "[16 / 32]: Loss = 0.0698\n",
      "[17 / 32]: Loss = 0.0787\n",
      "[18 / 32]: Loss = 0.0713\n",
      "[19 / 32]: Loss = 0.0641\n",
      "[20 / 32]: Loss = 0.0868\n",
      "[21 / 32]: Loss = 0.0752\n",
      "[22 / 32]: Loss = 0.0755\n",
      "[23 / 32]: Loss = 0.0744\n",
      "[24 / 32]: Loss = 0.0770\n",
      "[25 / 32]: Loss = 0.0617\n",
      "[26 / 32]: Loss = 0.0798\n",
      "[27 / 32]: Loss = 0.0684\n",
      "[28 / 32]: Loss = 0.0722\n",
      "[29 / 32]: Loss = 0.0773\n",
      "[30 / 32]: Loss = 0.0701\n",
      "[31 / 32]: Loss = 0.0886\n",
      "Epoch 1 / 3, Epoch Time = 211.96s: Train Loss = 0.1501, Train AUC = 0.6910, Val Loss = 0.0736, Val AUC = 0.9543\n",
      "[0 / 499]: Loss = 0.0850\n",
      "[1 / 499]: Loss = 0.0524\n",
      "[2 / 499]: Loss = 0.0708\n",
      "[3 / 499]: Loss = 0.0750\n",
      "[4 / 499]: Loss = 0.0714\n",
      "[5 / 499]: Loss = 0.0710\n",
      "[6 / 499]: Loss = 0.0887\n",
      "[7 / 499]: Loss = 0.0511\n",
      "[8 / 499]: Loss = 0.0844\n",
      "[9 / 499]: Loss = 0.0694\n",
      "[10 / 499]: Loss = 0.0712\n",
      "[11 / 499]: Loss = 0.0910\n",
      "[12 / 499]: Loss = 0.0683\n",
      "[13 / 499]: Loss = 0.0798\n",
      "[14 / 499]: Loss = 0.0749\n",
      "[15 / 499]: Loss = 0.0784\n",
      "[16 / 499]: Loss = 0.0777\n",
      "[17 / 499]: Loss = 0.0859\n",
      "[18 / 499]: Loss = 0.0741\n",
      "[19 / 499]: Loss = 0.0653\n",
      "[20 / 499]: Loss = 0.0859\n",
      "[21 / 499]: Loss = 0.0848\n",
      "[22 / 499]: Loss = 0.0635\n",
      "[23 / 499]: Loss = 0.0613\n",
      "[24 / 499]: Loss = 0.0675\n",
      "[25 / 499]: Loss = 0.0558\n",
      "[26 / 499]: Loss = 0.0794\n",
      "[27 / 499]: Loss = 0.0744\n",
      "[28 / 499]: Loss = 0.0792\n",
      "[29 / 499]: Loss = 0.0676\n",
      "[30 / 499]: Loss = 0.0758\n",
      "[31 / 499]: Loss = 0.0742\n",
      "[32 / 499]: Loss = 0.0842\n",
      "[33 / 499]: Loss = 0.0980\n",
      "[34 / 499]: Loss = 0.0607\n",
      "[35 / 499]: Loss = 0.0594\n",
      "[36 / 499]: Loss = 0.0631\n",
      "[37 / 499]: Loss = 0.0726\n",
      "[38 / 499]: Loss = 0.0655\n",
      "[39 / 499]: Loss = 0.0796\n",
      "[40 / 499]: Loss = 0.0871\n",
      "[41 / 499]: Loss = 0.0941\n",
      "[42 / 499]: Loss = 0.0586\n",
      "[43 / 499]: Loss = 0.0609\n",
      "[44 / 499]: Loss = 0.0606\n",
      "[45 / 499]: Loss = 0.0669\n",
      "[46 / 499]: Loss = 0.0755\n",
      "[47 / 499]: Loss = 0.0703\n",
      "[48 / 499]: Loss = 0.0709\n",
      "[49 / 499]: Loss = 0.0557\n",
      "[50 / 499]: Loss = 0.0781\n",
      "[51 / 499]: Loss = 0.0700\n",
      "[52 / 499]: Loss = 0.0534\n",
      "[53 / 499]: Loss = 0.0754\n",
      "[54 / 499]: Loss = 0.0768\n",
      "[55 / 499]: Loss = 0.0597\n",
      "[56 / 499]: Loss = 0.0674\n",
      "[57 / 499]: Loss = 0.0642\n",
      "[58 / 499]: Loss = 0.0851\n",
      "[59 / 499]: Loss = 0.0619\n",
      "[60 / 499]: Loss = 0.0641\n",
      "[61 / 499]: Loss = 0.0807\n",
      "[62 / 499]: Loss = 0.0709\n",
      "[63 / 499]: Loss = 0.0781\n",
      "[64 / 499]: Loss = 0.0677\n",
      "[65 / 499]: Loss = 0.0550\n",
      "[66 / 499]: Loss = 0.0694\n",
      "[67 / 499]: Loss = 0.0747\n",
      "[68 / 499]: Loss = 0.0657\n",
      "[69 / 499]: Loss = 0.0712\n",
      "[70 / 499]: Loss = 0.0838\n",
      "[71 / 499]: Loss = 0.0775\n",
      "[72 / 499]: Loss = 0.0807\n",
      "[73 / 499]: Loss = 0.0531\n",
      "[74 / 499]: Loss = 0.0845\n",
      "[75 / 499]: Loss = 0.0586\n",
      "[76 / 499]: Loss = 0.0557\n",
      "[77 / 499]: Loss = 0.0681\n",
      "[78 / 499]: Loss = 0.0609\n",
      "[79 / 499]: Loss = 0.0494\n",
      "[80 / 499]: Loss = 0.0500\n",
      "[81 / 499]: Loss = 0.0623\n",
      "[82 / 499]: Loss = 0.0697\n",
      "[83 / 499]: Loss = 0.0665\n",
      "[84 / 499]: Loss = 0.0763\n",
      "[85 / 499]: Loss = 0.0926\n",
      "[86 / 499]: Loss = 0.0607\n",
      "[87 / 499]: Loss = 0.0900\n",
      "[88 / 499]: Loss = 0.0760\n",
      "[89 / 499]: Loss = 0.0579\n",
      "[90 / 499]: Loss = 0.0607\n",
      "[91 / 499]: Loss = 0.0665\n",
      "[92 / 499]: Loss = 0.0604\n",
      "[93 / 499]: Loss = 0.0507\n",
      "[94 / 499]: Loss = 0.0713\n",
      "[95 / 499]: Loss = 0.0681\n",
      "[96 / 499]: Loss = 0.0728\n",
      "[97 / 499]: Loss = 0.0578\n",
      "[98 / 499]: Loss = 0.0570\n",
      "[99 / 499]: Loss = 0.0675\n",
      "[100 / 499]: Loss = 0.0635\n",
      "[101 / 499]: Loss = 0.0671\n",
      "[102 / 499]: Loss = 0.0612\n",
      "[103 / 499]: Loss = 0.0650\n",
      "[104 / 499]: Loss = 0.0573\n",
      "[105 / 499]: Loss = 0.0554\n",
      "[106 / 499]: Loss = 0.0599\n",
      "[107 / 499]: Loss = 0.0712\n",
      "[108 / 499]: Loss = 0.0713\n",
      "[109 / 499]: Loss = 0.0580\n",
      "[110 / 499]: Loss = 0.0597\n",
      "[111 / 499]: Loss = 0.0729\n",
      "[112 / 499]: Loss = 0.0685\n",
      "[113 / 499]: Loss = 0.0567\n",
      "[114 / 499]: Loss = 0.0592\n",
      "[115 / 499]: Loss = 0.0807\n",
      "[116 / 499]: Loss = 0.0691\n",
      "[117 / 499]: Loss = 0.0650\n",
      "[118 / 499]: Loss = 0.0465\n",
      "[119 / 499]: Loss = 0.0823\n",
      "[120 / 499]: Loss = 0.0817\n",
      "[121 / 499]: Loss = 0.0549\n",
      "[122 / 499]: Loss = 0.0571\n",
      "[123 / 499]: Loss = 0.0467\n",
      "[124 / 499]: Loss = 0.0692\n",
      "[125 / 499]: Loss = 0.0513\n",
      "[126 / 499]: Loss = 0.0532\n",
      "[127 / 499]: Loss = 0.0686\n",
      "[128 / 499]: Loss = 0.0595\n",
      "[129 / 499]: Loss = 0.0825\n",
      "[130 / 499]: Loss = 0.0723\n",
      "[131 / 499]: Loss = 0.0640\n",
      "[132 / 499]: Loss = 0.0592\n",
      "[133 / 499]: Loss = 0.0555\n",
      "[134 / 499]: Loss = 0.0527\n",
      "[135 / 499]: Loss = 0.0748\n",
      "[136 / 499]: Loss = 0.0618\n",
      "[137 / 499]: Loss = 0.0547\n",
      "[138 / 499]: Loss = 0.0604\n",
      "[139 / 499]: Loss = 0.0531\n",
      "[140 / 499]: Loss = 0.0360\n",
      "[141 / 499]: Loss = 0.0743\n",
      "[142 / 499]: Loss = 0.0654\n",
      "[143 / 499]: Loss = 0.0566\n",
      "[144 / 499]: Loss = 0.0897\n",
      "[145 / 499]: Loss = 0.0658\n",
      "[146 / 499]: Loss = 0.0792\n",
      "[147 / 499]: Loss = 0.0579\n",
      "[148 / 499]: Loss = 0.0730\n",
      "[149 / 499]: Loss = 0.0814\n",
      "[150 / 499]: Loss = 0.0714\n",
      "[151 / 499]: Loss = 0.0764\n",
      "[152 / 499]: Loss = 0.0786\n",
      "[153 / 499]: Loss = 0.0791\n",
      "[154 / 499]: Loss = 0.0755\n",
      "[155 / 499]: Loss = 0.0826\n",
      "[156 / 499]: Loss = 0.0645\n",
      "[157 / 499]: Loss = 0.0747\n",
      "[158 / 499]: Loss = 0.0879\n",
      "[159 / 499]: Loss = 0.0530\n",
      "[160 / 499]: Loss = 0.0576\n",
      "[161 / 499]: Loss = 0.0565\n",
      "[162 / 499]: Loss = 0.0587\n",
      "[163 / 499]: Loss = 0.0582\n",
      "[164 / 499]: Loss = 0.0624\n",
      "[165 / 499]: Loss = 0.0529\n",
      "[166 / 499]: Loss = 0.0535\n",
      "[167 / 499]: Loss = 0.0773\n",
      "[168 / 499]: Loss = 0.0745\n",
      "[169 / 499]: Loss = 0.0494\n",
      "[170 / 499]: Loss = 0.0503\n",
      "[171 / 499]: Loss = 0.0742\n",
      "[172 / 499]: Loss = 0.0820\n",
      "[173 / 499]: Loss = 0.0531\n",
      "[174 / 499]: Loss = 0.0824\n",
      "[175 / 499]: Loss = 0.0597\n",
      "[176 / 499]: Loss = 0.0695\n",
      "[177 / 499]: Loss = 0.0700\n",
      "[178 / 499]: Loss = 0.0473\n",
      "[179 / 499]: Loss = 0.0622\n",
      "[180 / 499]: Loss = 0.0656\n",
      "[181 / 499]: Loss = 0.0439\n",
      "[182 / 499]: Loss = 0.0644\n",
      "[183 / 499]: Loss = 0.0752\n",
      "[184 / 499]: Loss = 0.0518\n",
      "[185 / 499]: Loss = 0.0606\n",
      "[186 / 499]: Loss = 0.0708\n",
      "[187 / 499]: Loss = 0.0641\n",
      "[188 / 499]: Loss = 0.0760\n",
      "[189 / 499]: Loss = 0.1003\n",
      "[190 / 499]: Loss = 0.0637\n",
      "[191 / 499]: Loss = 0.0600\n",
      "[192 / 499]: Loss = 0.0639\n",
      "[193 / 499]: Loss = 0.0582\n",
      "[194 / 499]: Loss = 0.0586\n",
      "[195 / 499]: Loss = 0.0578\n",
      "[196 / 499]: Loss = 0.0537\n",
      "[197 / 499]: Loss = 0.0442\n",
      "[198 / 499]: Loss = 0.0527\n",
      "[199 / 499]: Loss = 0.0434\n",
      "[200 / 499]: Loss = 0.0533\n",
      "[201 / 499]: Loss = 0.0653\n",
      "[202 / 499]: Loss = 0.0580\n",
      "[203 / 499]: Loss = 0.0808\n",
      "[204 / 499]: Loss = 0.0685\n",
      "[205 / 499]: Loss = 0.0813\n",
      "[206 / 499]: Loss = 0.0643\n",
      "[207 / 499]: Loss = 0.0707\n",
      "[208 / 499]: Loss = 0.0598\n",
      "[209 / 499]: Loss = 0.0584\n",
      "[210 / 499]: Loss = 0.0716\n",
      "[211 / 499]: Loss = 0.0639\n",
      "[212 / 499]: Loss = 0.0576\n",
      "[213 / 499]: Loss = 0.0684\n",
      "[214 / 499]: Loss = 0.0522\n",
      "[215 / 499]: Loss = 0.0530\n",
      "[216 / 499]: Loss = 0.0528\n",
      "[217 / 499]: Loss = 0.0621\n",
      "[218 / 499]: Loss = 0.0649\n",
      "[219 / 499]: Loss = 0.0405\n",
      "[220 / 499]: Loss = 0.0691\n",
      "[221 / 499]: Loss = 0.0708\n",
      "[222 / 499]: Loss = 0.0465\n",
      "[223 / 499]: Loss = 0.0604\n",
      "[224 / 499]: Loss = 0.0654\n",
      "[225 / 499]: Loss = 0.0624\n",
      "[226 / 499]: Loss = 0.0620\n",
      "[227 / 499]: Loss = 0.0672\n",
      "[228 / 499]: Loss = 0.0802\n",
      "[229 / 499]: Loss = 0.0790\n",
      "[230 / 499]: Loss = 0.0487\n",
      "[231 / 499]: Loss = 0.0599\n",
      "[232 / 499]: Loss = 0.0609\n",
      "[233 / 499]: Loss = 0.0910\n",
      "[234 / 499]: Loss = 0.0696\n",
      "[235 / 499]: Loss = 0.0494\n",
      "[236 / 499]: Loss = 0.0463\n",
      "[237 / 499]: Loss = 0.0536\n",
      "[238 / 499]: Loss = 0.0562\n",
      "[239 / 499]: Loss = 0.0814\n",
      "[240 / 499]: Loss = 0.0642\n",
      "[241 / 499]: Loss = 0.0529\n",
      "[242 / 499]: Loss = 0.0574\n",
      "[243 / 499]: Loss = 0.0399\n",
      "[244 / 499]: Loss = 0.0578\n",
      "[245 / 499]: Loss = 0.0744\n",
      "[246 / 499]: Loss = 0.0627\n",
      "[247 / 499]: Loss = 0.0581\n",
      "[248 / 499]: Loss = 0.0490\n",
      "[249 / 499]: Loss = 0.0979\n",
      "[250 / 499]: Loss = 0.0339\n",
      "[251 / 499]: Loss = 0.0538\n",
      "[252 / 499]: Loss = 0.0616\n",
      "[253 / 499]: Loss = 0.0522\n",
      "[254 / 499]: Loss = 0.0548\n",
      "[255 / 499]: Loss = 0.0538\n",
      "[256 / 499]: Loss = 0.0541\n",
      "[257 / 499]: Loss = 0.0474\n",
      "[258 / 499]: Loss = 0.0462\n",
      "[259 / 499]: Loss = 0.0660\n",
      "[260 / 499]: Loss = 0.0938\n",
      "[261 / 499]: Loss = 0.0515\n",
      "[262 / 499]: Loss = 0.0613\n",
      "[263 / 499]: Loss = 0.0668\n",
      "[264 / 499]: Loss = 0.0719\n",
      "[265 / 499]: Loss = 0.0457\n",
      "[266 / 499]: Loss = 0.0697\n",
      "[267 / 499]: Loss = 0.0692\n",
      "[268 / 499]: Loss = 0.0598\n",
      "[269 / 499]: Loss = 0.0583\n",
      "[270 / 499]: Loss = 0.0611\n",
      "[271 / 499]: Loss = 0.0578\n",
      "[272 / 499]: Loss = 0.0445\n",
      "[273 / 499]: Loss = 0.0477\n",
      "[274 / 499]: Loss = 0.0606\n",
      "[275 / 499]: Loss = 0.0412\n",
      "[276 / 499]: Loss = 0.0568\n",
      "[277 / 499]: Loss = 0.0519\n",
      "[278 / 499]: Loss = 0.0707\n",
      "[279 / 499]: Loss = 0.0520\n",
      "[280 / 499]: Loss = 0.0773\n",
      "[281 / 499]: Loss = 0.0646\n",
      "[282 / 499]: Loss = 0.0575\n",
      "[283 / 499]: Loss = 0.0620\n",
      "[284 / 499]: Loss = 0.0631\n",
      "[285 / 499]: Loss = 0.0514\n",
      "[286 / 499]: Loss = 0.0609\n",
      "[287 / 499]: Loss = 0.0617\n",
      "[288 / 499]: Loss = 0.0618\n",
      "[289 / 499]: Loss = 0.0806\n",
      "[290 / 499]: Loss = 0.0601\n",
      "[291 / 499]: Loss = 0.0617\n",
      "[292 / 499]: Loss = 0.0654\n",
      "[293 / 499]: Loss = 0.0690\n",
      "[294 / 499]: Loss = 0.0704\n",
      "[295 / 499]: Loss = 0.0530\n",
      "[296 / 499]: Loss = 0.0664\n",
      "[297 / 499]: Loss = 0.0512\n",
      "[298 / 499]: Loss = 0.0634\n",
      "[299 / 499]: Loss = 0.0515\n",
      "[300 / 499]: Loss = 0.0511\n",
      "[301 / 499]: Loss = 0.0637\n",
      "[302 / 499]: Loss = 0.0474\n",
      "[303 / 499]: Loss = 0.0613\n",
      "[304 / 499]: Loss = 0.0440\n",
      "[305 / 499]: Loss = 0.0435\n",
      "[306 / 499]: Loss = 0.0454\n",
      "[307 / 499]: Loss = 0.0408\n",
      "[308 / 499]: Loss = 0.0782\n",
      "[309 / 499]: Loss = 0.0529\n",
      "[310 / 499]: Loss = 0.0411\n",
      "[311 / 499]: Loss = 0.0844\n",
      "[312 / 499]: Loss = 0.0897\n",
      "[313 / 499]: Loss = 0.0460\n",
      "[314 / 499]: Loss = 0.0785\n",
      "[315 / 499]: Loss = 0.0668\n",
      "[316 / 499]: Loss = 0.0506\n",
      "[317 / 499]: Loss = 0.0685\n",
      "[318 / 499]: Loss = 0.0548\n",
      "[319 / 499]: Loss = 0.0520\n",
      "[320 / 499]: Loss = 0.0677\n",
      "[321 / 499]: Loss = 0.0654\n",
      "[322 / 499]: Loss = 0.0573\n",
      "[323 / 499]: Loss = 0.0724\n",
      "[324 / 499]: Loss = 0.0734\n",
      "[325 / 499]: Loss = 0.0559\n",
      "[326 / 499]: Loss = 0.0544\n",
      "[327 / 499]: Loss = 0.0653\n",
      "[328 / 499]: Loss = 0.0696\n",
      "[329 / 499]: Loss = 0.0764\n",
      "[330 / 499]: Loss = 0.0546\n",
      "[331 / 499]: Loss = 0.0540\n",
      "[332 / 499]: Loss = 0.0714\n",
      "[333 / 499]: Loss = 0.0729\n",
      "[334 / 499]: Loss = 0.0533\n",
      "[335 / 499]: Loss = 0.0644\n",
      "[336 / 499]: Loss = 0.0463\n",
      "[337 / 499]: Loss = 0.0669\n",
      "[338 / 499]: Loss = 0.0585\n",
      "[339 / 499]: Loss = 0.0446\n",
      "[340 / 499]: Loss = 0.0624\n",
      "[341 / 499]: Loss = 0.0595\n",
      "[342 / 499]: Loss = 0.0550\n",
      "[343 / 499]: Loss = 0.0522\n",
      "[344 / 499]: Loss = 0.0578\n",
      "[345 / 499]: Loss = 0.0587\n",
      "[346 / 499]: Loss = 0.0608\n",
      "[347 / 499]: Loss = 0.0469\n",
      "[348 / 499]: Loss = 0.0749\n",
      "[349 / 499]: Loss = 0.0650\n",
      "[350 / 499]: Loss = 0.0537\n",
      "[351 / 499]: Loss = 0.0652\n",
      "[352 / 499]: Loss = 0.0621\n",
      "[353 / 499]: Loss = 0.0527\n",
      "[354 / 499]: Loss = 0.0326\n",
      "[355 / 499]: Loss = 0.0673\n",
      "[356 / 499]: Loss = 0.0736\n",
      "[357 / 499]: Loss = 0.0688\n",
      "[358 / 499]: Loss = 0.0354\n",
      "[359 / 499]: Loss = 0.0714\n",
      "[360 / 499]: Loss = 0.0542\n",
      "[361 / 499]: Loss = 0.0564\n",
      "[362 / 499]: Loss = 0.0450\n",
      "[363 / 499]: Loss = 0.0633\n",
      "[364 / 499]: Loss = 0.0766\n",
      "[365 / 499]: Loss = 0.0542\n",
      "[366 / 499]: Loss = 0.0605\n",
      "[367 / 499]: Loss = 0.0673\n",
      "[368 / 499]: Loss = 0.0712\n",
      "[369 / 499]: Loss = 0.0510\n",
      "[370 / 499]: Loss = 0.0644\n",
      "[371 / 499]: Loss = 0.0418\n",
      "[372 / 499]: Loss = 0.0629\n",
      "[373 / 499]: Loss = 0.0537\n",
      "[374 / 499]: Loss = 0.0435\n",
      "[375 / 499]: Loss = 0.0505\n",
      "[376 / 499]: Loss = 0.0633\n",
      "[377 / 499]: Loss = 0.0523\n",
      "[378 / 499]: Loss = 0.0614\n",
      "[379 / 499]: Loss = 0.0500\n",
      "[380 / 499]: Loss = 0.0529\n",
      "[381 / 499]: Loss = 0.0545\n",
      "[382 / 499]: Loss = 0.0627\n",
      "[383 / 499]: Loss = 0.0677\n",
      "[384 / 499]: Loss = 0.0763\n",
      "[385 / 499]: Loss = 0.0556\n",
      "[386 / 499]: Loss = 0.0754\n",
      "[387 / 499]: Loss = 0.0850\n",
      "[388 / 499]: Loss = 0.0524\n",
      "[389 / 499]: Loss = 0.0557\n",
      "[390 / 499]: Loss = 0.0540\n",
      "[391 / 499]: Loss = 0.0463\n",
      "[392 / 499]: Loss = 0.0610\n",
      "[393 / 499]: Loss = 0.0667\n",
      "[394 / 499]: Loss = 0.0742\n",
      "[395 / 499]: Loss = 0.0583\n",
      "[396 / 499]: Loss = 0.0593\n",
      "[397 / 499]: Loss = 0.0458\n",
      "[398 / 499]: Loss = 0.0509\n",
      "[399 / 499]: Loss = 0.0768\n",
      "[400 / 499]: Loss = 0.0385\n",
      "[401 / 499]: Loss = 0.0435\n",
      "[402 / 499]: Loss = 0.0523\n",
      "[403 / 499]: Loss = 0.0667\n",
      "[404 / 499]: Loss = 0.0638\n",
      "[405 / 499]: Loss = 0.0645\n",
      "[406 / 499]: Loss = 0.0565\n",
      "[407 / 499]: Loss = 0.0522\n",
      "[408 / 499]: Loss = 0.0514\n",
      "[409 / 499]: Loss = 0.0622\n",
      "[410 / 499]: Loss = 0.0518\n",
      "[411 / 499]: Loss = 0.0571\n",
      "[412 / 499]: Loss = 0.0541\n",
      "[413 / 499]: Loss = 0.0547\n",
      "[414 / 499]: Loss = 0.0630\n",
      "[415 / 499]: Loss = 0.0555\n",
      "[416 / 499]: Loss = 0.0620\n",
      "[417 / 499]: Loss = 0.0687\n",
      "[418 / 499]: Loss = 0.0491\n",
      "[419 / 499]: Loss = 0.0468\n",
      "[420 / 499]: Loss = 0.0626\n",
      "[421 / 499]: Loss = 0.0704\n",
      "[422 / 499]: Loss = 0.0790\n",
      "[423 / 499]: Loss = 0.0728\n",
      "[424 / 499]: Loss = 0.0560\n",
      "[425 / 499]: Loss = 0.0567\n",
      "[426 / 499]: Loss = 0.0487\n",
      "[427 / 499]: Loss = 0.0606\n",
      "[428 / 499]: Loss = 0.0670\n",
      "[429 / 499]: Loss = 0.0549\n",
      "[430 / 499]: Loss = 0.0644\n",
      "[431 / 499]: Loss = 0.0819\n",
      "[432 / 499]: Loss = 0.0450\n",
      "[433 / 499]: Loss = 0.0433\n",
      "[434 / 499]: Loss = 0.0544\n",
      "[435 / 499]: Loss = 0.0385\n",
      "[436 / 499]: Loss = 0.0376\n",
      "[437 / 499]: Loss = 0.0561\n",
      "[438 / 499]: Loss = 0.0500\n",
      "[439 / 499]: Loss = 0.0541\n",
      "[440 / 499]: Loss = 0.0672\n",
      "[441 / 499]: Loss = 0.0682\n",
      "[442 / 499]: Loss = 0.0378\n",
      "[443 / 499]: Loss = 0.0675\n",
      "[444 / 499]: Loss = 0.0347\n",
      "[445 / 499]: Loss = 0.0645\n",
      "[446 / 499]: Loss = 0.0581\n",
      "[447 / 499]: Loss = 0.0537\n",
      "[448 / 499]: Loss = 0.0501\n",
      "[449 / 499]: Loss = 0.0618\n",
      "[450 / 499]: Loss = 0.0400\n",
      "[451 / 499]: Loss = 0.0546\n",
      "[452 / 499]: Loss = 0.0572\n",
      "[453 / 499]: Loss = 0.0598\n",
      "[454 / 499]: Loss = 0.0845\n",
      "[455 / 499]: Loss = 0.0746\n",
      "[456 / 499]: Loss = 0.0481\n",
      "[457 / 499]: Loss = 0.0584\n",
      "[458 / 499]: Loss = 0.0430\n",
      "[459 / 499]: Loss = 0.0600\n",
      "[460 / 499]: Loss = 0.0487\n",
      "[461 / 499]: Loss = 0.0592\n",
      "[462 / 499]: Loss = 0.0569\n",
      "[463 / 499]: Loss = 0.0502\n",
      "[464 / 499]: Loss = 0.0818\n",
      "[465 / 499]: Loss = 0.0840\n",
      "[466 / 499]: Loss = 0.0706\n",
      "[467 / 499]: Loss = 0.0736\n",
      "[468 / 499]: Loss = 0.0537\n",
      "[469 / 499]: Loss = 0.0707\n",
      "[470 / 499]: Loss = 0.0522\n",
      "[471 / 499]: Loss = 0.0588\n",
      "[472 / 499]: Loss = 0.0584\n",
      "[473 / 499]: Loss = 0.0569\n",
      "[474 / 499]: Loss = 0.0464\n",
      "[475 / 499]: Loss = 0.0521\n",
      "[476 / 499]: Loss = 0.0663\n",
      "[477 / 499]: Loss = 0.0467\n",
      "[478 / 499]: Loss = 0.0600\n",
      "[479 / 499]: Loss = 0.0671\n",
      "[480 / 499]: Loss = 0.0599\n",
      "[481 / 499]: Loss = 0.0510\n",
      "[482 / 499]: Loss = 0.0626\n",
      "[483 / 499]: Loss = 0.0637\n",
      "[484 / 499]: Loss = 0.0394\n",
      "[485 / 499]: Loss = 0.0436\n",
      "[486 / 499]: Loss = 0.0559\n",
      "[487 / 499]: Loss = 0.0517\n",
      "[488 / 499]: Loss = 0.0704\n",
      "[489 / 499]: Loss = 0.0922\n",
      "[490 / 499]: Loss = 0.0755\n",
      "[491 / 499]: Loss = 0.0575\n",
      "[492 / 499]: Loss = 0.0646\n",
      "[493 / 499]: Loss = 0.0523\n",
      "[494 / 499]: Loss = 0.0445\n",
      "[495 / 499]: Loss = 0.0529\n",
      "[496 / 499]: Loss = 0.0634\n",
      "[497 / 499]: Loss = 0.0552\n",
      "[498 / 499]: Loss = 0.0531\n",
      "[0 / 32]: Loss = 0.0514\n",
      "[1 / 32]: Loss = 0.0576\n",
      "[2 / 32]: Loss = 0.0603\n",
      "[3 / 32]: Loss = 0.0607\n",
      "[4 / 32]: Loss = 0.0543\n",
      "[5 / 32]: Loss = 0.0565\n",
      "[6 / 32]: Loss = 0.0576\n",
      "[7 / 32]: Loss = 0.0552\n",
      "[8 / 32]: Loss = 0.0514\n",
      "[9 / 32]: Loss = 0.0489\n",
      "[10 / 32]: Loss = 0.0544\n",
      "[11 / 32]: Loss = 0.0592\n",
      "[12 / 32]: Loss = 0.0611\n",
      "[13 / 32]: Loss = 0.0567\n",
      "[14 / 32]: Loss = 0.0551\n",
      "[15 / 32]: Loss = 0.0601\n",
      "[16 / 32]: Loss = 0.0523\n",
      "[17 / 32]: Loss = 0.0610\n",
      "[18 / 32]: Loss = 0.0560\n",
      "[19 / 32]: Loss = 0.0576\n",
      "[20 / 32]: Loss = 0.0487\n",
      "[21 / 32]: Loss = 0.0678\n",
      "[22 / 32]: Loss = 0.0523\n",
      "[23 / 32]: Loss = 0.0584\n",
      "[24 / 32]: Loss = 0.0556\n",
      "[25 / 32]: Loss = 0.0573\n",
      "[26 / 32]: Loss = 0.0563\n",
      "[27 / 32]: Loss = 0.0487\n",
      "[28 / 32]: Loss = 0.0538\n",
      "[29 / 32]: Loss = 0.0463\n",
      "[30 / 32]: Loss = 0.0510\n",
      "[31 / 32]: Loss = 0.0542\n",
      "Epoch 2 / 3, Epoch Time = 212.66s: Train Loss = 0.0627, Train AUC = 0.9486, Val Loss = 0.0555, Val AUC = 0.9659\n",
      "[0 / 499]: Loss = 0.0537\n",
      "[1 / 499]: Loss = 0.0572\n",
      "[2 / 499]: Loss = 0.0526\n",
      "[3 / 499]: Loss = 0.0621\n",
      "[4 / 499]: Loss = 0.0677\n",
      "[5 / 499]: Loss = 0.0558\n",
      "[6 / 499]: Loss = 0.0647\n",
      "[7 / 499]: Loss = 0.0625\n",
      "[8 / 499]: Loss = 0.0755\n",
      "[9 / 499]: Loss = 0.0417\n",
      "[10 / 499]: Loss = 0.0549\n",
      "[11 / 499]: Loss = 0.0388\n",
      "[12 / 499]: Loss = 0.0492\n",
      "[13 / 499]: Loss = 0.0751\n",
      "[14 / 499]: Loss = 0.0548\n",
      "[15 / 499]: Loss = 0.0561\n",
      "[16 / 499]: Loss = 0.0494\n",
      "[17 / 499]: Loss = 0.0386\n",
      "[18 / 499]: Loss = 0.0636\n",
      "[19 / 499]: Loss = 0.0515\n",
      "[20 / 499]: Loss = 0.0371\n",
      "[21 / 499]: Loss = 0.0596\n",
      "[22 / 499]: Loss = 0.0632\n",
      "[23 / 499]: Loss = 0.0477\n",
      "[24 / 499]: Loss = 0.0498\n",
      "[25 / 499]: Loss = 0.0540\n",
      "[26 / 499]: Loss = 0.0636\n",
      "[27 / 499]: Loss = 0.0542\n",
      "[28 / 499]: Loss = 0.0727\n",
      "[29 / 499]: Loss = 0.0465\n",
      "[30 / 499]: Loss = 0.0676\n",
      "[31 / 499]: Loss = 0.0484\n",
      "[32 / 499]: Loss = 0.0622\n",
      "[33 / 499]: Loss = 0.0428\n",
      "[34 / 499]: Loss = 0.0536\n",
      "[35 / 499]: Loss = 0.0655\n",
      "[36 / 499]: Loss = 0.0409\n",
      "[37 / 499]: Loss = 0.0489\n",
      "[38 / 499]: Loss = 0.0626\n",
      "[39 / 499]: Loss = 0.0524\n",
      "[40 / 499]: Loss = 0.0471\n",
      "[41 / 499]: Loss = 0.0424\n",
      "[42 / 499]: Loss = 0.0630\n",
      "[43 / 499]: Loss = 0.0748\n",
      "[44 / 499]: Loss = 0.0639\n",
      "[45 / 499]: Loss = 0.0754\n",
      "[46 / 499]: Loss = 0.0507\n",
      "[47 / 499]: Loss = 0.0403\n",
      "[48 / 499]: Loss = 0.0557\n",
      "[49 / 499]: Loss = 0.0453\n",
      "[50 / 499]: Loss = 0.0310\n",
      "[51 / 499]: Loss = 0.0690\n",
      "[52 / 499]: Loss = 0.0509\n",
      "[53 / 499]: Loss = 0.0515\n",
      "[54 / 499]: Loss = 0.0636\n",
      "[55 / 499]: Loss = 0.0528\n",
      "[56 / 499]: Loss = 0.0524\n",
      "[57 / 499]: Loss = 0.0524\n",
      "[58 / 499]: Loss = 0.0670\n",
      "[59 / 499]: Loss = 0.0670\n",
      "[60 / 499]: Loss = 0.0636\n",
      "[61 / 499]: Loss = 0.0423\n",
      "[62 / 499]: Loss = 0.0506\n",
      "[63 / 499]: Loss = 0.0681\n",
      "[64 / 499]: Loss = 0.0871\n",
      "[65 / 499]: Loss = 0.0513\n",
      "[66 / 499]: Loss = 0.0487\n",
      "[67 / 499]: Loss = 0.0500\n",
      "[68 / 499]: Loss = 0.0590\n",
      "[69 / 499]: Loss = 0.0525\n",
      "[70 / 499]: Loss = 0.0610\n",
      "[71 / 499]: Loss = 0.0588\n",
      "[72 / 499]: Loss = 0.0696\n",
      "[73 / 499]: Loss = 0.0500\n",
      "[74 / 499]: Loss = 0.0453\n",
      "[75 / 499]: Loss = 0.0469\n",
      "[76 / 499]: Loss = 0.0391\n",
      "[77 / 499]: Loss = 0.0711\n",
      "[78 / 499]: Loss = 0.0590\n",
      "[79 / 499]: Loss = 0.0533\n",
      "[80 / 499]: Loss = 0.0507\n",
      "[81 / 499]: Loss = 0.0641\n",
      "[82 / 499]: Loss = 0.0482\n",
      "[83 / 499]: Loss = 0.0579\n",
      "[84 / 499]: Loss = 0.0389\n",
      "[85 / 499]: Loss = 0.0421\n",
      "[86 / 499]: Loss = 0.0613\n",
      "[87 / 499]: Loss = 0.0668\n",
      "[88 / 499]: Loss = 0.0558\n",
      "[89 / 499]: Loss = 0.0595\n",
      "[90 / 499]: Loss = 0.0848\n",
      "[91 / 499]: Loss = 0.0842\n",
      "[92 / 499]: Loss = 0.0423\n",
      "[93 / 499]: Loss = 0.0691\n",
      "[94 / 499]: Loss = 0.0446\n",
      "[95 / 499]: Loss = 0.0501\n",
      "[96 / 499]: Loss = 0.0554\n",
      "[97 / 499]: Loss = 0.0525\n",
      "[98 / 499]: Loss = 0.0605\n",
      "[99 / 499]: Loss = 0.0503\n",
      "[100 / 499]: Loss = 0.0511\n",
      "[101 / 499]: Loss = 0.0505\n",
      "[102 / 499]: Loss = 0.0479\n",
      "[103 / 499]: Loss = 0.0656\n",
      "[104 / 499]: Loss = 0.0592\n",
      "[105 / 499]: Loss = 0.0481\n",
      "[106 / 499]: Loss = 0.0595\n",
      "[107 / 499]: Loss = 0.0545\n",
      "[108 / 499]: Loss = 0.0502\n",
      "[109 / 499]: Loss = 0.0589\n",
      "[110 / 499]: Loss = 0.0507\n",
      "[111 / 499]: Loss = 0.0512\n",
      "[112 / 499]: Loss = 0.0555\n",
      "[113 / 499]: Loss = 0.0508\n",
      "[114 / 499]: Loss = 0.0361\n",
      "[115 / 499]: Loss = 0.0568\n",
      "[116 / 499]: Loss = 0.0487\n",
      "[117 / 499]: Loss = 0.0597\n",
      "[118 / 499]: Loss = 0.0385\n",
      "[119 / 499]: Loss = 0.0560\n",
      "[120 / 499]: Loss = 0.0564\n",
      "[121 / 499]: Loss = 0.0519\n",
      "[122 / 499]: Loss = 0.0552\n",
      "[123 / 499]: Loss = 0.0494\n",
      "[124 / 499]: Loss = 0.0571\n",
      "[125 / 499]: Loss = 0.0533\n",
      "[126 / 499]: Loss = 0.0683\n",
      "[127 / 499]: Loss = 0.0613\n",
      "[128 / 499]: Loss = 0.0689\n",
      "[129 / 499]: Loss = 0.0660\n",
      "[130 / 499]: Loss = 0.0386\n",
      "[131 / 499]: Loss = 0.0532\n",
      "[132 / 499]: Loss = 0.0518\n",
      "[133 / 499]: Loss = 0.0539\n",
      "[134 / 499]: Loss = 0.0583\n",
      "[135 / 499]: Loss = 0.0698\n",
      "[136 / 499]: Loss = 0.0551\n",
      "[137 / 499]: Loss = 0.0525\n",
      "[138 / 499]: Loss = 0.0426\n",
      "[139 / 499]: Loss = 0.0583\n",
      "[140 / 499]: Loss = 0.0343\n",
      "[141 / 499]: Loss = 0.0481\n",
      "[142 / 499]: Loss = 0.0512\n",
      "[143 / 499]: Loss = 0.0615\n",
      "[144 / 499]: Loss = 0.0572\n",
      "[145 / 499]: Loss = 0.0575\n",
      "[146 / 499]: Loss = 0.0691\n",
      "[147 / 499]: Loss = 0.0451\n",
      "[148 / 499]: Loss = 0.0564\n",
      "[149 / 499]: Loss = 0.0530\n",
      "[150 / 499]: Loss = 0.0594\n",
      "[151 / 499]: Loss = 0.0515\n",
      "[152 / 499]: Loss = 0.0650\n",
      "[153 / 499]: Loss = 0.0710\n",
      "[154 / 499]: Loss = 0.0724\n",
      "[155 / 499]: Loss = 0.0391\n",
      "[156 / 499]: Loss = 0.0536\n",
      "[157 / 499]: Loss = 0.0641\n",
      "[158 / 499]: Loss = 0.0556\n",
      "[159 / 499]: Loss = 0.0445\n",
      "[160 / 499]: Loss = 0.0537\n",
      "[161 / 499]: Loss = 0.0476\n",
      "[162 / 499]: Loss = 0.0480\n",
      "[163 / 499]: Loss = 0.0653\n",
      "[164 / 499]: Loss = 0.0606\n",
      "[165 / 499]: Loss = 0.0428\n",
      "[166 / 499]: Loss = 0.0554\n",
      "[167 / 499]: Loss = 0.0429\n",
      "[168 / 499]: Loss = 0.0630\n",
      "[169 / 499]: Loss = 0.0496\n",
      "[170 / 499]: Loss = 0.0644\n",
      "[171 / 499]: Loss = 0.0622\n",
      "[172 / 499]: Loss = 0.0531\n",
      "[173 / 499]: Loss = 0.0613\n",
      "[174 / 499]: Loss = 0.0479\n",
      "[175 / 499]: Loss = 0.0414\n",
      "[176 / 499]: Loss = 0.0535\n",
      "[177 / 499]: Loss = 0.0460\n",
      "[178 / 499]: Loss = 0.0532\n",
      "[179 / 499]: Loss = 0.0601\n",
      "[180 / 499]: Loss = 0.0600\n",
      "[181 / 499]: Loss = 0.0488\n",
      "[182 / 499]: Loss = 0.0490\n",
      "[183 / 499]: Loss = 0.0514\n",
      "[184 / 499]: Loss = 0.0408\n",
      "[185 / 499]: Loss = 0.0318\n",
      "[186 / 499]: Loss = 0.0559\n",
      "[187 / 499]: Loss = 0.0461\n",
      "[188 / 499]: Loss = 0.0440\n",
      "[189 / 499]: Loss = 0.0390\n",
      "[190 / 499]: Loss = 0.0441\n",
      "[191 / 499]: Loss = 0.0596\n",
      "[192 / 499]: Loss = 0.0684\n",
      "[193 / 499]: Loss = 0.0727\n",
      "[194 / 499]: Loss = 0.0406\n",
      "[195 / 499]: Loss = 0.0440\n",
      "[196 / 499]: Loss = 0.0537\n",
      "[197 / 499]: Loss = 0.0639\n",
      "[198 / 499]: Loss = 0.0535\n",
      "[199 / 499]: Loss = 0.0676\n",
      "[200 / 499]: Loss = 0.0695\n",
      "[201 / 499]: Loss = 0.0667\n",
      "[202 / 499]: Loss = 0.0378\n",
      "[203 / 499]: Loss = 0.0593\n",
      "[204 / 499]: Loss = 0.0643\n",
      "[205 / 499]: Loss = 0.0490\n",
      "[206 / 499]: Loss = 0.0518\n",
      "[207 / 499]: Loss = 0.0565\n",
      "[208 / 499]: Loss = 0.0656\n",
      "[209 / 499]: Loss = 0.0608\n",
      "[210 / 499]: Loss = 0.0709\n",
      "[211 / 499]: Loss = 0.0482\n",
      "[212 / 499]: Loss = 0.0526\n",
      "[213 / 499]: Loss = 0.0490\n",
      "[214 / 499]: Loss = 0.0522\n",
      "[215 / 499]: Loss = 0.0463\n",
      "[216 / 499]: Loss = 0.0466\n",
      "[217 / 499]: Loss = 0.0603\n",
      "[218 / 499]: Loss = 0.0629\n",
      "[219 / 499]: Loss = 0.0570\n",
      "[220 / 499]: Loss = 0.0790\n",
      "[221 / 499]: Loss = 0.0648\n",
      "[222 / 499]: Loss = 0.0612\n",
      "[223 / 499]: Loss = 0.0596\n",
      "[224 / 499]: Loss = 0.0689\n",
      "[225 / 499]: Loss = 0.0400\n",
      "[226 / 499]: Loss = 0.0512\n",
      "[227 / 499]: Loss = 0.0495\n",
      "[228 / 499]: Loss = 0.0479\n",
      "[229 / 499]: Loss = 0.0468\n",
      "[230 / 499]: Loss = 0.0504\n",
      "[231 / 499]: Loss = 0.0568\n",
      "[232 / 499]: Loss = 0.0600\n",
      "[233 / 499]: Loss = 0.0572\n",
      "[234 / 499]: Loss = 0.0580\n",
      "[235 / 499]: Loss = 0.0508\n",
      "[236 / 499]: Loss = 0.0489\n",
      "[237 / 499]: Loss = 0.0464\n",
      "[238 / 499]: Loss = 0.0645\n",
      "[239 / 499]: Loss = 0.0628\n",
      "[240 / 499]: Loss = 0.0459\n",
      "[241 / 499]: Loss = 0.0561\n",
      "[242 / 499]: Loss = 0.0356\n",
      "[243 / 499]: Loss = 0.0382\n",
      "[244 / 499]: Loss = 0.0626\n",
      "[245 / 499]: Loss = 0.0414\n",
      "[246 / 499]: Loss = 0.0645\n",
      "[247 / 499]: Loss = 0.0462\n",
      "[248 / 499]: Loss = 0.0522\n",
      "[249 / 499]: Loss = 0.0683\n",
      "[250 / 499]: Loss = 0.0436\n",
      "[251 / 499]: Loss = 0.0586\n",
      "[252 / 499]: Loss = 0.0743\n",
      "[253 / 499]: Loss = 0.0406\n",
      "[254 / 499]: Loss = 0.0611\n",
      "[255 / 499]: Loss = 0.0401\n",
      "[256 / 499]: Loss = 0.0364\n",
      "[257 / 499]: Loss = 0.0578\n",
      "[258 / 499]: Loss = 0.0408\n",
      "[259 / 499]: Loss = 0.0330\n",
      "[260 / 499]: Loss = 0.0619\n",
      "[261 / 499]: Loss = 0.0539\n",
      "[262 / 499]: Loss = 0.0513\n",
      "[263 / 499]: Loss = 0.0556\n",
      "[264 / 499]: Loss = 0.0560\n",
      "[265 / 499]: Loss = 0.0429\n",
      "[266 / 499]: Loss = 0.0701\n",
      "[267 / 499]: Loss = 0.0738\n",
      "[268 / 499]: Loss = 0.0619\n",
      "[269 / 499]: Loss = 0.0437\n",
      "[270 / 499]: Loss = 0.0390\n",
      "[271 / 499]: Loss = 0.0678\n",
      "[272 / 499]: Loss = 0.0421\n",
      "[273 / 499]: Loss = 0.0441\n",
      "[274 / 499]: Loss = 0.0575\n",
      "[275 / 499]: Loss = 0.0572\n",
      "[276 / 499]: Loss = 0.0377\n",
      "[277 / 499]: Loss = 0.0496\n",
      "[278 / 499]: Loss = 0.0428\n",
      "[279 / 499]: Loss = 0.0543\n",
      "[280 / 499]: Loss = 0.0611\n",
      "[281 / 499]: Loss = 0.0332\n",
      "[282 / 499]: Loss = 0.0591\n",
      "[283 / 499]: Loss = 0.0506\n",
      "[284 / 499]: Loss = 0.0553\n",
      "[285 / 499]: Loss = 0.0520\n",
      "[286 / 499]: Loss = 0.0477\n",
      "[287 / 499]: Loss = 0.0410\n",
      "[288 / 499]: Loss = 0.0448\n",
      "[289 / 499]: Loss = 0.0554\n",
      "[290 / 499]: Loss = 0.0641\n",
      "[291 / 499]: Loss = 0.0548\n",
      "[292 / 499]: Loss = 0.0490\n",
      "[293 / 499]: Loss = 0.0482\n",
      "[294 / 499]: Loss = 0.0606\n",
      "[295 / 499]: Loss = 0.0490\n",
      "[296 / 499]: Loss = 0.0426\n",
      "[297 / 499]: Loss = 0.0482\n",
      "[298 / 499]: Loss = 0.0484\n",
      "[299 / 499]: Loss = 0.0828\n",
      "[300 / 499]: Loss = 0.0500\n",
      "[301 / 499]: Loss = 0.0521\n",
      "[302 / 499]: Loss = 0.0523\n",
      "[303 / 499]: Loss = 0.0501\n",
      "[304 / 499]: Loss = 0.0331\n",
      "[305 / 499]: Loss = 0.0716\n",
      "[306 / 499]: Loss = 0.0437\n",
      "[307 / 499]: Loss = 0.0428\n",
      "[308 / 499]: Loss = 0.0435\n",
      "[309 / 499]: Loss = 0.0507\n",
      "[310 / 499]: Loss = 0.0558\n",
      "[311 / 499]: Loss = 0.0290\n",
      "[312 / 499]: Loss = 0.0589\n",
      "[313 / 499]: Loss = 0.0429\n",
      "[314 / 499]: Loss = 0.0527\n",
      "[315 / 499]: Loss = 0.0504\n",
      "[316 / 499]: Loss = 0.0669\n",
      "[317 / 499]: Loss = 0.0604\n",
      "[318 / 499]: Loss = 0.0381\n",
      "[319 / 499]: Loss = 0.0400\n",
      "[320 / 499]: Loss = 0.0606\n",
      "[321 / 499]: Loss = 0.0655\n",
      "[322 / 499]: Loss = 0.0365\n",
      "[323 / 499]: Loss = 0.0428\n",
      "[324 / 499]: Loss = 0.0452\n",
      "[325 / 499]: Loss = 0.0454\n",
      "[326 / 499]: Loss = 0.0434\n",
      "[327 / 499]: Loss = 0.0646\n",
      "[328 / 499]: Loss = 0.0312\n",
      "[329 / 499]: Loss = 0.0540\n",
      "[330 / 499]: Loss = 0.0731\n",
      "[331 / 499]: Loss = 0.0651\n",
      "[332 / 499]: Loss = 0.0570\n",
      "[333 / 499]: Loss = 0.0515\n",
      "[334 / 499]: Loss = 0.0575\n",
      "[335 / 499]: Loss = 0.0671\n",
      "[336 / 499]: Loss = 0.0481\n",
      "[337 / 499]: Loss = 0.0480\n",
      "[338 / 499]: Loss = 0.0609\n",
      "[339 / 499]: Loss = 0.0644\n",
      "[340 / 499]: Loss = 0.0542\n",
      "[341 / 499]: Loss = 0.0527\n",
      "[342 / 499]: Loss = 0.0458\n",
      "[343 / 499]: Loss = 0.0525\n",
      "[344 / 499]: Loss = 0.0421\n",
      "[345 / 499]: Loss = 0.0690\n",
      "[346 / 499]: Loss = 0.0594\n",
      "[347 / 499]: Loss = 0.0551\n",
      "[348 / 499]: Loss = 0.0454\n",
      "[349 / 499]: Loss = 0.0419\n",
      "[350 / 499]: Loss = 0.0469\n",
      "[351 / 499]: Loss = 0.0645\n",
      "[352 / 499]: Loss = 0.0555\n",
      "[353 / 499]: Loss = 0.0589\n",
      "[354 / 499]: Loss = 0.0530\n",
      "[355 / 499]: Loss = 0.0566\n",
      "[356 / 499]: Loss = 0.0469\n",
      "[357 / 499]: Loss = 0.0412\n",
      "[358 / 499]: Loss = 0.0391\n",
      "[359 / 499]: Loss = 0.0501\n",
      "[360 / 499]: Loss = 0.0556\n",
      "[361 / 499]: Loss = 0.0367\n",
      "[362 / 499]: Loss = 0.0742\n",
      "[363 / 499]: Loss = 0.0510\n",
      "[364 / 499]: Loss = 0.0543\n",
      "[365 / 499]: Loss = 0.0366\n",
      "[366 / 499]: Loss = 0.0450\n",
      "[367 / 499]: Loss = 0.0410\n",
      "[368 / 499]: Loss = 0.0562\n",
      "[369 / 499]: Loss = 0.0563\n",
      "[370 / 499]: Loss = 0.0533\n",
      "[371 / 499]: Loss = 0.0711\n",
      "[372 / 499]: Loss = 0.0542\n",
      "[373 / 499]: Loss = 0.0637\n",
      "[374 / 499]: Loss = 0.0685\n",
      "[375 / 499]: Loss = 0.0693\n",
      "[376 / 499]: Loss = 0.0511\n",
      "[377 / 499]: Loss = 0.0405\n",
      "[378 / 499]: Loss = 0.0527\n",
      "[379 / 499]: Loss = 0.0615\n",
      "[380 / 499]: Loss = 0.0475\n",
      "[381 / 499]: Loss = 0.0539\n",
      "[382 / 499]: Loss = 0.0541\n",
      "[383 / 499]: Loss = 0.0625\n",
      "[384 / 499]: Loss = 0.0730\n",
      "[385 / 499]: Loss = 0.0680\n",
      "[386 / 499]: Loss = 0.0418\n",
      "[387 / 499]: Loss = 0.0553\n",
      "[388 / 499]: Loss = 0.0494\n",
      "[389 / 499]: Loss = 0.0457\n",
      "[390 / 499]: Loss = 0.0612\n",
      "[391 / 499]: Loss = 0.0625\n",
      "[392 / 499]: Loss = 0.0548\n",
      "[393 / 499]: Loss = 0.0574\n",
      "[394 / 499]: Loss = 0.0551\n",
      "[395 / 499]: Loss = 0.0534\n",
      "[396 / 499]: Loss = 0.0517\n",
      "[397 / 499]: Loss = 0.0538\n",
      "[398 / 499]: Loss = 0.0472\n",
      "[399 / 499]: Loss = 0.0476\n",
      "[400 / 499]: Loss = 0.0439\n",
      "[401 / 499]: Loss = 0.0452\n",
      "[402 / 499]: Loss = 0.0821\n",
      "[403 / 499]: Loss = 0.0508\n",
      "[404 / 499]: Loss = 0.0657\n",
      "[405 / 499]: Loss = 0.0462\n",
      "[406 / 499]: Loss = 0.0430\n",
      "[407 / 499]: Loss = 0.0439\n",
      "[408 / 499]: Loss = 0.0466\n",
      "[409 / 499]: Loss = 0.0376\n",
      "[410 / 499]: Loss = 0.0511\n",
      "[411 / 499]: Loss = 0.0541\n",
      "[412 / 499]: Loss = 0.0680\n",
      "[413 / 499]: Loss = 0.0293\n",
      "[414 / 499]: Loss = 0.0438\n",
      "[415 / 499]: Loss = 0.0386\n",
      "[416 / 499]: Loss = 0.0414\n",
      "[417 / 499]: Loss = 0.0383\n",
      "[418 / 499]: Loss = 0.0354\n",
      "[419 / 499]: Loss = 0.0414\n",
      "[420 / 499]: Loss = 0.0468\n",
      "[421 / 499]: Loss = 0.0478\n",
      "[422 / 499]: Loss = 0.0525\n",
      "[423 / 499]: Loss = 0.0476\n",
      "[424 / 499]: Loss = 0.0362\n",
      "[425 / 499]: Loss = 0.0510\n",
      "[426 / 499]: Loss = 0.0658\n",
      "[427 / 499]: Loss = 0.0523\n",
      "[428 / 499]: Loss = 0.0416\n",
      "[429 / 499]: Loss = 0.0366\n",
      "[430 / 499]: Loss = 0.0562\n",
      "[431 / 499]: Loss = 0.0642\n",
      "[432 / 499]: Loss = 0.0403\n",
      "[433 / 499]: Loss = 0.0450\n",
      "[434 / 499]: Loss = 0.0717\n",
      "[435 / 499]: Loss = 0.0354\n",
      "[436 / 499]: Loss = 0.0521\n",
      "[437 / 499]: Loss = 0.0567\n",
      "[438 / 499]: Loss = 0.0547\n",
      "[439 / 499]: Loss = 0.0514\n",
      "[440 / 499]: Loss = 0.0620\n",
      "[441 / 499]: Loss = 0.0849\n",
      "[442 / 499]: Loss = 0.0508\n",
      "[443 / 499]: Loss = 0.0403\n",
      "[444 / 499]: Loss = 0.0511\n",
      "[445 / 499]: Loss = 0.0371\n",
      "[446 / 499]: Loss = 0.0478\n",
      "[447 / 499]: Loss = 0.0510\n",
      "[448 / 499]: Loss = 0.0434\n",
      "[449 / 499]: Loss = 0.0707\n",
      "[450 / 499]: Loss = 0.0429\n",
      "[451 / 499]: Loss = 0.0485\n",
      "[452 / 499]: Loss = 0.0405\n",
      "[453 / 499]: Loss = 0.0502\n",
      "[454 / 499]: Loss = 0.0399\n",
      "[455 / 499]: Loss = 0.0408\n",
      "[456 / 499]: Loss = 0.0580\n",
      "[457 / 499]: Loss = 0.0617\n",
      "[458 / 499]: Loss = 0.0628\n",
      "[459 / 499]: Loss = 0.0519\n",
      "[460 / 499]: Loss = 0.0343\n",
      "[461 / 499]: Loss = 0.0442\n",
      "[462 / 499]: Loss = 0.0620\n",
      "[463 / 499]: Loss = 0.0577\n",
      "[464 / 499]: Loss = 0.0537\n",
      "[465 / 499]: Loss = 0.0783\n",
      "[466 / 499]: Loss = 0.0914\n",
      "[467 / 499]: Loss = 0.0614\n",
      "[468 / 499]: Loss = 0.0747\n",
      "[469 / 499]: Loss = 0.0451\n",
      "[470 / 499]: Loss = 0.0711\n",
      "[471 / 499]: Loss = 0.0347\n",
      "[472 / 499]: Loss = 0.0515\n",
      "[473 / 499]: Loss = 0.0588\n",
      "[474 / 499]: Loss = 0.0695\n",
      "[475 / 499]: Loss = 0.0400\n",
      "[476 / 499]: Loss = 0.0487\n",
      "[477 / 499]: Loss = 0.0478\n",
      "[478 / 499]: Loss = 0.0593\n",
      "[479 / 499]: Loss = 0.0452\n",
      "[480 / 499]: Loss = 0.0638\n",
      "[481 / 499]: Loss = 0.0442\n",
      "[482 / 499]: Loss = 0.0629\n",
      "[483 / 499]: Loss = 0.0630\n",
      "[484 / 499]: Loss = 0.0383\n",
      "[485 / 499]: Loss = 0.0538\n",
      "[486 / 499]: Loss = 0.0601\n",
      "[487 / 499]: Loss = 0.0398\n",
      "[488 / 499]: Loss = 0.0611\n",
      "[489 / 499]: Loss = 0.0642\n",
      "[490 / 499]: Loss = 0.0634\n",
      "[491 / 499]: Loss = 0.0446\n",
      "[492 / 499]: Loss = 0.0428\n",
      "[493 / 499]: Loss = 0.0651\n",
      "[494 / 499]: Loss = 0.0558\n",
      "[495 / 499]: Loss = 0.0523\n",
      "[496 / 499]: Loss = 0.0439\n",
      "[497 / 499]: Loss = 0.0448\n",
      "[498 / 499]: Loss = 0.0318\n",
      "[0 / 32]: Loss = 0.0516\n",
      "[1 / 32]: Loss = 0.0496\n",
      "[2 / 32]: Loss = 0.0581\n",
      "[3 / 32]: Loss = 0.0459\n",
      "[4 / 32]: Loss = 0.0556\n",
      "[5 / 32]: Loss = 0.0561\n",
      "[6 / 32]: Loss = 0.0527\n",
      "[7 / 32]: Loss = 0.0566\n",
      "[8 / 32]: Loss = 0.0514\n",
      "[9 / 32]: Loss = 0.0486\n",
      "[10 / 32]: Loss = 0.0478\n",
      "[11 / 32]: Loss = 0.0514\n",
      "[12 / 32]: Loss = 0.0549\n",
      "[13 / 32]: Loss = 0.0571\n",
      "[14 / 32]: Loss = 0.0452\n",
      "[15 / 32]: Loss = 0.0535\n",
      "[16 / 32]: Loss = 0.0483\n",
      "[17 / 32]: Loss = 0.0506\n",
      "[18 / 32]: Loss = 0.0500\n",
      "[19 / 32]: Loss = 0.0546\n",
      "[20 / 32]: Loss = 0.0551\n",
      "[21 / 32]: Loss = 0.0477\n",
      "[22 / 32]: Loss = 0.0524\n",
      "[23 / 32]: Loss = 0.0488\n",
      "[24 / 32]: Loss = 0.0488\n",
      "[25 / 32]: Loss = 0.0499\n",
      "[26 / 32]: Loss = 0.0530\n",
      "[27 / 32]: Loss = 0.0455\n",
      "[28 / 32]: Loss = 0.0488\n",
      "[29 / 32]: Loss = 0.0499\n",
      "[30 / 32]: Loss = 0.0591\n",
      "[31 / 32]: Loss = 0.0453\n",
      "Epoch 3 / 3, Epoch Time = 211.38s: Train Loss = 0.0536, Train AUC = 0.9666, Val Loss = 0.0514, Val AUC = 0.9713\n"
     ]
    }
   ],
   "source": [
    "vocab_size  = len(token_to_id)\n",
    "embed_size  = 300\n",
    "hidden_size = 64\n",
    "num_classes = 6\n",
    "\n",
    "\n",
    "model        = RCNN2(torch.FloatTensor(embedding_matrix),\n",
    "                  vocab_size, \n",
    "                  embed_size,\n",
    "                  hidden_size,\n",
    "                  num_classes\n",
    "                  ).cuda()\n",
    "\n",
    "criterion    = nn.BCEWithLogitsLoss().cuda()\n",
    "optimizer    = optim.Adam([param for param in model.parameters() if param.requires_grad], lr=0.001)\n",
    "\n",
    "X_train      = as_matrix(data_train['tokenized_comments'], \n",
    "                         token_to_id, \n",
    "                         word_dropout=0.000, \n",
    "                         UNK_IX=UNK_IX, \n",
    "                         PAD_IX=PAD_IX,\n",
    "                         max_len=MAX_LEN\n",
    "                        )\n",
    "\n",
    "train_labels = data_train.loc[:, TARGET_COLS].values \n",
    "\n",
    "X_test       = as_matrix(data_val['tokenized_comments'],\n",
    "                         token_to_id, \n",
    "                         word_dropout=0.000, \n",
    "                         UNK_IX=UNK_IX, \n",
    "                         PAD_IX=PAD_IX,\n",
    "                         max_len=MAX_LEN\n",
    "                        )\n",
    "\n",
    "test_labels  = data_val.loc[:, TARGET_COLS].values\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, train_labels), epochs_count=3, \n",
    "    batch_size=256, val_data=(X_test, test_labels), val_batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 2 / 2, Epoch Time = 167.66s: Train Loss = 0.0427, Train AUC = 0.9793, Val Loss = 0.0483, Val AUC = 0.9781"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4,  5,  5,  6],\n",
      "         [ 0,  0,  0,  0]],\n",
      "\n",
      "        [[10, 10, 10, 10],\n",
      "         [ 0,  0,  0,  0]]])\n",
      "\n",
      "tensor([[[ 0,  0,  0,  0],\n",
      "         [ 4,  5,  5,  6]],\n",
      "\n",
      "        [[ 0,  0,  0,  0],\n",
      "         [10, 10, 10, 10]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor([[[1, 2, 3, 4],\n",
    "                      [4, 5, 5, 6]],\n",
    "                      \n",
    "                      [[1, 1, 1, 1],\n",
    "                       [10, 10, 10, 10]\n",
    "                      ]\n",
    "                     ])\n",
    "\n",
    "print(F.pad(x, (0, 0, 0, 1, 0, 0))[:, 1:, :])\n",
    "print()\n",
    "print(torch.flip(F.pad(x, (0, 0, 0, 1, 0, 0))[:, 1:, :], [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
