This repo contains implementation of Word2Vec which learns neural word embeddings using SkipGram Model tried following things:

- [Naive Word2Vec](https://arxiv.org/pdf/1411.2738.pdf) with a two-layer neural network.
- Word2vec only with one matrix.
- Negative Sampling
    - Vanilla Implementation.
    - Batch Transpose Trick.
- [Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606)

[Medium Post](https://medium.com/@numb3r303_59126/enriching-word-vectors-with-subword-information-9ebe771a059d)
